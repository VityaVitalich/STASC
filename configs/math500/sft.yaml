model:
  model_name_or_path: "VityaVitalich/Llama3.1-8b-instruct"
  tokenizer_name: null
  cache_dir: "/home/data/v.moskvoretskii/cache/"
  trust_remote_code: false
  use_fast_tokenizer: true
  torch_dtype: "bfloat16"

data:
  dataset_name: "VityaVitalich/CQA"
  block_size: 4096
  validation_split_percentage: 0
  dataset_percentage: 100
  seed: 42
  streaming: false
  overwrite_cache: false
  preprocessing_num_workers: 4
  load_from_disk: false

training:
  output_dir: "/home/data/v.moskvoretskii/cache/cqa_6e-4_4bs_0.1warmup_3epoch_r8/"
  learning_rate: 6.0e-4
  num_train_epochs: 3
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 2
  gradient_checkpointing: false
  max_steps: -1
  save_strategy: "epoch"
  save_steps: 1
  evaluation_strategy: "no"
  eval_steps: 1
  weight_decay: 0.1
  warmup_ratio: 0.1
  lr_scheduler_type: "cosine"
  logging_steps: 10
  do_train: true
  do_eval: false
  report_to: ["wandb"]
  run_name: "cqa_6e-4_4bs_0.1warmup_3epoch_r32_all_modules"
  project_name: "TRL"

peft:
  use_lora: true
  lora_rank: 32
  lora_alpha: 16
  lora_dropout: 0.1
  lora_target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "up_proj"
    - "down_proj"
    - "gate_proj"

  dora: false
