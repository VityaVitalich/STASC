2025-01-06 17:22:45,936 - star_logger_test - INFO - [INFO] Starting iteration 1/2
2025-01-06 17:22:45,936 - star_logger_test - INFO - Running command: python star_vllm_generation.py --config_path configs/star_config.yaml --generation_model_path luezzka/Llama-3.2-1B-Instruct --ft_dataset_path /home/data/v.moskvoretskii/cache/STaR/test/data/data_0 --iteration 0
2025-01-06 17:22:52,965 - star_logger_test - INFO - [INFO] No few-shot file found for prompt_type='star_generation' at 'few_shots/star_generation.json'. Using none.
2025-01-06 17:22:52,965 - star_logger_test - INFO - [INFO] No few-shot file found for prompt_type='star_rationalization' at 'few_shots/star_rationalization.json'. Using none.
2025-01-06 17:22:52,965 - star_logger_test - INFO - INFO 01-06 17:22:52 config.py:1652] Downcasting torch.float32 to torch.bfloat16.
2025-01-06 17:22:52,966 - star_logger_test - INFO - INFO 01-06 17:22:52 config.py:899] Defaulting to use mp for distributed inference
2025-01-06 17:22:52,966 - star_logger_test - INFO - WARNING 01-06 17:22:52 config.py:389] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
2025-01-06 17:22:52,969 - star_logger_test - INFO - INFO 01-06 17:22:52 llm_engine.py:226] Initializing an LLM engine (v0.6.1.dev238+ge2c6e0a82) with config: model='luezzka/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='luezzka/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1024, download_dir='/home/data/v.moskvoretskii/cache/', load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=luezzka/Llama-3.2-1B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, multi_step_stream_outputs=False, enable_prefix_caching=False, use_async_output_proc=False, use_cached_outputs=False, mm_processor_kwargs=None)
2025-01-06 17:22:54,076 - star_logger_test - INFO - WARNING 01-06 17:22:54 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
2025-01-06 17:22:54,120 - star_logger_test - INFO - INFO 01-06 17:22:54 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
2025-01-06 17:22:54,478 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=197906)[0;0m INFO 01-06 17:22:54 multiproc_worker_utils.py:218] Worker ready; awaiting tasks
2025-01-06 17:22:55,287 - star_logger_test - INFO - INFO 01-06 17:22:55 utils.py:992] Found nccl from library libnccl.so.2
2025-01-06 17:22:55,287 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=197906)[0;0m INFO 01-06 17:22:55 utils.py:992] Found nccl from library libnccl.so.2
2025-01-06 17:22:55,287 - star_logger_test - INFO - INFO 01-06 17:22:55 pynccl.py:63] vLLM is using nccl==2.20.5
2025-01-06 17:22:55,287 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=197906)[0;0m INFO 01-06 17:22:55 pynccl.py:63] vLLM is using nccl==2.20.5
2025-01-06 17:22:55,561 - star_logger_test - INFO - INFO 01-06 17:22:55 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
2025-01-06 17:22:55,561 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=197906)[0;0m INFO 01-06 17:22:55 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
2025-01-06 17:22:55,569 - star_logger_test - INFO - INFO 01-06 17:22:55 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7fde08e72560>, local_subscribe_port=47155, remote_subscribe_port=None)
2025-01-06 17:22:55,573 - star_logger_test - INFO - INFO 01-06 17:22:55 model_runner.py:1014] Starting to load model luezzka/Llama-3.2-1B-Instruct...
2025-01-06 17:22:55,573 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=197906)[0;0m INFO 01-06 17:22:55 model_runner.py:1014] Starting to load model luezzka/Llama-3.2-1B-Instruct...
2025-01-06 17:22:56,013 - star_logger_test - INFO - INFO 01-06 17:22:56 weight_utils.py:242] Using model weights format ['*.safetensors']
2025-01-06 17:22:56,069 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=197906)[0;0m INFO 01-06 17:22:56 weight_utils.py:242] Using model weights format ['*.safetensors']
2025-01-06 17:22:56,321 - star_logger_test - INFO - INFO 01-06 17:22:56 weight_utils.py:287] No model.safetensors.index.json found in remote.
2025-01-06 17:22:56,321 - star_logger_test - ERROR - 
2025-01-06 17:22:56,322 - star_logger_test - ERROR - Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-01-06 17:22:56,678 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=197906)[0;0m INFO 01-06 17:22:56 weight_utils.py:287] No model.safetensors.index.json found in remote.
2025-01-06 17:22:57,134 - star_logger_test - ERROR - 
2025-01-06 17:22:57,134 - star_logger_test - ERROR - Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.23it/s]
2025-01-06 17:22:57,135 - star_logger_test - ERROR - 
2025-01-06 17:22:57,135 - star_logger_test - ERROR - Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.23it/s]
2025-01-06 17:22:57,135 - star_logger_test - ERROR - 
2025-01-06 17:22:57,415 - star_logger_test - INFO - INFO 01-06 17:22:57 model_runner.py:1025] Loading model weights took 1.1666 GB
2025-01-06 17:22:57,790 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=197906)[0;0m INFO 01-06 17:22:57 model_runner.py:1025] Loading model weights took 1.1666 GB
2025-01-06 17:22:58,693 - star_logger_test - INFO - INFO 01-06 17:22:58 distributed_gpu_executor.py:57] # GPU blocks: 168803, # CPU blocks: 16384
2025-01-06 17:23:01,714 - star_logger_test - INFO - [INFO] Starting generation at 1/2
2025-01-06 17:23:01,715 - star_logger_test - ERROR - 
2025-01-06 17:23:04,734 - star_logger_test - ERROR - Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
2025-01-06 17:23:07,456 - star_logger_test - ERROR - Processed prompts:   0%|          | 1/500 [00:03<25:06,  3.02s/it, est. speed input: 36.43 toks/s, output: 9.60 toks/s]
2025-01-06 17:23:08,628 - star_logger_test - ERROR - Processed prompts:   0%|          | 2/500 [00:05<23:36,  2.84s/it, est. speed input: 37.97 toks/s, output: 18.11 toks/s]
2025-01-06 17:23:09,127 - star_logger_test - ERROR - Processed prompts:   1%|          | 3/500 [00:06<17:14,  2.08s/it, est. speed input: 47.88 toks/s, output: 28.06 toks/s]
2025-01-06 17:23:09,625 - star_logger_test - ERROR - Processed prompts:   1%|          | 4/500 [00:07<12:02,  1.46s/it, est. speed input: 59.63 toks/s, output: 39.39 toks/s]
2025-01-06 17:23:10,626 - star_logger_test - ERROR - Processed prompts:   1%|          | 6/500 [00:07<06:43,  1.22it/s, est. speed input: 83.30 toks/s, output: 62.83 toks/s]
2025-01-06 17:23:10,864 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 8/500 [00:08<05:34,  1.47it/s, est. speed input: 99.54 toks/s, output: 81.47 toks/s]
2025-01-06 17:23:10,992 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 9/500 [00:09<04:42,  1.74it/s, est. speed input: 109.41 toks/s, output: 93.12 toks/s]
2025-01-06 17:23:11,133 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 10/500 [00:09<03:47,  2.16it/s, est. speed input: 119.65 toks/s, output: 105.64 toks/s]
2025-01-06 17:23:11,501 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 12/500 [00:09<02:26,  3.34it/s, est. speed input: 141.10 toks/s, output: 131.54 toks/s]
2025-01-06 17:23:11,764 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 13/500 [00:09<02:33,  3.17it/s, est. speed input: 147.03 toks/s, output: 140.50 toks/s]
2025-01-06 17:23:11,977 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 15/500 [00:10<01:57,  4.13it/s, est. speed input: 165.28 toks/s, output: 164.38 toks/s]
2025-01-06 17:23:12,115 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 16/500 [00:10<01:54,  4.24it/s, est. speed input: 172.97 toks/s, output: 174.91 toks/s]
2025-01-06 17:23:12,247 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 17/500 [00:10<01:42,  4.71it/s, est. speed input: 181.25 toks/s, output: 186.54 toks/s]
2025-01-06 17:23:12,438 - star_logger_test - ERROR - Processed prompts:   4%|▎         | 18/500 [00:10<01:32,  5.21it/s, est. speed input: 189.51 toks/s, output: 198.15 toks/s]
2025-01-06 17:23:12,630 - star_logger_test - ERROR - Processed prompts:   4%|▍         | 20/500 [00:10<01:12,  6.61it/s, est. speed input: 206.55 toks/s, output: 222.41 toks/s]
2025-01-06 17:23:12,765 - star_logger_test - ERROR - Processed prompts:   4%|▍         | 22/500 [00:10<01:02,  7.67it/s, est. speed input: 223.08 toks/s, output: 246.35 toks/s]
2025-01-06 17:23:12,894 - star_logger_test - ERROR - Processed prompts:   5%|▍         | 23/500 [00:11<01:02,  7.60it/s, est. speed input: 230.39 toks/s, output: 257.36 toks/s]
2025-01-06 17:23:13,156 - star_logger_test - ERROR - Processed prompts:   5%|▍         | 24/500 [00:11<01:02,  7.65it/s, est. speed input: 237.94 toks/s, output: 268.45 toks/s]
2025-01-06 17:23:13,307 - star_logger_test - ERROR - Processed prompts:   5%|▌         | 25/500 [00:11<01:17,  6.11it/s, est. speed input: 242.00 toks/s, output: 276.35 toks/s]
2025-01-06 17:23:13,457 - star_logger_test - ERROR - Processed prompts:   6%|▌         | 29/500 [00:11<00:42, 11.16it/s, est. speed input: 276.74 toks/s, output: 328.58 toks/s]
2025-01-06 17:23:13,605 - star_logger_test - ERROR - Processed prompts:   7%|▋         | 33/500 [00:11<00:30, 15.17it/s, est. speed input: 310.82 toks/s, output: 380.14 toks/s]
2025-01-06 17:23:13,865 - star_logger_test - ERROR - Processed prompts:   7%|▋         | 37/500 [00:11<00:25, 18.36it/s, est. speed input: 343.88 toks/s, output: 431.26 toks/s]
2025-01-06 17:23:14,034 - star_logger_test - ERROR - Processed prompts:   8%|▊         | 39/500 [00:12<00:32, 14.08it/s, est. speed input: 354.64 toks/s, output: 450.03 toks/s]
2025-01-06 17:23:14,249 - star_logger_test - ERROR - Processed prompts:   8%|▊         | 41/500 [00:12<00:34, 13.47it/s, est. speed input: 367.48 toks/s, output: 471.87 toks/s]
2025-01-06 17:23:14,461 - star_logger_test - ERROR - Processed prompts:   9%|▉         | 45/500 [00:12<00:30, 15.15it/s, est. speed input: 396.42 toks/s, output: 519.20 toks/s]
2025-01-06 17:23:14,587 - star_logger_test - ERROR - Processed prompts:   9%|▉         | 47/500 [00:12<00:33, 13.34it/s, est. speed input: 407.16 toks/s, output: 538.49 toks/s]
2025-01-06 17:23:14,724 - star_logger_test - ERROR - Processed prompts:  10%|█         | 50/500 [00:12<00:28, 15.57it/s, est. speed input: 428.75 toks/s, output: 575.10 toks/s]
2025-01-06 17:23:14,944 - star_logger_test - ERROR - Processed prompts:  10%|█         | 52/500 [00:13<00:29, 15.33it/s, est. speed input: 441.60 toks/s, output: 597.02 toks/s]
2025-01-06 17:23:15,115 - star_logger_test - ERROR - Processed prompts:  11%|█         | 56/500 [00:13<00:27, 16.36it/s, est. speed input: 468.04 toks/s, output: 642.87 toks/s]
2025-01-06 17:23:15,286 - star_logger_test - ERROR - Processed prompts:  12%|█▏        | 58/500 [00:13<00:29, 15.02it/s, est. speed input: 478.48 toks/s, output: 662.65 toks/s]
2025-01-06 17:23:15,512 - star_logger_test - ERROR - Processed prompts:  12%|█▏        | 62/500 [00:13<00:25, 17.45it/s, est. speed input: 505.98 toks/s, output: 710.01 toks/s]
2025-01-06 17:23:15,682 - star_logger_test - ERROR - Processed prompts:  13%|█▎        | 64/500 [00:13<00:30, 14.40it/s, est. speed input: 513.78 toks/s, output: 726.21 toks/s]
2025-01-06 17:23:15,822 - star_logger_test - ERROR - Processed prompts:  13%|█▎        | 66/500 [00:13<00:31, 13.69it/s, est. speed input: 523.38 toks/s, output: 745.26 toks/s]
2025-01-06 17:23:15,959 - star_logger_test - ERROR - Processed prompts:  14%|█▎        | 68/500 [00:14<00:31, 13.82it/s, est. speed input: 533.47 toks/s, output: 765.61 toks/s]
2025-01-06 17:23:16,191 - star_logger_test - ERROR - Processed prompts:  14%|█▍        | 70/500 [00:14<00:30, 14.02it/s, est. speed input: 544.34 toks/s, output: 786.19 toks/s]
2025-01-06 17:23:16,364 - star_logger_test - ERROR - Processed prompts:  14%|█▍        | 72/500 [00:14<00:35, 11.96it/s, est. speed input: 550.68 toks/s, output: 801.35 toks/s]
2025-01-06 17:23:16,500 - star_logger_test - ERROR - Processed prompts:  15%|█▍        | 74/500 [00:14<00:35, 11.85it/s, est. speed input: 559.49 toks/s, output: 819.70 toks/s]
2025-01-06 17:23:16,648 - star_logger_test - ERROR - Processed prompts:  15%|█▌        | 76/500 [00:14<00:33, 12.55it/s, est. speed input: 569.35 toks/s, output: 839.89 toks/s]
2025-01-06 17:23:16,885 - star_logger_test - ERROR - Processed prompts:  16%|█▌        | 79/500 [00:14<00:28, 14.67it/s, est. speed input: 585.66 toks/s, output: 873.06 toks/s]
2025-01-06 17:23:17,057 - star_logger_test - ERROR - Processed prompts:  16%|█▌        | 81/500 [00:15<00:34, 12.25it/s, est. speed input: 590.93 toks/s, output: 887.09 toks/s]
2025-01-06 17:23:17,228 - star_logger_test - ERROR - Processed prompts:  17%|█▋        | 83/500 [00:15<00:34, 12.08it/s, est. speed input: 598.79 toks/s, output: 904.87 toks/s]
2025-01-06 17:23:17,369 - star_logger_test - ERROR - Processed prompts:  18%|█▊        | 89/500 [00:15<00:21, 18.73it/s, est. speed input: 634.67 toks/s, output: 977.54 toks/s]
2025-01-06 17:23:17,643 - star_logger_test - ERROR - Processed prompts:  18%|█▊        | 91/500 [00:15<00:23, 17.59it/s, est. speed input: 643.22 toks/s, output: 996.36 toks/s]
2025-01-06 17:23:17,938 - star_logger_test - ERROR - Processed prompts:  19%|█▊        | 93/500 [00:15<00:30, 13.33it/s, est. speed input: 645.72 toks/s, output: 1006.84 toks/s]
2025-01-06 17:23:18,100 - star_logger_test - ERROR - Processed prompts:  19%|█▉        | 95/500 [00:16<00:37, 10.78it/s, est. speed input: 647.33 toks/s, output: 1016.18 toks/s]
2025-01-06 17:23:18,258 - star_logger_test - ERROR - Processed prompts:  20%|█▉        | 98/500 [00:16<00:31, 12.59it/s, est. speed input: 661.01 toks/s, output: 1039.94 toks/s]
2025-01-06 17:23:18,419 - star_logger_test - ERROR - Processed prompts:  20%|██        | 101/500 [00:16<00:28, 14.15it/s, est. speed input: 674.51 toks/s, output: 1071.40 toks/s]
2025-01-06 17:23:18,569 - star_logger_test - ERROR - Processed prompts:  21%|██        | 103/500 [00:16<00:28, 13.70it/s, est. speed input: 681.42 toks/s, output: 1088.66 toks/s]
2025-01-06 17:23:18,801 - star_logger_test - ERROR - Processed prompts:  21%|██        | 105/500 [00:16<00:29, 13.61it/s, est. speed input: 688.24 toks/s, output: 1106.53 toks/s]
2025-01-06 17:23:18,950 - star_logger_test - ERROR - Processed prompts:  22%|██▏       | 109/500 [00:17<00:26, 14.94it/s, est. speed input: 704.84 toks/s, output: 1146.31 toks/s]
2025-01-06 17:23:19,083 - star_logger_test - ERROR - Processed prompts:  23%|██▎       | 113/500 [00:17<00:21, 17.91it/s, est. speed input: 724.26 toks/s, output: 1191.31 toks/s]
2025-01-06 17:23:19,242 - star_logger_test - ERROR - Processed prompts:  23%|██▎       | 115/500 [00:17<00:22, 17.24it/s, est. speed input: 731.34 toks/s, output: 1209.75 toks/s]
2025-01-06 17:23:19,469 - star_logger_test - ERROR - Processed prompts:  23%|██▎       | 117/500 [00:17<00:24, 15.87it/s, est. speed input: 737.26 toks/s, output: 1226.32 toks/s]
2025-01-06 17:23:19,649 - star_logger_test - ERROR - Processed prompts:  24%|██▍       | 121/500 [00:17<00:22, 16.51it/s, est. speed input: 752.70 toks/s, output: 1265.35 toks/s]
2025-01-06 17:23:19,817 - star_logger_test - ERROR - Processed prompts:  25%|██▍       | 124/500 [00:17<00:22, 16.55it/s, est. speed input: 763.65 toks/s, output: 1293.85 toks/s]
2025-01-06 17:23:20,027 - star_logger_test - ERROR - Processed prompts:  25%|██▌       | 126/500 [00:18<00:24, 15.25it/s, est. speed input: 768.80 toks/s, output: 1309.34 toks/s]
2025-01-06 17:23:20,517 - star_logger_test - ERROR - Processed prompts:  26%|██▌       | 128/500 [00:18<00:27, 13.31it/s, est. speed input: 772.08 toks/s, output: 1321.64 toks/s]
2025-01-06 17:23:21,907 - star_logger_test - ERROR - Processed prompts:  26%|██▌       | 130/500 [00:18<00:43,  8.43it/s, est. speed input: 763.51 toks/s, output: 1314.17 toks/s]
2025-01-06 17:23:23,416 - star_logger_test - ERROR - Processed prompts:  52%|█████▏    | 258/500 [00:20<00:03, 65.48it/s, est. speed input: 1412.88 toks/s, output: 2841.35 toks/s]
2025-01-06 17:23:23,965 - star_logger_test - ERROR - Processed prompts:  52%|█████▏    | 262/500 [00:21<00:07, 33.19it/s, est. speed input: 1335.01 toks/s, output: 2676.74 toks/s]
2025-01-06 17:23:24,112 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=197906)[0;0m INFO 01-06 17:23:24 multiproc_worker_utils.py:244] Worker exiting
2025-01-06 17:23:24,112 - star_logger_test - ERROR - Processed prompts:  53%|█████▎    | 265/500 [00:22<00:08, 27.34it/s, est. speed input: 1317.06 toks/s, output: 2630.21 toks/s][rank0]: Traceback (most recent call last):
2025-01-06 17:23:24,113 - star_logger_test - ERROR - [rank0]:   File "/home/data/v.moskvoretskii/QAC/star_vllm_generation.py", line 328, in <module>
2025-01-06 17:23:24,113 - star_logger_test - ERROR - [rank0]:     main()
2025-01-06 17:23:24,113 - star_logger_test - ERROR - [rank0]:   File "/home/data/v.moskvoretskii/QAC/star_vllm_generation.py", line 279, in main
2025-01-06 17:23:24,113 - star_logger_test - ERROR - [rank0]:     train_data = perform_generation(
2025-01-06 17:23:24,113 - star_logger_test - ERROR - [rank0]:   File "/home/data/v.moskvoretskii/QAC/star_vllm_generation.py", line 203, in perform_generation
2025-01-06 17:23:24,113 - star_logger_test - ERROR - [rank0]:     generation_results = generate_for_dataset(
2025-01-06 17:23:24,113 - star_logger_test - ERROR - [rank0]:   File "/home/data/v.moskvoretskii/QAC/generation_utils.py", line 184, in generate_for_dataset
2025-01-06 17:23:24,113 - star_logger_test - ERROR - [rank0]:     generation_results = model.generate(all_prompts, sampling_params)
2025-01-06 17:23:24,113 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/utils.py", line 1047, in inner
2025-01-06 17:23:24,113 - star_logger_test - ERROR - [rank0]:     return fn(*args, **kwargs)
2025-01-06 17:23:24,113 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/llm.py", line 388, in generate
2025-01-06 17:23:24,113 - star_logger_test - ERROR - [rank0]:     outputs = self._run_engine(use_tqdm=use_tqdm)
2025-01-06 17:23:24,113 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/llm.py", line 877, in _run_engine
2025-01-06 17:23:24,113 - star_logger_test - ERROR - [rank0]:     step_outputs = self.llm_engine.step()
2025-01-06 17:23:24,114 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py", line 1306, in step
2025-01-06 17:23:24,114 - star_logger_test - ERROR - [rank0]:     self._process_model_outputs(ctx=ctx)
2025-01-06 17:23:24,114 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py", line 1009, in _process_model_outputs
2025-01-06 17:23:24,114 - star_logger_test - ERROR - [rank0]:     if self.model_config.embedding_mode:
2025-01-06 17:23:24,114 - star_logger_test - ERROR - [rank0]: KeyboardInterrupt
2025-01-06 17:23:25,349 - star_logger_test - ERROR - 
2025-01-06 17:23:25,349 - star_logger_test - ERROR - Processed prompts:  54%|█████▎    | 268/500 [00:23<00:20, 11.34it/s, est. speed input: 1325.89 toks/s, output: 2634.50 toks/s]
2025-01-06 17:23:25,988 - star_logger_test - ERROR - [rank0]:[W106 17:23:25.976976671 CudaIPCTypes.cpp:16] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]
2025-01-06 17:23:26,433 - star_logger_test - ERROR - /usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
2025-01-06 17:23:26,433 - star_logger_test - ERROR -   warnings.warn('resource_tracker: There appear to be %d '
2025-01-06 17:31:14,518 - star_logger_test - INFO - [INFO] Starting iteration 1/2
2025-01-06 17:31:14,518 - star_logger_test - INFO - Running command: python star_vllm_generation.py --config_path configs/star_config.yaml --generation_model_path luezzka/Llama-3.2-1B-Instruct --ft_dataset_path /home/data/v.moskvoretskii/cache/STaR/test/data/data_0 --iteration 0
2025-01-06 17:31:22,917 - star_logger_test - INFO - [INFO] No few-shot file found for prompt_type='star_generation' at 'few_shots/star_generation.json'. Using none.
2025-01-06 17:31:22,917 - star_logger_test - INFO - [INFO] No few-shot file found for prompt_type='star_rationalization' at 'few_shots/star_rationalization.json'. Using none.
2025-01-06 17:31:22,917 - star_logger_test - INFO - INFO 01-06 17:31:22 config.py:2272] Downcasting torch.float32 to torch.bfloat16.
2025-01-06 17:31:30,425 - star_logger_test - INFO - INFO 01-06 17:31:30 config.py:510] This model supports multiple tasks: {'embed', 'generate', 'score', 'reward', 'classify'}. Defaulting to 'generate'.
2025-01-06 17:31:30,426 - star_logger_test - INFO - INFO 01-06 17:31:30 config.py:1310] Defaulting to use mp for distributed inference
2025-01-06 17:31:30,426 - star_logger_test - INFO - WARNING 01-06 17:31:30 cuda.py:98] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
2025-01-06 17:31:30,426 - star_logger_test - INFO - WARNING 01-06 17:31:30 config.py:642] Async output processing is not supported on the current platform type cuda.
2025-01-06 17:31:30,435 - star_logger_test - INFO - INFO 01-06 17:31:30 llm_engine.py:234] Initializing an LLM engine (v0.6.6.post1) with config: model='luezzka/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='luezzka/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1024, download_dir='/home/data/v.moskvoretskii/cache/', load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=luezzka/Llama-3.2-1B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[],"max_capture_size":0}, use_cached_outputs=False, 
2025-01-06 17:31:31,459 - star_logger_test - INFO - WARNING 01-06 17:31:31 multiproc_worker_utils.py:312] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
2025-01-06 17:31:31,517 - star_logger_test - INFO - INFO 01-06 17:31:31 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
2025-01-06 17:31:32,785 - star_logger_test - INFO - INFO 01-06 17:31:32 selector.py:120] Using Flash Attention backend.
2025-01-06 17:31:32,797 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=203052)[0;0m INFO 01-06 17:31:32 selector.py:120] Using Flash Attention backend.
2025-01-06 17:31:32,798 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=203052)[0;0m INFO 01-06 17:31:32 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
2025-01-06 17:31:33,531 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=203052)[0;0m INFO 01-06 17:31:33 utils.py:918] Found nccl from library libnccl.so.2
2025-01-06 17:31:33,531 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=203052)[0;0m INFO 01-06 17:31:33 pynccl.py:69] vLLM is using nccl==2.21.5
2025-01-06 17:31:33,531 - star_logger_test - INFO - INFO 01-06 17:31:33 utils.py:918] Found nccl from library libnccl.so.2
2025-01-06 17:31:33,532 - star_logger_test - INFO - INFO 01-06 17:31:33 pynccl.py:69] vLLM is using nccl==2.21.5
2025-01-06 17:31:33,795 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=203052)[0;0m INFO 01-06 17:31:33 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
2025-01-06 17:31:33,796 - star_logger_test - INFO - INFO 01-06 17:31:33 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
2025-01-06 17:31:33,815 - star_logger_test - INFO - INFO 01-06 17:31:33 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_1bff679a'), local_subscribe_port=52817, remote_subscribe_port=None)
2025-01-06 17:31:33,823 - star_logger_test - INFO - INFO 01-06 17:31:33 model_runner.py:1094] Starting to load model luezzka/Llama-3.2-1B-Instruct...
2025-01-06 17:31:33,824 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=203052)[0;0m INFO 01-06 17:31:33 model_runner.py:1094] Starting to load model luezzka/Llama-3.2-1B-Instruct...
2025-01-06 17:31:34,361 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=203052)[0;0m INFO 01-06 17:31:34 weight_utils.py:251] Using model weights format ['*.safetensors']
2025-01-06 17:31:34,371 - star_logger_test - INFO - INFO 01-06 17:31:34 weight_utils.py:251] Using model weights format ['*.safetensors']
2025-01-06 17:31:34,711 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=203052)[0;0m INFO 01-06 17:31:34 weight_utils.py:296] No model.safetensors.index.json found in remote.
2025-01-06 17:31:35,063 - star_logger_test - INFO - INFO 01-06 17:31:35 weight_utils.py:296] No model.safetensors.index.json found in remote.
2025-01-06 17:31:35,064 - star_logger_test - ERROR - 
2025-01-06 17:31:35,064 - star_logger_test - ERROR - Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-01-06 17:31:35,821 - star_logger_test - ERROR - 
2025-01-06 17:31:35,821 - star_logger_test - ERROR - Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.32it/s]
2025-01-06 17:31:35,822 - star_logger_test - ERROR - 
2025-01-06 17:31:35,822 - star_logger_test - ERROR - Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.32it/s]
2025-01-06 17:31:35,822 - star_logger_test - ERROR - 
2025-01-06 17:31:35,994 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=203052)[0;0m INFO 01-06 17:31:35 model_runner.py:1099] Loading model weights took 1.1666 GB
2025-01-06 17:31:36,153 - star_logger_test - INFO - INFO 01-06 17:31:36 model_runner.py:1099] Loading model weights took 1.1666 GB
2025-01-06 17:31:39,160 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=203052)[0;0m INFO 01-06 17:31:39 worker.py:241] Memory profiling takes 3.01 seconds
2025-01-06 17:31:39,160 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=203052)[0;0m INFO 01-06 17:31:39 worker.py:241] the current vLLM instance can use total_gpu_memory (44.38GiB) x gpu_memory_utilization (0.99) = 43.94GiB
2025-01-06 17:31:39,161 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=203052)[0;0m INFO 01-06 17:31:39 worker.py:241] model weights take 1.17GiB; non_torch_memory takes 0.47GiB; PyTorch activation peak memory takes 0.24GiB; the rest of the memory reserved for KV Cache is 42.06GiB.
2025-01-06 17:31:39,221 - star_logger_test - INFO - INFO 01-06 17:31:39 worker.py:241] Memory profiling takes 3.07 seconds
2025-01-06 17:31:39,221 - star_logger_test - INFO - INFO 01-06 17:31:39 worker.py:241] the current vLLM instance can use total_gpu_memory (44.38GiB) x gpu_memory_utilization (0.99) = 43.94GiB
2025-01-06 17:31:39,221 - star_logger_test - INFO - INFO 01-06 17:31:39 worker.py:241] model weights take 1.17GiB; non_torch_memory takes 0.47GiB; PyTorch activation peak memory takes 1.18GiB; the rest of the memory reserved for KV Cache is 41.12GiB.
2025-01-06 17:31:39,448 - star_logger_test - INFO - INFO 01-06 17:31:39 distributed_gpu_executor.py:57] # GPU blocks: 168428, # CPU blocks: 16384
2025-01-06 17:31:39,448 - star_logger_test - INFO - INFO 01-06 17:31:39 distributed_gpu_executor.py:61] Maximum concurrency for 1024 tokens per request: 2631.69x
2025-01-06 17:31:43,865 - star_logger_test - INFO - INFO 01-06 17:31:43 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 7.71 seconds
2025-01-06 17:31:48,089 - star_logger_test - INFO - [INFO] Starting generation at 1/2
2025-01-06 17:31:48,089 - star_logger_test - ERROR - 
2025-01-06 17:31:50,936 - star_logger_test - ERROR - Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
2025-01-06 17:31:53,503 - star_logger_test - ERROR - Processed prompts:   0%|          | 1/500 [00:02<23:40,  2.85s/it, est. speed input: 38.64 toks/s, output: 10.19 toks/s]
2025-01-06 17:31:54,352 - star_logger_test - ERROR - Processed prompts:   0%|          | 2/500 [00:05<22:15,  2.68s/it, est. speed input: 40.27 toks/s, output: 19.21 toks/s]
2025-01-06 17:31:54,810 - star_logger_test - ERROR - Processed prompts:   1%|          | 3/500 [00:06<15:17,  1.85s/it, est. speed input: 52.85 toks/s, output: 30.98 toks/s]
2025-01-06 17:31:55,284 - star_logger_test - ERROR - Processed prompts:   1%|          | 4/500 [00:06<10:43,  1.30s/it, est. speed input: 65.76 toks/s, output: 43.44 toks/s]
2025-01-06 17:31:56,255 - star_logger_test - ERROR - Processed prompts:   1%|          | 6/500 [00:07<06:03,  1.36it/s, est. speed input: 91.60 toks/s, output: 69.08 toks/s]
2025-01-06 17:31:56,497 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 8/500 [00:08<05:08,  1.59it/s, est. speed input: 108.63 toks/s, output: 88.91 toks/s]
2025-01-06 17:31:56,631 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 9/500 [00:08<04:23,  1.86it/s, est. speed input: 119.06 toks/s, output: 101.34 toks/s]
2025-01-06 17:31:56,774 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 10/500 [00:08<03:33,  2.30it/s, est. speed input: 129.96 toks/s, output: 114.74 toks/s]
2025-01-06 17:31:57,132 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 12/500 [00:08<02:18,  3.53it/s, est. speed input: 153.03 toks/s, output: 142.67 toks/s]
2025-01-06 17:31:57,386 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 13/500 [00:09<02:26,  3.33it/s, est. speed input: 159.14 toks/s, output: 152.06 toks/s]
2025-01-06 17:31:57,567 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 15/500 [00:09<01:52,  4.32it/s, est. speed input: 178.67 toks/s, output: 177.70 toks/s]
2025-01-06 17:31:57,694 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 16/500 [00:09<01:46,  4.53it/s, est. speed input: 187.27 toks/s, output: 189.38 toks/s]
2025-01-06 17:31:57,821 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 17/500 [00:09<01:35,  5.05it/s, est. speed input: 196.25 toks/s, output: 201.98 toks/s]
2025-01-06 17:31:58,016 - star_logger_test - ERROR - Processed prompts:   4%|▎         | 18/500 [00:09<01:26,  5.56it/s, est. speed input: 205.11 toks/s, output: 214.46 toks/s]
2025-01-06 17:31:58,209 - star_logger_test - ERROR - Processed prompts:   4%|▍         | 20/500 [00:09<01:09,  6.89it/s, est. speed input: 223.14 toks/s, output: 240.27 toks/s]
2025-01-06 17:31:58,336 - star_logger_test - ERROR - Processed prompts:   4%|▍         | 22/500 [00:10<01:00,  7.88it/s, est. speed input: 240.62 toks/s, output: 265.72 toks/s]
2025-01-06 17:31:58,464 - star_logger_test - ERROR - Processed prompts:   5%|▍         | 23/500 [00:10<01:00,  7.88it/s, est. speed input: 248.47 toks/s, output: 277.56 toks/s]
2025-01-06 17:31:58,708 - star_logger_test - ERROR - Processed prompts:   5%|▍         | 24/500 [00:10<01:00,  7.87it/s, est. speed input: 256.40 toks/s, output: 289.27 toks/s]
2025-01-06 17:31:58,851 - star_logger_test - ERROR - Processed prompts:   5%|▌         | 25/500 [00:10<01:14,  6.40it/s, est. speed input: 260.77 toks/s, output: 297.78 toks/s]
2025-01-06 17:31:59,011 - star_logger_test - ERROR - Processed prompts:   6%|▌         | 29/500 [00:10<00:40, 11.69it/s, est. speed input: 298.08 toks/s, output: 353.93 toks/s]
2025-01-06 17:31:59,154 - star_logger_test - ERROR - Processed prompts:   7%|▋         | 33/500 [00:10<00:30, 15.45it/s, est. speed input: 334.20 toks/s, output: 408.73 toks/s]
2025-01-06 17:31:59,477 - star_logger_test - ERROR - Processed prompts:   7%|▋         | 37/500 [00:11<00:24, 18.77it/s, est. speed input: 369.56 toks/s, output: 463.46 toks/s]
2025-01-06 17:31:59,758 - star_logger_test - ERROR - Processed prompts:   8%|▊         | 40/500 [00:11<00:31, 14.40it/s, est. speed input: 388.05 toks/s, output: 495.27 toks/s]
2025-01-06 17:31:59,958 - star_logger_test - ERROR - Processed prompts:   9%|▉         | 45/500 [00:11<00:29, 15.63it/s, est. speed input: 425.83 toks/s, output: 557.71 toks/s]
2025-01-06 17:32:00,091 - star_logger_test - ERROR - Processed prompts:   9%|▉         | 47/500 [00:11<00:32, 14.12it/s, est. speed input: 437.29 toks/s, output: 578.34 toks/s]
2025-01-06 17:32:00,223 - star_logger_test - ERROR - Processed prompts:  10%|█         | 50/500 [00:12<00:28, 15.83it/s, est. speed input: 459.84 toks/s, output: 616.82 toks/s]
2025-01-06 17:32:00,428 - star_logger_test - ERROR - Processed prompts:  10%|█         | 52/500 [00:12<00:28, 15.69it/s, est. speed input: 473.48 toks/s, output: 640.12 toks/s]
2025-01-06 17:32:00,569 - star_logger_test - ERROR - Processed prompts:  11%|█         | 56/500 [00:12<00:26, 16.95it/s, est. speed input: 501.82 toks/s, output: 689.28 toks/s]
2025-01-06 17:32:00,710 - star_logger_test - ERROR - Processed prompts:  12%|█▏        | 58/500 [00:12<00:27, 16.26it/s, est. speed input: 513.77 toks/s, output: 711.52 toks/s]
2025-01-06 17:32:00,983 - star_logger_test - ERROR - Processed prompts:  12%|█▏        | 62/500 [00:12<00:22, 19.42it/s, est. speed input: 544.10 toks/s, output: 763.50 toks/s]
2025-01-06 17:32:01,210 - star_logger_test - ERROR - Processed prompts:  13%|█▎        | 65/500 [00:12<00:27, 15.90it/s, est. speed input: 558.34 toks/s, output: 792.18 toks/s]
2025-01-06 17:32:01,355 - star_logger_test - ERROR - Processed prompts:  14%|█▎        | 68/500 [00:13<00:28, 15.00it/s, est. speed input: 573.59 toks/s, output: 823.19 toks/s]
2025-01-06 17:32:01,621 - star_logger_test - ERROR - Processed prompts:  14%|█▍        | 70/500 [00:13<00:29, 14.72it/s, est. speed input: 584.51 toks/s, output: 844.19 toks/s]
2025-01-06 17:32:01,783 - star_logger_test - ERROR - Processed prompts:  14%|█▍        | 72/500 [00:13<00:35, 12.00it/s, est. speed input: 589.13 toks/s, output: 857.32 toks/s]
2025-01-06 17:32:01,921 - star_logger_test - ERROR - Processed prompts:  15%|█▍        | 74/500 [00:13<00:35, 12.09it/s, est. speed input: 598.53 toks/s, output: 876.91 toks/s]
2025-01-06 17:32:02,061 - star_logger_test - ERROR - Processed prompts:  15%|█▌        | 76/500 [00:13<00:33, 12.64it/s, est. speed input: 608.60 toks/s, output: 897.78 toks/s]
2025-01-06 17:32:02,274 - star_logger_test - ERROR - Processed prompts:  16%|█▌        | 79/500 [00:13<00:28, 14.85it/s, est. speed input: 625.98 toks/s, output: 933.17 toks/s]
2025-01-06 17:32:02,426 - star_logger_test - ERROR - Processed prompts:  16%|█▌        | 81/500 [00:14<00:32, 12.92it/s, est. speed input: 632.01 toks/s, output: 948.76 toks/s]
2025-01-06 17:32:02,583 - star_logger_test - ERROR - Processed prompts:  17%|█▋        | 83/500 [00:14<00:32, 12.98it/s, est. speed input: 640.79 toks/s, output: 968.33 toks/s]
2025-01-06 17:32:02,862 - star_logger_test - ERROR - Processed prompts:  18%|█▊        | 89/500 [00:14<00:20, 20.07it/s, est. speed input: 679.32 toks/s, output: 1046.30 toks/s]
2025-01-06 17:32:03,218 - star_logger_test - ERROR - Processed prompts:  18%|█▊        | 92/500 [00:14<00:25, 16.19it/s, est. speed input: 688.90 toks/s, output: 1070.61 toks/s]
2025-01-06 17:32:03,372 - star_logger_test - ERROR - Processed prompts:  19%|█▉        | 94/500 [00:15<00:34, 11.62it/s, est. speed input: 687.01 toks/s, output: 1074.80 toks/s]
2025-01-06 17:32:03,521 - star_logger_test - ERROR - Processed prompts:  19%|█▉        | 96/500 [00:15<00:33, 11.91it/s, est. speed input: 694.23 toks/s, output: 1093.49 toks/s]
2025-01-06 17:32:03,666 - star_logger_test - ERROR - Processed prompts:  20%|█▉        | 99/500 [00:15<00:29, 13.77it/s, est. speed input: 708.99 toks/s, output: 1118.99 toks/s]
2025-01-06 17:32:03,868 - star_logger_test - ERROR - Processed prompts:  20%|██        | 102/500 [00:15<00:25, 15.42it/s, est. speed input: 723.63 toks/s, output: 1152.66 toks/s]
2025-01-06 17:32:04,070 - star_logger_test - ERROR - Processed prompts:  21%|██        | 105/500 [00:15<00:25, 15.24it/s, est. speed input: 735.16 toks/s, output: 1181.95 toks/s]
2025-01-06 17:32:04,213 - star_logger_test - ERROR - Processed prompts:  22%|██▏       | 109/500 [00:15<00:23, 16.67it/s, est. speed input: 753.57 toks/s, output: 1225.56 toks/s]
2025-01-06 17:32:04,413 - star_logger_test - ERROR - Processed prompts:  23%|██▎       | 113/500 [00:16<00:19, 19.40it/s, est. speed input: 774.18 toks/s, output: 1273.42 toks/s]
2025-01-06 17:32:04,554 - star_logger_test - ERROR - Processed prompts:  23%|██▎       | 116/500 [00:16<00:21, 17.98it/s, est. speed input: 784.93 toks/s, output: 1301.90 toks/s]
2025-01-06 17:32:04,746 - star_logger_test - ERROR - Processed prompts:  24%|██▍       | 120/500 [00:16<00:18, 20.56it/s, est. speed input: 805.00 toks/s, output: 1349.63 toks/s]
2025-01-06 17:32:04,883 - star_logger_test - ERROR - Processed prompts:  25%|██▍       | 123/500 [00:16<00:19, 18.96it/s, est. speed input: 815.78 toks/s, output: 1378.33 toks/s]
2025-01-06 17:32:05,131 - star_logger_test - ERROR - Processed prompts:  25%|██▌       | 125/500 [00:16<00:21, 17.85it/s, est. speed input: 822.19 toks/s, output: 1396.50 toks/s]
2025-01-06 17:32:05,311 - star_logger_test - ERROR - Processed prompts:  26%|██▌       | 128/500 [00:17<00:23, 15.61it/s, est. speed input: 829.66 toks/s, output: 1420.21 toks/s]
2025-01-06 17:32:06,677 - star_logger_test - ERROR - Processed prompts:  26%|██▌       | 130/500 [00:17<00:25, 14.30it/s, est. speed input: 833.58 toks/s, output: 1434.78 toks/s]
2025-01-06 17:32:08,160 - star_logger_test - ERROR - Processed prompts:  52%|█████▏    | 258/500 [00:18<00:03, 74.48it/s, est. speed input: 1534.81 toks/s, output: 3086.57 toks/s]
2025-01-06 17:32:08,703 - star_logger_test - ERROR - Processed prompts:  52%|█████▏    | 262/500 [00:20<00:06, 35.70it/s, est. speed input: 1443.45 toks/s, output: 2894.17 toks/s]
2025-01-06 17:32:08,807 - star_logger_test - ERROR - Processed prompts:  53%|█████▎    | 265/500 [00:20<00:08, 29.04it/s, est. speed input: 1421.59 toks/s, output: 2838.97 toks/s]
2025-01-06 17:32:09,773 - star_logger_test - ERROR - Processed prompts:  54%|█████▎    | 268/500 [00:20<00:07, 29.04it/s, est. speed input: 1430.31 toks/s, output: 2841.99 toks/s]
2025-01-06 17:32:09,880 - star_logger_test - ERROR - Processed prompts:  54%|█████▍    | 271/500 [00:21<00:12, 17.89it/s, est. speed input: 1381.87 toks/s, output: 2743.72 toks/s]
2025-01-06 17:32:10,611 - star_logger_test - ERROR - Processed prompts:  55%|█████▍    | 273/500 [00:21<00:12, 17.94it/s, est. speed input: 1385.27 toks/s, output: 2744.38 toks/s]
2025-01-06 17:32:10,714 - star_logger_test - ERROR - Processed prompts:  55%|█████▌    | 275/500 [00:22<00:18, 12.11it/s, est. speed input: 1350.00 toks/s, output: 2675.35 toks/s]
2025-01-06 17:32:10,986 - star_logger_test - ERROR - Processed prompts:  55%|█████▌    | 277/500 [00:22<00:17, 12.63it/s, est. speed input: 1353.70 toks/s, output: 2680.71 toks/s]
2025-01-06 17:32:11,145 - star_logger_test - ERROR - Processed prompts:  56%|█████▌    | 279/500 [00:22<00:19, 11.51it/s, est. speed input: 1347.10 toks/s, output: 2669.61 toks/s]
2025-01-06 17:32:11,366 - star_logger_test - ERROR - Processed prompts:  56%|█████▋    | 282/500 [00:23<00:17, 12.62it/s, est. speed input: 1352.22 toks/s, output: 2668.74 toks/s]
2025-01-06 17:32:11,567 - star_logger_test - ERROR - Processed prompts:  57%|█████▋    | 284/500 [00:23<00:18, 11.79it/s, est. speed input: 1348.86 toks/s, output: 2660.94 toks/s]
2025-01-06 17:32:11,777 - star_logger_test - ERROR - Processed prompts:  58%|█████▊    | 288/500 [00:23<00:15, 13.67it/s, est. speed input: 1356.15 toks/s, output: 2672.35 toks/s]
2025-01-06 17:32:11,884 - star_logger_test - ERROR - Processed prompts:  58%|█████▊    | 291/500 [00:23<00:15, 13.82it/s, est. speed input: 1358.14 toks/s, output: 2671.35 toks/s]
2025-01-06 17:32:12,034 - star_logger_test - ERROR - Processed prompts:  59%|█████▊    | 293/500 [00:23<00:14, 14.59it/s, est. speed input: 1361.23 toks/s, output: 2675.31 toks/s]
2025-01-06 17:32:12,351 - star_logger_test - ERROR - Processed prompts:  59%|█████▉    | 295/500 [00:23<00:14, 14.28it/s, est. speed input: 1361.80 toks/s, output: 2668.38 toks/s]
2025-01-06 17:32:12,595 - star_logger_test - ERROR - Processed prompts:  59%|█████▉    | 297/500 [00:24<00:18, 10.94it/s, est. speed input: 1353.34 toks/s, output: 2644.31 toks/s]
2025-01-06 17:32:12,696 - star_logger_test - ERROR - Processed prompts:  60%|█████▉    | 299/500 [00:24<00:19, 10.07it/s, est. speed input: 1348.77 toks/s, output: 2638.82 toks/s]
2025-01-06 17:32:12,803 - star_logger_test - ERROR - Processed prompts:  61%|██████    | 303/500 [00:24<00:13, 14.73it/s, est. speed input: 1361.23 toks/s, output: 2655.57 toks/s]
2025-01-06 17:32:12,949 - star_logger_test - ERROR - Processed prompts:  61%|██████    | 305/500 [00:24<00:12, 15.48it/s, est. speed input: 1364.34 toks/s, output: 2655.19 toks/s]
2025-01-06 17:32:13,092 - star_logger_test - ERROR - Processed prompts:  62%|██████▏   | 309/500 [00:24<00:10, 18.73it/s, est. speed input: 1374.11 toks/s, output: 2668.93 toks/s]
2025-01-06 17:32:13,277 - star_logger_test - ERROR - Processed prompts:  63%|██████▎   | 313/500 [00:25<00:08, 21.28it/s, est. speed input: 1383.73 toks/s, output: 2686.38 toks/s]
2025-01-06 17:32:13,415 - star_logger_test - ERROR - Processed prompts:  63%|██████▎   | 316/500 [00:25<00:09, 19.56it/s, est. speed input: 1386.97 toks/s, output: 2691.24 toks/s]
2025-01-06 17:32:13,599 - star_logger_test - ERROR - Processed prompts:  64%|██████▍   | 321/500 [00:25<00:07, 23.98it/s, est. speed input: 1401.14 toks/s, output: 2715.05 toks/s]
2025-01-06 17:32:13,836 - star_logger_test - ERROR - Processed prompts:  65%|██████▍   | 324/500 [00:25<00:08, 21.40it/s, est. speed input: 1403.99 toks/s, output: 2714.14 toks/s]
2025-01-06 17:32:14,059 - star_logger_test - ERROR - Processed prompts:  66%|██████▌   | 328/500 [00:25<00:08, 19.69it/s, est. speed input: 1408.22 toks/s, output: 2720.20 toks/s]
2025-01-06 17:32:14,186 - star_logger_test - ERROR - Processed prompts:  66%|██████▌   | 331/500 [00:25<00:09, 17.57it/s, est. speed input: 1408.98 toks/s, output: 2722.55 toks/s]
2025-01-06 17:32:14,319 - star_logger_test - ERROR - Processed prompts:  67%|██████▋   | 334/500 [00:26<00:08, 18.87it/s, est. speed input: 1414.87 toks/s, output: 2735.59 toks/s]
2025-01-06 17:32:14,452 - star_logger_test - ERROR - Processed prompts:  67%|██████▋   | 337/500 [00:26<00:08, 19.79it/s, est. speed input: 1420.34 toks/s, output: 2750.06 toks/s]
2025-01-06 17:32:14,578 - star_logger_test - ERROR - Processed prompts:  68%|██████▊   | 340/500 [00:26<00:07, 20.48it/s, est. speed input: 1425.51 toks/s, output: 2760.24 toks/s]
2025-01-06 17:32:14,699 - star_logger_test - ERROR - Processed prompts:  69%|██████▉   | 346/500 [00:26<00:05, 27.53it/s, est. speed input: 1443.77 toks/s, output: 2801.36 toks/s]
2025-01-06 17:32:14,822 - star_logger_test - ERROR - Processed prompts:  70%|███████   | 351/500 [00:26<00:04, 31.19it/s, est. speed input: 1458.25 toks/s, output: 2829.57 toks/s]
2025-01-06 17:32:14,952 - star_logger_test - ERROR - Processed prompts:  71%|███████   | 355/500 [00:26<00:04, 31.50it/s, est. speed input: 1468.07 toks/s, output: 2851.26 toks/s]
2025-01-06 17:32:15,067 - star_logger_test - ERROR - Processed prompts:  73%|███████▎  | 363/500 [00:26<00:03, 40.34it/s, est. speed input: 1493.69 toks/s, output: 2891.60 toks/s]
2025-01-06 17:32:15,197 - star_logger_test - ERROR - Processed prompts:  74%|███████▍  | 370/500 [00:26<00:02, 45.93it/s, est. speed input: 1515.88 toks/s, output: 2935.56 toks/s]
2025-01-06 17:32:15,353 - star_logger_test - ERROR - Processed prompts:  76%|███████▌  | 381/500 [00:27<00:02, 57.64it/s, est. speed input: 1553.25 toks/s, output: 3007.49 toks/s]
2025-01-06 17:32:15,538 - star_logger_test - ERROR - Processed prompts:  77%|███████▋  | 387/500 [00:27<00:02, 51.07it/s, est. speed input: 1568.35 toks/s, output: 3034.34 toks/s]
2025-01-06 17:32:15,660 - star_logger_test - ERROR - Processed prompts:  79%|███████▊  | 393/500 [00:27<00:02, 44.24it/s, est. speed input: 1582.02 toks/s, output: 3061.27 toks/s]
2025-01-06 17:32:15,777 - star_logger_test - ERROR - Processed prompts:  80%|███████▉  | 399/500 [00:27<00:02, 45.55it/s, est. speed input: 1599.05 toks/s, output: 3098.58 toks/s]
2025-01-06 17:32:15,923 - star_logger_test - ERROR - Processed prompts:  81%|████████  | 405/500 [00:27<00:02, 47.03it/s, est. speed input: 1616.63 toks/s, output: 3134.41 toks/s]
2025-01-06 17:32:16,037 - star_logger_test - ERROR - Processed prompts:  82%|████████▏ | 410/500 [00:27<00:02, 43.01it/s, est. speed input: 1628.15 toks/s, output: 3160.87 toks/s]
2025-01-06 17:32:16,174 - star_logger_test - ERROR - Processed prompts:  83%|████████▎ | 416/500 [00:27<00:01, 45.44it/s, est. speed input: 1645.29 toks/s, output: 3200.30 toks/s]
2025-01-06 17:32:16,334 - star_logger_test - ERROR - Processed prompts:  84%|████████▍ | 421/500 [00:28<00:01, 42.71it/s, est. speed input: 1656.76 toks/s, output: 3226.11 toks/s]
2025-01-06 17:32:16,473 - star_logger_test - ERROR - Processed prompts:  85%|████████▌ | 426/500 [00:28<00:01, 38.80it/s, est. speed input: 1667.31 toks/s, output: 3251.10 toks/s]
2025-01-06 17:32:16,584 - star_logger_test - ERROR - Processed prompts:  86%|████████▌ | 431/500 [00:28<00:01, 37.96it/s, est. speed input: 1678.52 toks/s, output: 3279.18 toks/s]
2025-01-06 17:32:16,697 - star_logger_test - ERROR - Processed prompts:  88%|████████▊ | 438/500 [00:28<00:01, 44.34it/s, est. speed input: 1699.30 toks/s, output: 3325.74 toks/s]
2025-01-06 17:32:16,872 - star_logger_test - ERROR - Processed prompts:  89%|████████▉ | 445/500 [00:28<00:01, 49.03it/s, est. speed input: 1719.76 toks/s, output: 3372.64 toks/s]
2025-01-06 17:32:17,012 - star_logger_test - ERROR - Processed prompts:  90%|█████████ | 451/500 [00:28<00:01, 43.56it/s, est. speed input: 1732.32 toks/s, output: 3404.23 toks/s]
2025-01-06 17:32:17,037 - star_logger_test - ERROR - Processed prompts:  91%|█████████ | 456/500 [00:28<00:01, 41.18it/s, est. speed input: 1743.31 toks/s, output: 3431.64 toks/s]
2025-01-06 17:32:17,037 - star_logger_test - ERROR - Processed prompts: 100%|██████████| 500/500 [00:28<00:00, 17.27it/s, est. speed input: 1909.69 toks/s, output: 3817.80 toks/s]
2025-01-06 17:32:17,581 - star_logger_test - INFO - [INFO] Starting rationalization at 1/2
2025-01-06 17:32:17,582 - star_logger_test - ERROR - 
2025-01-06 17:32:22,692 - star_logger_test - ERROR - Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
2025-01-06 17:32:23,604 - star_logger_test - ERROR - Processed prompts:   0%|          | 1/500 [00:05<42:30,  5.11s/it, est. speed input: 28.96 toks/s, output: 13.89 toks/s]
2025-01-06 17:32:23,839 - star_logger_test - ERROR - Processed prompts:   0%|          | 2/500 [00:06<21:55,  2.64s/it, est. speed input: 48.65 toks/s, output: 26.24 toks/s]
2025-01-06 17:32:24,028 - star_logger_test - ERROR - Processed prompts:   1%|          | 3/500 [00:06<12:46,  1.54s/it, est. speed input: 70.32 toks/s, output: 39.79 toks/s]
2025-01-06 17:32:24,439 - star_logger_test - ERROR - Processed prompts:   1%|          | 6/500 [00:06<04:38,  1.78it/s, est. speed input: 136.37 toks/s, output: 81.45 toks/s]
2025-01-06 17:32:24,566 - star_logger_test - ERROR - Processed prompts:   1%|▏         | 7/500 [00:06<04:19,  1.90it/s, est. speed input: 149.63 toks/s, output: 91.29 toks/s]
2025-01-06 17:32:24,882 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 8/500 [00:06<03:28,  2.35it/s, est. speed input: 168.10 toks/s, output: 104.38 toks/s]
2025-01-06 17:32:25,241 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 12/500 [00:07<01:47,  4.55it/s, est. speed input: 240.96 toks/s, output: 157.12 toks/s]
2025-01-06 17:32:25,442 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 14/500 [00:07<01:40,  4.81it/s, est. speed input: 268.19 toks/s, output: 178.75 toks/s]
2025-01-06 17:32:25,751 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 16/500 [00:07<01:25,  5.69it/s, est. speed input: 297.83 toks/s, output: 203.69 toks/s]
2025-01-06 17:32:26,014 - star_logger_test - ERROR - Processed prompts:   4%|▎         | 18/500 [00:08<01:21,  5.90it/s, est. speed input: 322.05 toks/s, output: 225.23 toks/s]
2025-01-06 17:32:26,225 - star_logger_test - ERROR - Processed prompts:   4%|▍         | 19/500 [00:08<01:29,  5.38it/s, est. speed input: 329.23 toks/s, output: 233.17 toks/s]
2025-01-06 17:32:26,548 - star_logger_test - ERROR - Processed prompts:   4%|▍         | 21/500 [00:08<01:16,  6.29it/s, est. speed input: 354.61 toks/s, output: 257.08 toks/s]
2025-01-06 17:32:26,680 - star_logger_test - ERROR - Processed prompts:   5%|▍         | 23/500 [00:08<01:16,  6.26it/s, est. speed input: 374.42 toks/s, output: 277.16 toks/s]
2025-01-06 17:32:26,873 - star_logger_test - ERROR - Processed prompts:   5%|▍         | 24/500 [00:09<01:13,  6.47it/s, est. speed input: 384.68 toks/s, output: 288.07 toks/s]
2025-01-06 17:32:27,134 - star_logger_test - ERROR - Processed prompts:   5%|▌         | 26/500 [00:09<01:03,  7.45it/s, est. speed input: 408.68 toks/s, output: 311.71 toks/s]
2025-01-06 17:32:27,273 - star_logger_test - ERROR - Processed prompts:   6%|▌         | 28/500 [00:09<01:02,  7.52it/s, est. speed input: 427.23 toks/s, output: 332.80 toks/s]
2025-01-06 17:32:27,462 - star_logger_test - ERROR - Processed prompts:   6%|▌         | 30/500 [00:09<00:52,  8.88it/s, est. speed input: 451.02 toks/s, output: 357.84 toks/s]
2025-01-06 17:32:27,591 - star_logger_test - ERROR - Processed prompts:   6%|▌         | 31/500 [00:09<00:59,  7.88it/s, est. speed input: 457.09 toks/s, output: 365.99 toks/s]
2025-01-06 17:32:27,735 - star_logger_test - ERROR - Processed prompts:   7%|▋         | 33/500 [00:10<00:49,  9.51it/s, est. speed input: 480.85 toks/s, output: 391.03 toks/s]
2025-01-06 17:32:28,250 - star_logger_test - ERROR - Processed prompts:   7%|▋         | 36/500 [00:10<00:37, 12.38it/s, est. speed input: 516.48 toks/s, output: 430.20 toks/s]
2025-01-06 17:32:28,445 - star_logger_test - ERROR - Processed prompts:   8%|▊         | 38/500 [00:10<01:00,  7.58it/s, est. speed input: 518.44 toks/s, output: 438.86 toks/s]
2025-01-06 17:32:28,660 - star_logger_test - ERROR - Processed prompts:   8%|▊         | 40/500 [00:10<00:56,  8.21it/s, est. speed input: 537.03 toks/s, output: 460.99 toks/s]
2025-01-06 17:32:28,866 - star_logger_test - ERROR - Processed prompts:   8%|▊         | 42/500 [00:11<00:53,  8.50it/s, est. speed input: 552.96 toks/s, output: 481.83 toks/s]
2025-01-06 17:32:29,127 - star_logger_test - ERROR - Processed prompts:   9%|▉         | 45/500 [00:11<00:44, 10.14it/s, est. speed input: 581.10 toks/s, output: 517.46 toks/s]
2025-01-06 17:32:29,315 - star_logger_test - ERROR - Processed prompts:   9%|▉         | 47/500 [00:11<00:48,  9.32it/s, est. speed input: 593.48 toks/s, output: 535.62 toks/s]
2025-01-06 17:32:29,457 - star_logger_test - ERROR - Processed prompts:  10%|▉         | 49/500 [00:11<00:46,  9.66it/s, est. speed input: 608.30 toks/s, output: 557.07 toks/s]
2025-01-06 17:32:29,709 - star_logger_test - ERROR - Processed prompts:  10%|█         | 51/500 [00:11<00:42, 10.61it/s, est. speed input: 624.93 toks/s, output: 580.29 toks/s]
2025-01-06 17:32:29,965 - star_logger_test - ERROR - Processed prompts:  11%|█         | 53/500 [00:12<00:46,  9.67it/s, est. speed input: 635.93 toks/s, output: 597.92 toks/s]
2025-01-06 17:32:30,104 - star_logger_test - ERROR - Processed prompts:  11%|█▏        | 57/500 [00:12<00:37, 11.68it/s, est. speed input: 670.92 toks/s, output: 644.83 toks/s]
2025-01-06 17:32:30,232 - star_logger_test - ERROR - Processed prompts:  12%|█▏        | 59/500 [00:12<00:36, 12.24it/s, est. speed input: 686.39 toks/s, output: 667.63 toks/s]
2025-01-06 17:32:30,373 - star_logger_test - ERROR - Processed prompts:  12%|█▏        | 61/500 [00:12<00:33, 12.97it/s, est. speed input: 702.76 toks/s, output: 690.74 toks/s]
2025-01-06 17:32:31,106 - star_logger_test - ERROR - Processed prompts:  13%|█▎        | 63/500 [00:12<00:32, 13.28it/s, est. speed input: 717.93 toks/s, output: 713.08 toks/s]
2025-01-06 17:32:31,323 - star_logger_test - ERROR - Processed prompts:  14%|█▍        | 69/500 [00:13<00:43,  9.96it/s, est. speed input: 744.25 toks/s, output: 760.22 toks/s]
2025-01-06 17:32:31,485 - star_logger_test - ERROR - Processed prompts:  14%|█▍        | 72/500 [00:13<00:39, 10.79it/s, est. speed input: 764.44 toks/s, output: 791.14 toks/s]
2025-01-06 17:32:31,630 - star_logger_test - ERROR - Processed prompts:  15%|█▌        | 77/500 [00:13<00:29, 14.55it/s, est. speed input: 807.43 toks/s, output: 853.46 toks/s]
2025-01-06 17:32:31,774 - star_logger_test - ERROR - Processed prompts:  16%|█▌        | 79/500 [00:14<00:29, 14.41it/s, est. speed input: 819.71 toks/s, output: 873.38 toks/s]
2025-01-06 17:32:32,068 - star_logger_test - ERROR - Processed prompts:  16%|█▌        | 81/500 [00:14<00:29, 14.28it/s, est. speed input: 831.70 toks/s, output: 893.14 toks/s]
2025-01-06 17:32:32,211 - star_logger_test - ERROR - Processed prompts:  17%|█▋        | 87/500 [00:14<00:24, 16.66it/s, est. speed input: 875.28 toks/s, output: 950.66 toks/s]
2025-01-06 17:32:32,365 - star_logger_test - ERROR - Processed prompts:  18%|█▊        | 89/500 [00:14<00:25, 16.07it/s, est. speed input: 886.63 toks/s, output: 969.95 toks/s]
2025-01-06 17:32:32,510 - star_logger_test - ERROR - Processed prompts:  18%|█▊        | 91/500 [00:14<00:26, 15.33it/s, est. speed input: 897.45 toks/s, output: 988.50 toks/s]
2025-01-06 17:32:32,659 - star_logger_test - ERROR - Processed prompts:  19%|█▉        | 95/500 [00:14<00:22, 18.35it/s, est. speed input: 928.02 toks/s, output: 1035.93 toks/s]
2025-01-06 17:32:32,867 - star_logger_test - ERROR - Processed prompts:  20%|█▉        | 99/500 [00:15<00:19, 20.62it/s, est. speed input: 957.65 toks/s, output: 1074.25 toks/s]
2025-01-06 17:32:33,030 - star_logger_test - ERROR - Processed prompts:  21%|██        | 103/500 [00:15<00:19, 20.14it/s, est. speed input: 982.76 toks/s, output: 1116.48 toks/s]
2025-01-06 17:32:33,369 - star_logger_test - ERROR - Processed prompts:  21%|██▏       | 107/500 [00:15<00:18, 21.37it/s, est. speed input: 1009.28 toks/s, output: 1161.66 toks/s]
2025-01-06 17:32:33,746 - star_logger_test - ERROR - Processed prompts:  22%|██▏       | 110/500 [00:15<00:24, 15.70it/s, est. speed input: 1015.20 toks/s, output: 1179.39 toks/s]
2025-01-06 17:32:33,883 - star_logger_test - ERROR - Processed prompts:  22%|██▏       | 112/500 [00:16<00:34, 11.33it/s, est. speed input: 1009.49 toks/s, output: 1180.42 toks/s]
2025-01-06 17:32:34,076 - star_logger_test - ERROR - Processed prompts:  23%|██▎       | 115/500 [00:16<00:29, 13.23it/s, est. speed input: 1028.39 toks/s, output: 1213.40 toks/s]
2025-01-06 17:32:34,330 - star_logger_test - ERROR - Processed prompts:  24%|██▎       | 118/500 [00:16<00:27, 13.84it/s, est. speed input: 1042.78 toks/s, output: 1242.00 toks/s]
2025-01-06 17:32:34,468 - star_logger_test - ERROR - Processed prompts:  24%|██▍       | 122/500 [00:16<00:26, 14.47it/s, est. speed input: 1062.66 toks/s, output: 1280.16 toks/s]
2025-01-06 17:32:34,717 - star_logger_test - ERROR - Processed prompts:  25%|██▍       | 124/500 [00:16<00:25, 14.48it/s, est. speed input: 1070.98 toks/s, output: 1298.43 toks/s]
2025-01-06 17:32:34,852 - star_logger_test - ERROR - Processed prompts:  25%|██▌       | 126/500 [00:17<00:30, 12.26it/s, est. speed input: 1072.25 toks/s, output: 1308.26 toks/s]
2025-01-06 17:32:35,058 - star_logger_test - ERROR - Processed prompts:  26%|██▌       | 128/500 [00:17<00:29, 12.80it/s, est. speed input: 1080.91 toks/s, output: 1326.83 toks/s]
2025-01-06 17:32:35,253 - star_logger_test - ERROR - Processed prompts:  26%|██▌       | 131/500 [00:17<00:27, 13.36it/s, est. speed input: 1092.94 toks/s, output: 1354.22 toks/s]
2025-01-06 17:32:36,710 - star_logger_test - ERROR - Processed prompts:  27%|██▋       | 134/500 [00:17<00:26, 13.95it/s, est. speed input: 1106.07 toks/s, output: 1382.28 toks/s]
2025-01-06 17:32:37,040 - star_logger_test - ERROR - Processed prompts:  52%|█████▏    | 259/500 [00:19<00:03, 68.67it/s, est. speed input: 1986.13 toks/s, output: 2942.90 toks/s]
2025-01-06 17:32:38,141 - star_logger_test - ERROR - Processed prompts:  53%|█████▎    | 263/500 [00:19<00:04, 57.48it/s, est. speed input: 1982.73 toks/s, output: 2920.44 toks/s]
2025-01-06 17:32:38,620 - star_logger_test - ERROR - Processed prompts:  53%|█████▎    | 266/500 [00:20<00:07, 30.91it/s, est. speed input: 1897.83 toks/s, output: 2780.94 toks/s]
2025-01-06 17:32:38,733 - star_logger_test - ERROR - Processed prompts:  54%|█████▍    | 269/500 [00:21<00:09, 25.21it/s, est. speed input: 1875.54 toks/s, output: 2746.58 toks/s]
2025-01-06 17:32:38,955 - star_logger_test - ERROR - Processed prompts:  54%|█████▍    | 271/500 [00:21<00:09, 24.66it/s, est. speed input: 1879.44 toks/s, output: 2751.12 toks/s]
2025-01-06 17:32:39,125 - star_logger_test - ERROR - Processed prompts:  55%|█████▍    | 274/500 [00:21<00:09, 22.78it/s, est. speed input: 1880.57 toks/s, output: 2749.61 toks/s]
2025-01-06 17:32:39,538 - star_logger_test - ERROR - Processed prompts:  55%|█████▌    | 276/500 [00:21<00:10, 21.06it/s, est. speed input: 1879.44 toks/s, output: 2744.96 toks/s]
2025-01-06 17:32:40,365 - star_logger_test - ERROR - Processed prompts:  56%|█████▌    | 278/500 [00:21<00:14, 15.36it/s, est. speed input: 1857.40 toks/s, output: 2710.04 toks/s]
2025-01-06 17:32:40,519 - star_logger_test - ERROR - Processed prompts:  56%|█████▌    | 280/500 [00:22<00:24,  8.88it/s, est. speed input: 1803.17 toks/s, output: 2626.77 toks/s]
2025-01-06 17:32:40,721 - star_logger_test - ERROR - Processed prompts:  56%|█████▌    | 281/500 [00:22<00:25,  8.59it/s, est. speed input: 1797.50 toks/s, output: 2615.24 toks/s]
2025-01-06 17:32:40,981 - star_logger_test - ERROR - Processed prompts:  57%|█████▋    | 285/500 [00:23<00:20, 10.62it/s, est. speed input: 1807.10 toks/s, output: 2631.97 toks/s]
2025-01-06 17:32:41,142 - star_logger_test - ERROR - Processed prompts:  58%|█████▊    | 288/500 [00:23<00:19, 10.85it/s, est. speed input: 1805.74 toks/s, output: 2625.58 toks/s]
2025-01-06 17:32:41,251 - star_logger_test - ERROR - Processed prompts:  58%|█████▊    | 291/500 [00:23<00:17, 12.25it/s, est. speed input: 1812.36 toks/s, output: 2627.83 toks/s]
2025-01-06 17:32:41,361 - star_logger_test - ERROR - Processed prompts:  59%|█████▉    | 294/500 [00:23<00:14, 14.53it/s, est. speed input: 1822.74 toks/s, output: 2636.82 toks/s]
2025-01-06 17:32:41,470 - star_logger_test - ERROR - Processed prompts:  59%|█████▉    | 296/500 [00:23<00:13, 15.18it/s, est. speed input: 1826.81 toks/s, output: 2640.59 toks/s]
2025-01-06 17:32:41,722 - star_logger_test - ERROR - Processed prompts:  60%|█████▉    | 298/500 [00:23<00:12, 15.82it/s, est. speed input: 1830.85 toks/s, output: 2646.41 toks/s]
2025-01-06 17:32:41,913 - star_logger_test - ERROR - Processed prompts:  60%|██████    | 300/500 [00:24<00:15, 12.68it/s, est. speed input: 1823.87 toks/s, output: 2631.00 toks/s]
2025-01-06 17:32:42,055 - star_logger_test - ERROR - Processed prompts:  61%|██████    | 303/500 [00:24<00:14, 13.59it/s, est. speed input: 1827.93 toks/s, output: 2638.30 toks/s]
2025-01-06 17:32:42,332 - star_logger_test - ERROR - Processed prompts:  61%|██████    | 306/500 [00:24<00:12, 15.42it/s, est. speed input: 1835.10 toks/s, output: 2649.10 toks/s]
2025-01-06 17:32:42,469 - star_logger_test - ERROR - Processed prompts:  62%|██████▏   | 310/500 [00:24<00:12, 15.03it/s, est. speed input: 1838.61 toks/s, output: 2647.18 toks/s]
2025-01-06 17:32:42,655 - star_logger_test - ERROR - Processed prompts:  62%|██████▏   | 312/500 [00:24<00:12, 14.91it/s, est. speed input: 1840.57 toks/s, output: 2643.50 toks/s]
2025-01-06 17:32:42,760 - star_logger_test - ERROR - Processed prompts:  63%|██████▎   | 314/500 [00:25<00:13, 13.68it/s, est. speed input: 1838.65 toks/s, output: 2639.71 toks/s]
2025-01-06 17:32:42,988 - star_logger_test - ERROR - Processed prompts:  63%|██████▎   | 317/500 [00:25<00:11, 16.56it/s, est. speed input: 1848.16 toks/s, output: 2649.48 toks/s]
2025-01-06 17:32:43,128 - star_logger_test - ERROR - Processed prompts:  64%|██████▍   | 319/500 [00:25<00:13, 13.64it/s, est. speed input: 1843.71 toks/s, output: 2642.26 toks/s]
2025-01-06 17:32:43,307 - star_logger_test - ERROR - Processed prompts:  64%|██████▍   | 322/500 [00:25<00:11, 15.56it/s, est. speed input: 1850.79 toks/s, output: 2651.88 toks/s]
2025-01-06 17:32:43,442 - star_logger_test - ERROR - Processed prompts:  65%|██████▌   | 326/500 [00:25<00:09, 17.67it/s, est. speed input: 1860.64 toks/s, output: 2660.27 toks/s]
2025-01-06 17:32:43,654 - star_logger_test - ERROR - Processed prompts:  66%|██████▌   | 329/500 [00:25<00:09, 18.84it/s, est. speed input: 1868.06 toks/s, output: 2672.28 toks/s]
2025-01-06 17:32:43,856 - star_logger_test - ERROR - Processed prompts:  67%|██████▋   | 336/500 [00:26<00:06, 23.96it/s, est. speed input: 1892.41 toks/s, output: 2706.11 toks/s]
2025-01-06 17:32:44,069 - star_logger_test - ERROR - Processed prompts:  68%|██████▊   | 339/500 [00:26<00:07, 20.97it/s, est. speed input: 1894.29 toks/s, output: 2707.99 toks/s]
2025-01-06 17:32:44,188 - star_logger_test - ERROR - Processed prompts:  68%|██████▊   | 342/500 [00:26<00:08, 18.68it/s, est. speed input: 1896.16 toks/s, output: 2713.69 toks/s]
2025-01-06 17:32:44,355 - star_logger_test - ERROR - Processed prompts:  69%|██████▉   | 347/500 [00:26<00:06, 23.53it/s, est. speed input: 1915.13 toks/s, output: 2741.72 toks/s]
2025-01-06 17:32:44,514 - star_logger_test - ERROR - Processed prompts:  70%|███████   | 350/500 [00:26<00:06, 21.90it/s, est. speed input: 1919.45 toks/s, output: 2743.89 toks/s]
2025-01-06 17:32:44,632 - star_logger_test - ERROR - Processed prompts:  71%|███████   | 353/500 [00:26<00:06, 21.05it/s, est. speed input: 1924.27 toks/s, output: 2753.36 toks/s]
2025-01-06 17:32:44,781 - star_logger_test - ERROR - Processed prompts:  72%|███████▏  | 359/500 [00:27<00:05, 28.00it/s, est. speed input: 1948.44 toks/s, output: 2788.22 toks/s]
2025-01-06 17:32:44,887 - star_logger_test - ERROR - Processed prompts:  73%|███████▎  | 363/500 [00:27<00:04, 27.65it/s, est. speed input: 1959.55 toks/s, output: 2807.63 toks/s]
2025-01-06 17:32:45,035 - star_logger_test - ERROR - Processed prompts:  73%|███████▎  | 366/500 [00:27<00:04, 27.78it/s, est. speed input: 1967.93 toks/s, output: 2819.48 toks/s]
2025-01-06 17:32:45,144 - star_logger_test - ERROR - Processed prompts:  74%|███████▍  | 369/500 [00:27<00:05, 25.43it/s, est. speed input: 1973.23 toks/s, output: 2829.82 toks/s]
2025-01-06 17:32:45,263 - star_logger_test - ERROR - Processed prompts:  75%|███████▍  | 373/500 [00:27<00:04, 28.22it/s, est. speed input: 1986.56 toks/s, output: 2853.32 toks/s]
2025-01-06 17:32:45,377 - star_logger_test - ERROR - Processed prompts:  75%|███████▌  | 377/500 [00:27<00:04, 29.73it/s, est. speed input: 1999.26 toks/s, output: 2873.57 toks/s]
2025-01-06 17:32:45,485 - star_logger_test - ERROR - Processed prompts:  77%|███████▋  | 385/500 [00:27<00:02, 40.97it/s, est. speed input: 2033.54 toks/s, output: 2924.92 toks/s]
2025-01-06 17:32:45,588 - star_logger_test - ERROR - Processed prompts:  78%|███████▊  | 390/500 [00:27<00:02, 42.42it/s, est. speed input: 2052.40 toks/s, output: 2955.49 toks/s]
2025-01-06 17:32:45,689 - star_logger_test - ERROR - Processed prompts:  79%|███████▉  | 395/500 [00:28<00:02, 44.01it/s, est. speed input: 2071.34 toks/s, output: 2985.23 toks/s]
2025-01-06 17:32:45,817 - star_logger_test - ERROR - Processed prompts:  80%|████████  | 400/500 [00:28<00:02, 45.57it/s, est. speed input: 2090.36 toks/s, output: 3013.40 toks/s]
2025-01-06 17:32:45,940 - star_logger_test - ERROR - Processed prompts:  81%|████████  | 406/500 [00:28<00:02, 46.02it/s, est. speed input: 2112.06 toks/s, output: 3047.67 toks/s]
2025-01-06 17:32:46,071 - star_logger_test - ERROR - Processed prompts:  82%|████████▏ | 412/500 [00:28<00:01, 46.87it/s, est. speed input: 2133.96 toks/s, output: 3085.68 toks/s]
2025-01-06 17:32:46,171 - star_logger_test - ERROR - Processed prompts:  83%|████████▎ | 417/500 [00:28<00:01, 44.06it/s, est. speed input: 2150.01 toks/s, output: 3115.08 toks/s]
2025-01-06 17:32:46,346 - star_logger_test - ERROR - Processed prompts:  85%|████████▍ | 424/500 [00:28<00:01, 50.74it/s, est. speed input: 2177.95 toks/s, output: 3161.94 toks/s]
2025-01-06 17:32:46,475 - star_logger_test - ERROR - Processed prompts:  86%|████████▌ | 431/500 [00:28<00:01, 46.60it/s, est. speed input: 2200.44 toks/s, output: 3199.85 toks/s]
2025-01-06 17:32:46,598 - star_logger_test - ERROR - Processed prompts:  87%|████████▋ | 436/500 [00:28<00:01, 44.22it/s, est. speed input: 2215.72 toks/s, output: 3228.05 toks/s]
2025-01-06 17:32:46,778 - star_logger_test - ERROR - Processed prompts:  89%|████████▊ | 443/500 [00:29<00:01, 47.88it/s, est. speed input: 2241.71 toks/s, output: 3273.30 toks/s]
2025-01-06 17:32:46,925 - star_logger_test - ERROR - Processed prompts:  90%|████████▉ | 448/500 [00:29<00:01, 40.36it/s, est. speed input: 2253.17 toks/s, output: 3296.11 toks/s]
2025-01-06 17:32:47,017 - star_logger_test - ERROR - Processed prompts:  91%|█████████ | 453/500 [00:29<00:01, 38.44it/s, est. speed input: 2266.93 toks/s, output: 3322.81 toks/s]
2025-01-06 17:32:47,017 - star_logger_test - ERROR - Processed prompts: 100%|██████████| 500/500 [00:29<00:00, 16.99it/s, est. speed input: 2494.86 toks/s, output: 3720.85 toks/s]
2025-01-06 17:32:47,452 - star_logger_test - INFO - DatasetDict({
2025-01-06 17:32:47,452 - star_logger_test - INFO -     train: Dataset({
2025-01-06 17:32:47,452 - star_logger_test - INFO -         features: ['question_id', 'question_text', 'reference', 'rationale', 'messages'],
2025-01-06 17:32:47,452 - star_logger_test - INFO -         num_rows: 15
2025-01-06 17:32:47,453 - star_logger_test - INFO -     })
2025-01-06 17:32:47,453 - star_logger_test - INFO - })
2025-01-06 17:32:47,453 - star_logger_test - ERROR - 
2025-01-06 17:32:47,457 - star_logger_test - ERROR - Saving the dataset (0/1 shards):   0%|          | 0/15 [00:00<?, ? examples/s]
2025-01-06 17:32:47,457 - star_logger_test - ERROR - Saving the dataset (1/1 shards): 100%|██████████| 15/15 [00:00<00:00, 3504.79 examples/s]
2025-01-06 17:32:47,457 - star_logger_test - ERROR - Saving the dataset (1/1 shards): 100%|██████████| 15/15 [00:00<00:00, 3378.69 examples/s]
2025-01-06 17:32:47,497 - star_logger_test - INFO - INFO 01-06 17:32:47 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
2025-01-06 17:32:47,499 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=203052)[0;0m INFO 01-06 17:32:47 multiproc_worker_utils.py:247] Worker exiting
2025-01-06 17:32:49,568 - star_logger_test - ERROR - [rank0]:[W106 17:32:49.557240829 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
2025-01-06 17:32:50,657 - star_logger_test - ERROR - /usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
2025-01-06 17:32:50,657 - star_logger_test - ERROR -   warnings.warn('resource_tracker: There appear to be %d '
2025-01-06 17:32:51,554 - star_logger_test - INFO - Running command: accelerate launch --config_file configs/accelerate_config.yaml fine_tune.py --config_path configs/temp_STaR_ft_config.yaml
2025-01-06 17:33:01,034 - star_logger_test - INFO - False
2025-01-06 17:33:01,034 - star_logger_test - INFO - 
2025-01-06 17:33:01,034 - star_logger_test - INFO - ===================================BUG REPORT===================================
2025-01-06 17:33:01,034 - star_logger_test - INFO - ================================================================================
2025-01-06 17:33:01,035 - star_logger_test - INFO - The following directories listed in your path were found to be non-existent: {PosixPath('/tmp/torchelastic_y8jr5_0d/none_be52_a8l/attempt_0/0/error.json')}
2025-01-06 17:33:01,035 - star_logger_test - INFO - CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...
2025-01-06 17:33:01,035 - star_logger_test - INFO - The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib64')}
2025-01-06 17:33:01,035 - star_logger_test - INFO - DEBUG: Possible options found for libcudart.so: set()
2025-01-06 17:33:01,035 - star_logger_test - INFO - CUDA SETUP: PyTorch settings found: CUDA_VERSION=124, Highest Compute Capability: 8.6.
2025-01-06 17:33:01,035 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:167: UserWarning: Welcome to bitsandbytes. For bug reports, please run
2025-01-06 17:33:01,035 - star_logger_test - INFO - CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md
2025-01-06 17:33:01,036 - star_logger_test - INFO - CUDA SETUP: Required library version not found: libbitsandbytes_cuda124.so. Maybe you need to compile it from source?
2025-01-06 17:33:01,036 - star_logger_test - INFO - CUDA SETUP: Defaulting to libbitsandbytes_cpu.so...
2025-01-06 17:33:01,035 - star_logger_test - ERROR - 
2025-01-06 17:33:01,036 - star_logger_test - INFO - 
2025-01-06 17:33:01,036 - star_logger_test - ERROR - python -m bitsandbytes
2025-01-06 17:33:01,036 - star_logger_test - INFO - ================================================ERROR=====================================
2025-01-06 17:33:01,036 - star_logger_test - ERROR - 
2025-01-06 17:33:01,036 - star_logger_test - INFO - CUDA SETUP: CUDA detection failed! Possible reasons:
2025-01-06 17:33:01,036 - star_logger_test - ERROR - 
2025-01-06 17:33:01,036 - star_logger_test - INFO - 1. You need to manually override the PyTorch CUDA version. Please see: "https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md
2025-01-06 17:33:01,037 - star_logger_test - ERROR -   warn(msg)
2025-01-06 17:33:01,037 - star_logger_test - INFO - 2. CUDA driver not installed
2025-01-06 17:33:01,037 - star_logger_test - ERROR - Traceback (most recent call last):
2025-01-06 17:33:01,037 - star_logger_test - INFO - 3. CUDA not installed
2025-01-06 17:33:01,037 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py", line 1793, in _get_module
2025-01-06 17:33:01,037 - star_logger_test - INFO - 4. You have multiple conflicting CUDA libraries
2025-01-06 17:33:01,037 - star_logger_test - ERROR -     return importlib.import_module("." + module_name, self.__name__)
2025-01-06 17:33:01,037 - star_logger_test - INFO - 5. Required library not pre-compiled for this bitsandbytes release!
2025-01-06 17:33:01,037 - star_logger_test - ERROR -   File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-01-06 17:33:01,037 - star_logger_test - INFO - CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.
2025-01-06 17:33:01,037 - star_logger_test - ERROR -     return _bootstrap._gcd_import(name[level:], package, level)
2025-01-06 17:33:01,037 - star_logger_test - INFO - CUDA SETUP: The CUDA version for the compile might depend on your conda install. Inspect CUDA version via `conda list | grep cuda`.
2025-01-06 17:33:01,037 - star_logger_test - ERROR -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-01-06 17:33:01,038 - star_logger_test - INFO - ================================================================================
2025-01-06 17:33:01,038 - star_logger_test - ERROR -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-01-06 17:33:01,038 - star_logger_test - INFO - 
2025-01-06 17:33:01,038 - star_logger_test - ERROR -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-01-06 17:33:01,038 - star_logger_test - INFO - CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.
2025-01-06 17:33:01,038 - star_logger_test - ERROR -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-01-06 17:33:01,038 - star_logger_test - INFO - CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable
2025-01-06 17:33:01,038 - star_logger_test - ERROR -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-01-06 17:33:01,038 - star_logger_test - INFO - CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null
2025-01-06 17:33:01,038 - star_logger_test - ERROR -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-01-06 17:33:01,038 - star_logger_test - INFO - CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a
2025-01-06 17:33:01,038 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py", line 226, in <module>
2025-01-06 17:33:01,038 - star_logger_test - INFO - CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc
2025-01-06 17:33:01,039 - star_logger_test - ERROR -     from peft import PeftModel
2025-01-06 17:33:01,039 - star_logger_test - INFO - CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.
2025-01-06 17:33:01,039 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/peft/__init__.py", line 22, in <module>
2025-01-06 17:33:01,039 - star_logger_test - INFO - CUDA SETUP: Solution 2a): Download CUDA install script: wget https://raw.githubusercontent.com/TimDettmers/bitsandbytes/main/cuda_install.sh
2025-01-06 17:33:01,039 - star_logger_test - ERROR -     from .auto import (
2025-01-06 17:33:01,039 - star_logger_test - INFO - CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.
2025-01-06 17:33:01,039 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/peft/auto.py", line 31, in <module>
2025-01-06 17:33:01,039 - star_logger_test - INFO - CUDA SETUP: Solution 2b): For example, "bash cuda_install.sh 113 ~/local/" will download CUDA 11.3 and install into the folder ~/local
2025-01-06 17:33:01,039 - star_logger_test - ERROR -     from .mapping import MODEL_TYPE_TO_PEFT_MODEL_MAPPING
2025-01-06 17:33:01,039 - star_logger_test - INFO - CUDA SETUP: Setup Failed!
2025-01-06 17:33:01,039 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/peft/mapping.py", line 23, in <module>
2025-01-06 17:33:01,039 - star_logger_test - ERROR -     from .peft_model import (
2025-01-06 17:33:01,039 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 38, in <module>
2025-01-06 17:33:01,039 - star_logger_test - ERROR -     from .tuners import (
2025-01-06 17:33:01,040 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/peft/tuners/__init__.py", line 21, in <module>
2025-01-06 17:33:01,040 - star_logger_test - ERROR -     from .lora import LoraConfig, LoraModel
2025-01-06 17:33:01,040 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py", line 45, in <module>
2025-01-06 17:33:01,040 - star_logger_test - ERROR -     import bitsandbytes as bnb
2025-01-06 17:33:01,040 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/bitsandbytes/__init__.py", line 6, in <module>
2025-01-06 17:33:01,040 - star_logger_test - ERROR -     from . import cuda_setup, utils, research
2025-01-06 17:33:01,040 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/__init__.py", line 1, in <module>
2025-01-06 17:33:01,040 - star_logger_test - ERROR -     from . import nn
2025-01-06 17:33:01,040 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/__init__.py", line 1, in <module>
2025-01-06 17:33:01,040 - star_logger_test - ERROR -     from .modules import LinearFP8Mixed, LinearFP8Global
2025-01-06 17:33:01,040 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/modules.py", line 8, in <module>
2025-01-06 17:33:01,040 - star_logger_test - ERROR -     from bitsandbytes.optim import GlobalOptimManager
2025-01-06 17:33:01,040 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/bitsandbytes/optim/__init__.py", line 6, in <module>
2025-01-06 17:33:01,040 - star_logger_test - ERROR -     from bitsandbytes.cextension import COMPILED_WITH_CUDA
2025-01-06 17:33:01,040 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py", line 20, in <module>
2025-01-06 17:33:01,040 - star_logger_test - ERROR -     raise RuntimeError('''
2025-01-06 17:33:01,040 - star_logger_test - ERROR - RuntimeError: 
2025-01-06 17:33:01,040 - star_logger_test - ERROR -         CUDA Setup failed despite GPU being available. Please run the following command to get more information:
2025-01-06 17:33:01,040 - star_logger_test - ERROR - 
2025-01-06 17:33:01,040 - star_logger_test - ERROR -         python -m bitsandbytes
2025-01-06 17:33:01,040 - star_logger_test - ERROR - 
2025-01-06 17:33:01,040 - star_logger_test - ERROR -         Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them
2025-01-06 17:33:01,041 - star_logger_test - ERROR -         to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes
2025-01-06 17:33:01,041 - star_logger_test - ERROR -         and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues
2025-01-06 17:33:01,041 - star_logger_test - ERROR - 
2025-01-06 17:33:01,041 - star_logger_test - ERROR - The above exception was the direct cause of the following exception:
2025-01-06 17:33:01,041 - star_logger_test - ERROR - 
2025-01-06 17:33:01,041 - star_logger_test - ERROR - Traceback (most recent call last):
2025-01-06 17:33:01,041 - star_logger_test - ERROR -   File "/home/data/v.moskvoretskii/QAC/fine_tune.py", line 8, in <module>
2025-01-06 17:33:01,041 - star_logger_test - ERROR -     from transformers import (
2025-01-06 17:33:01,041 - star_logger_test - ERROR -   File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
2025-01-06 17:33:01,041 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py", line 1781, in __getattr__
2025-01-06 17:33:01,041 - star_logger_test - ERROR -     module = self._get_module(self._class_to_module[name])
2025-01-06 17:33:01,041 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py", line 1795, in _get_module
2025-01-06 17:33:01,041 - star_logger_test - ERROR -     raise RuntimeError(
2025-01-06 17:33:01,041 - star_logger_test - ERROR - RuntimeError: Failed to import transformers.trainer because of the following error (look up to see its traceback):
2025-01-06 17:33:01,041 - star_logger_test - ERROR - 
2025-01-06 17:33:01,041 - star_logger_test - ERROR -         CUDA Setup failed despite GPU being available. Please run the following command to get more information:
2025-01-06 17:33:01,041 - star_logger_test - ERROR - 
2025-01-06 17:33:01,041 - star_logger_test - ERROR -         python -m bitsandbytes
2025-01-06 17:33:01,041 - star_logger_test - ERROR - 
2025-01-06 17:33:01,041 - star_logger_test - ERROR -         Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them
2025-01-06 17:33:01,041 - star_logger_test - ERROR -         to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes
2025-01-06 17:33:01,041 - star_logger_test - ERROR -         and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues
2025-01-06 17:33:01,596 - star_logger_test - INFO - False
2025-01-06 17:33:01,596 - star_logger_test - INFO - 
2025-01-06 17:33:01,596 - star_logger_test - INFO - ===================================BUG REPORT===================================
2025-01-06 17:33:01,596 - star_logger_test - INFO - ================================================================================
2025-01-06 17:33:01,596 - star_logger_test - INFO - The following directories listed in your path were found to be non-existent: {PosixPath('/tmp/torchelastic_y8jr5_0d/none_be52_a8l/attempt_0/1/error.json')}
2025-01-06 17:33:01,596 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:167: UserWarning: Welcome to bitsandbytes. For bug reports, please run
2025-01-06 17:33:01,597 - star_logger_test - INFO - CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...
2025-01-06 17:33:01,597 - star_logger_test - ERROR - 
2025-01-06 17:33:01,597 - star_logger_test - INFO - The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib64')}
2025-01-06 17:33:01,597 - star_logger_test - ERROR - python -m bitsandbytes
2025-01-06 17:33:01,597 - star_logger_test - INFO - DEBUG: Possible options found for libcudart.so: set()
2025-01-06 17:33:01,597 - star_logger_test - ERROR - 
2025-01-06 17:33:01,597 - star_logger_test - INFO - CUDA SETUP: PyTorch settings found: CUDA_VERSION=124, Highest Compute Capability: 8.6.
2025-01-06 17:33:01,597 - star_logger_test - ERROR - 
2025-01-06 17:33:01,597 - star_logger_test - INFO - CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md
2025-01-06 17:33:01,597 - star_logger_test - ERROR -   warn(msg)
2025-01-06 17:33:01,597 - star_logger_test - INFO - CUDA SETUP: Required library version not found: libbitsandbytes_cuda124.so. Maybe you need to compile it from source?
2025-01-06 17:33:01,597 - star_logger_test - ERROR - Traceback (most recent call last):
2025-01-06 17:33:01,597 - star_logger_test - INFO - CUDA SETUP: Defaulting to libbitsandbytes_cpu.so...
2025-01-06 17:33:01,597 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py", line 1793, in _get_module
2025-01-06 17:33:01,598 - star_logger_test - INFO - 
2025-01-06 17:33:01,598 - star_logger_test - ERROR -     return importlib.import_module("." + module_name, self.__name__)
2025-01-06 17:33:01,598 - star_logger_test - INFO - ================================================ERROR=====================================
2025-01-06 17:33:01,598 - star_logger_test - ERROR -   File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-01-06 17:33:01,598 - star_logger_test - INFO - CUDA SETUP: CUDA detection failed! Possible reasons:
2025-01-06 17:33:01,598 - star_logger_test - ERROR -     return _bootstrap._gcd_import(name[level:], package, level)
2025-01-06 17:33:01,598 - star_logger_test - INFO - 1. You need to manually override the PyTorch CUDA version. Please see: "https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md
2025-01-06 17:33:01,598 - star_logger_test - ERROR -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-01-06 17:33:01,598 - star_logger_test - INFO - 2. CUDA driver not installed
2025-01-06 17:33:01,598 - star_logger_test - ERROR -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-01-06 17:33:01,598 - star_logger_test - INFO - 3. CUDA not installed
2025-01-06 17:33:01,598 - star_logger_test - ERROR -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-01-06 17:33:01,598 - star_logger_test - INFO - 4. You have multiple conflicting CUDA libraries
2025-01-06 17:33:01,598 - star_logger_test - ERROR -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-01-06 17:33:01,598 - star_logger_test - INFO - 5. Required library not pre-compiled for this bitsandbytes release!
2025-01-06 17:33:01,599 - star_logger_test - ERROR -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-01-06 17:33:01,599 - star_logger_test - INFO - CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.
2025-01-06 17:33:01,599 - star_logger_test - ERROR -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-01-06 17:33:01,599 - star_logger_test - INFO - CUDA SETUP: The CUDA version for the compile might depend on your conda install. Inspect CUDA version via `conda list | grep cuda`.
2025-01-06 17:33:01,599 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py", line 226, in <module>
2025-01-06 17:33:01,599 - star_logger_test - INFO - ================================================================================
2025-01-06 17:33:01,599 - star_logger_test - ERROR -     from peft import PeftModel
2025-01-06 17:33:01,599 - star_logger_test - INFO - 
2025-01-06 17:33:01,599 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/peft/__init__.py", line 22, in <module>
2025-01-06 17:33:01,599 - star_logger_test - INFO - CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.
2025-01-06 17:33:01,599 - star_logger_test - ERROR -     from .auto import (
2025-01-06 17:33:01,599 - star_logger_test - INFO - CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable
2025-01-06 17:33:01,599 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/peft/auto.py", line 31, in <module>
2025-01-06 17:33:01,599 - star_logger_test - INFO - CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null
2025-01-06 17:33:01,599 - star_logger_test - ERROR -     from .mapping import MODEL_TYPE_TO_PEFT_MODEL_MAPPING
2025-01-06 17:33:01,600 - star_logger_test - INFO - CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a
2025-01-06 17:33:01,600 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/peft/mapping.py", line 23, in <module>
2025-01-06 17:33:01,600 - star_logger_test - INFO - CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc
2025-01-06 17:33:01,600 - star_logger_test - ERROR -     from .peft_model import (
2025-01-06 17:33:01,600 - star_logger_test - INFO - CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.
2025-01-06 17:33:01,600 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 38, in <module>
2025-01-06 17:33:01,600 - star_logger_test - INFO - CUDA SETUP: Solution 2a): Download CUDA install script: wget https://raw.githubusercontent.com/TimDettmers/bitsandbytes/main/cuda_install.sh
2025-01-06 17:33:01,600 - star_logger_test - ERROR -     from .tuners import (
2025-01-06 17:33:01,600 - star_logger_test - INFO - CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.
2025-01-06 17:33:01,600 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/peft/tuners/__init__.py", line 21, in <module>
2025-01-06 17:33:01,600 - star_logger_test - INFO - CUDA SETUP: Solution 2b): For example, "bash cuda_install.sh 113 ~/local/" will download CUDA 11.3 and install into the folder ~/local
2025-01-06 17:33:01,600 - star_logger_test - ERROR -     from .lora import LoraConfig, LoraModel
2025-01-06 17:33:01,600 - star_logger_test - INFO - CUDA SETUP: Setup Failed!
2025-01-06 17:33:01,600 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py", line 45, in <module>
2025-01-06 17:33:01,600 - star_logger_test - ERROR -     import bitsandbytes as bnb
2025-01-06 17:33:01,601 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/bitsandbytes/__init__.py", line 6, in <module>
2025-01-06 17:33:01,601 - star_logger_test - ERROR -     from . import cuda_setup, utils, research
2025-01-06 17:33:01,601 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/__init__.py", line 1, in <module>
2025-01-06 17:33:01,601 - star_logger_test - ERROR -     from . import nn
2025-01-06 17:33:01,601 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/__init__.py", line 1, in <module>
2025-01-06 17:33:01,601 - star_logger_test - ERROR -     from .modules import LinearFP8Mixed, LinearFP8Global
2025-01-06 17:33:01,601 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/bitsandbytes/research/nn/modules.py", line 8, in <module>
2025-01-06 17:33:01,601 - star_logger_test - ERROR -     from bitsandbytes.optim import GlobalOptimManager
2025-01-06 17:33:01,601 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/bitsandbytes/optim/__init__.py", line 6, in <module>
2025-01-06 17:33:01,601 - star_logger_test - ERROR -     from bitsandbytes.cextension import COMPILED_WITH_CUDA
2025-01-06 17:33:01,601 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py", line 20, in <module>
2025-01-06 17:33:01,601 - star_logger_test - ERROR -     raise RuntimeError('''
2025-01-06 17:33:01,601 - star_logger_test - ERROR - RuntimeError: 
2025-01-06 17:33:01,601 - star_logger_test - ERROR -         CUDA Setup failed despite GPU being available. Please run the following command to get more information:
2025-01-06 17:33:01,601 - star_logger_test - ERROR - 
2025-01-06 17:33:01,601 - star_logger_test - ERROR -         python -m bitsandbytes
2025-01-06 17:33:01,601 - star_logger_test - ERROR - 
2025-01-06 17:33:01,601 - star_logger_test - ERROR -         Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them
2025-01-06 17:33:01,601 - star_logger_test - ERROR -         to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes
2025-01-06 17:33:01,601 - star_logger_test - ERROR -         and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues
2025-01-06 17:33:01,601 - star_logger_test - ERROR - 
2025-01-06 17:33:01,601 - star_logger_test - ERROR - The above exception was the direct cause of the following exception:
2025-01-06 17:33:01,601 - star_logger_test - ERROR - 
2025-01-06 17:33:01,601 - star_logger_test - ERROR - Traceback (most recent call last):
2025-01-06 17:33:01,602 - star_logger_test - ERROR -   File "/home/data/v.moskvoretskii/QAC/fine_tune.py", line 8, in <module>
2025-01-06 17:33:01,602 - star_logger_test - ERROR -     from transformers import (
2025-01-06 17:33:01,602 - star_logger_test - ERROR -   File "<frozen importlib._bootstrap>", line 1075, in _handle_fromlist
2025-01-06 17:33:01,602 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py", line 1781, in __getattr__
2025-01-06 17:33:01,602 - star_logger_test - ERROR -     module = self._get_module(self._class_to_module[name])
2025-01-06 17:33:01,602 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py", line 1795, in _get_module
2025-01-06 17:33:01,602 - star_logger_test - ERROR -     raise RuntimeError(
2025-01-06 17:33:01,602 - star_logger_test - ERROR - RuntimeError: Failed to import transformers.trainer because of the following error (look up to see its traceback):
2025-01-06 17:33:01,602 - star_logger_test - ERROR - 
2025-01-06 17:33:01,602 - star_logger_test - ERROR -         CUDA Setup failed despite GPU being available. Please run the following command to get more information:
2025-01-06 17:33:01,602 - star_logger_test - ERROR - 
2025-01-06 17:33:01,602 - star_logger_test - ERROR -         python -m bitsandbytes
2025-01-06 17:33:01,602 - star_logger_test - ERROR - 
2025-01-06 17:33:01,602 - star_logger_test - ERROR -         Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them
2025-01-06 17:33:01,602 - star_logger_test - ERROR -         to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes
2025-01-06 17:33:01,602 - star_logger_test - ERROR -         and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues
2025-01-06 17:33:01,946 - star_logger_test - ERROR - W0106 17:33:01.945000 203876 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 204052 closing signal SIGTERM
2025-01-06 17:33:02,111 - star_logger_test - ERROR - E0106 17:33:02.110000 203876 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 204051) of binary: /usr/bin/python
2025-01-06 17:33:02,117 - star_logger_test - ERROR - Traceback (most recent call last):
2025-01-06 17:33:02,118 - star_logger_test - ERROR -   File "/usr/local/bin/accelerate", line 8, in <module>
2025-01-06 17:33:02,118 - star_logger_test - ERROR -     sys.exit(main())
2025-01-06 17:33:02,118 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py", line 48, in main
2025-01-06 17:33:02,118 - star_logger_test - ERROR -     args.func(args)
2025-01-06 17:33:02,118 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 1155, in launch_command
2025-01-06 17:33:02,119 - star_logger_test - ERROR -     multi_gpu_launcher(args)
2025-01-06 17:33:02,119 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py", line 793, in multi_gpu_launcher
2025-01-06 17:33:02,119 - star_logger_test - ERROR -     distrib_run.run(args)
2025-01-06 17:33:02,119 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 910, in run
2025-01-06 17:33:02,120 - star_logger_test - ERROR -     elastic_launch(
2025-01-06 17:33:02,120 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 138, in __call__
2025-01-06 17:33:02,120 - star_logger_test - ERROR -     return launch_agent(self._config, self._entrypoint, list(args))
2025-01-06 17:33:02,121 - star_logger_test - ERROR -   File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
2025-01-06 17:33:02,121 - star_logger_test - ERROR -     raise ChildFailedError(
2025-01-06 17:33:02,121 - star_logger_test - ERROR - torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
2025-01-06 17:33:02,121 - star_logger_test - ERROR - ============================================================
2025-01-06 17:33:02,121 - star_logger_test - ERROR - fine_tune.py FAILED
2025-01-06 17:33:02,121 - star_logger_test - ERROR - ------------------------------------------------------------
2025-01-06 17:33:02,121 - star_logger_test - ERROR - Failures:
2025-01-06 17:33:02,121 - star_logger_test - ERROR -   <NO_OTHER_FAILURES>
2025-01-06 17:33:02,122 - star_logger_test - ERROR - ------------------------------------------------------------
2025-01-06 17:33:02,122 - star_logger_test - ERROR - Root Cause (first observed failure):
2025-01-06 17:33:02,122 - star_logger_test - ERROR - [0]:
2025-01-06 17:33:02,122 - star_logger_test - ERROR -   time      : 2025-01-06_17:33:01
2025-01-06 17:33:02,122 - star_logger_test - ERROR -   host      : f84ce4ed13b2
2025-01-06 17:33:02,122 - star_logger_test - ERROR -   rank      : 0 (local_rank: 0)
2025-01-06 17:33:02,122 - star_logger_test - ERROR -   exitcode  : 1 (pid: 204051)
2025-01-06 17:33:02,122 - star_logger_test - ERROR -   error_file: <N/A>
2025-01-06 17:33:02,123 - star_logger_test - ERROR -   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-01-06 17:33:02,123 - star_logger_test - ERROR - ============================================================
2025-01-06 17:47:26,704 - star_logger_test - INFO - [INFO] Starting iteration 1/2
2025-01-06 17:47:26,704 - star_logger_test - INFO - Running command: python star_vllm_generation.py --config_path configs/star_config.yaml --generation_model_path luezzka/Llama-3.2-1B-Instruct --ft_dataset_path /home/data/v.moskvoretskii/cache/STaR/test/data/data_0 --iteration 0
2025-01-06 17:47:35,107 - star_logger_test - INFO - [INFO] No few-shot file found for prompt_type='star_generation' at 'few_shots/star_generation.json'. Using none.
2025-01-06 17:47:35,107 - star_logger_test - INFO - [INFO] No few-shot file found for prompt_type='star_rationalization' at 'few_shots/star_rationalization.json'. Using none.
2025-01-06 17:47:35,107 - star_logger_test - INFO - INFO 01-06 17:47:35 config.py:2272] Downcasting torch.float32 to torch.bfloat16.
2025-01-06 17:47:44,135 - star_logger_test - INFO - INFO 01-06 17:47:44 config.py:510] This model supports multiple tasks: {'score', 'generate', 'embed', 'reward', 'classify'}. Defaulting to 'generate'.
2025-01-06 17:47:44,136 - star_logger_test - INFO - INFO 01-06 17:47:44 config.py:1310] Defaulting to use mp for distributed inference
2025-01-06 17:47:44,137 - star_logger_test - INFO - WARNING 01-06 17:47:44 cuda.py:98] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
2025-01-06 17:47:44,137 - star_logger_test - INFO - WARNING 01-06 17:47:44 config.py:642] Async output processing is not supported on the current platform type cuda.
2025-01-06 17:47:44,147 - star_logger_test - INFO - INFO 01-06 17:47:44 llm_engine.py:234] Initializing an LLM engine (v0.6.6.post1) with config: model='luezzka/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='luezzka/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1024, download_dir='/home/data/v.moskvoretskii/cache/', load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=luezzka/Llama-3.2-1B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[],"max_capture_size":0}, use_cached_outputs=False, 
2025-01-06 17:47:45,350 - star_logger_test - INFO - WARNING 01-06 17:47:45 multiproc_worker_utils.py:312] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
2025-01-06 17:47:45,355 - star_logger_test - INFO - INFO 01-06 17:47:45 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
2025-01-06 17:47:46,620 - star_logger_test - INFO - INFO 01-06 17:47:46 selector.py:120] Using Flash Attention backend.
2025-01-06 17:47:46,889 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=212399)[0;0m INFO 01-06 17:47:46 selector.py:120] Using Flash Attention backend.
2025-01-06 17:47:46,889 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=212399)[0;0m INFO 01-06 17:47:46 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
2025-01-06 17:47:47,531 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=212399)[0;0m INFO 01-06 17:47:47 utils.py:918] Found nccl from library libnccl.so.2
2025-01-06 17:47:47,531 - star_logger_test - INFO - INFO 01-06 17:47:47 utils.py:918] Found nccl from library libnccl.so.2
2025-01-06 17:47:47,531 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=212399)[0;0m INFO 01-06 17:47:47 pynccl.py:69] vLLM is using nccl==2.21.5
2025-01-06 17:47:47,532 - star_logger_test - INFO - INFO 01-06 17:47:47 pynccl.py:69] vLLM is using nccl==2.21.5
2025-01-06 17:47:47,809 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=212399)[0;0m INFO 01-06 17:47:47 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
2025-01-06 17:47:47,809 - star_logger_test - INFO - INFO 01-06 17:47:47 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
2025-01-06 17:47:47,824 - star_logger_test - INFO - INFO 01-06 17:47:47 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_ab33d77c'), local_subscribe_port=52507, remote_subscribe_port=None)
2025-01-06 17:47:47,829 - star_logger_test - INFO - INFO 01-06 17:47:47 model_runner.py:1094] Starting to load model luezzka/Llama-3.2-1B-Instruct...
2025-01-06 17:47:47,831 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=212399)[0;0m INFO 01-06 17:47:47 model_runner.py:1094] Starting to load model luezzka/Llama-3.2-1B-Instruct...
2025-01-06 17:47:48,376 - star_logger_test - INFO - INFO 01-06 17:47:48 weight_utils.py:251] Using model weights format ['*.safetensors']
2025-01-06 17:47:48,590 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=212399)[0;0m INFO 01-06 17:47:48 weight_utils.py:251] Using model weights format ['*.safetensors']
2025-01-06 17:47:48,701 - star_logger_test - INFO - INFO 01-06 17:47:48 weight_utils.py:296] No model.safetensors.index.json found in remote.
2025-01-06 17:47:48,702 - star_logger_test - ERROR - 
2025-01-06 17:47:48,702 - star_logger_test - ERROR - Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-01-06 17:47:49,060 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=212399)[0;0m INFO 01-06 17:47:49 weight_utils.py:296] No model.safetensors.index.json found in remote.
2025-01-06 17:48:24,165 - star_logger_test - ERROR - 
2025-01-06 17:48:24,165 - star_logger_test - ERROR - Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:35<00:00, 35.46s/it]
2025-01-06 17:48:24,165 - star_logger_test - ERROR - 
2025-01-06 17:48:24,165 - star_logger_test - ERROR - Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:35<00:00, 35.46s/it]
2025-01-06 17:48:24,165 - star_logger_test - ERROR - 
2025-01-06 17:48:24,565 - star_logger_test - INFO - INFO 01-06 17:48:24 model_runner.py:1099] Loading model weights took 1.1666 GB
2025-01-06 17:48:26,229 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=212399)[0;0m INFO 01-06 17:48:26 model_runner.py:1099] Loading model weights took 1.1666 GB
2025-01-06 17:48:29,075 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=212399)[0;0m INFO 01-06 17:48:29 worker.py:241] Memory profiling takes 2.84 seconds
2025-01-06 17:48:29,075 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=212399)[0;0m INFO 01-06 17:48:29 worker.py:241] the current vLLM instance can use total_gpu_memory (44.38GiB) x gpu_memory_utilization (0.99) = 43.94GiB
2025-01-06 17:48:29,075 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=212399)[0;0m INFO 01-06 17:48:29 worker.py:241] model weights take 1.17GiB; non_torch_memory takes 0.25GiB; PyTorch activation peak memory takes 0.08GiB; the rest of the memory reserved for KV Cache is 42.44GiB.
2025-01-06 17:48:29,193 - star_logger_test - INFO - INFO 01-06 17:48:29 worker.py:241] Memory profiling takes 2.96 seconds
2025-01-06 17:48:29,193 - star_logger_test - INFO - INFO 01-06 17:48:29 worker.py:241] the current vLLM instance can use total_gpu_memory (44.38GiB) x gpu_memory_utilization (0.99) = 43.94GiB
2025-01-06 17:48:29,193 - star_logger_test - INFO - INFO 01-06 17:48:29 worker.py:241] model weights take 1.17GiB; non_torch_memory takes 0.25GiB; PyTorch activation peak memory takes 1.18GiB; the rest of the memory reserved for KV Cache is 41.34GiB.
2025-01-06 17:48:29,424 - star_logger_test - INFO - INFO 01-06 17:48:29 distributed_gpu_executor.py:57] # GPU blocks: 169332, # CPU blocks: 16384
2025-01-06 17:48:29,424 - star_logger_test - INFO - INFO 01-06 17:48:29 distributed_gpu_executor.py:61] Maximum concurrency for 1024 tokens per request: 2645.81x
2025-01-06 17:48:32,510 - star_logger_test - INFO - INFO 01-06 17:48:32 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 6.28 seconds
2025-01-06 17:48:36,715 - star_logger_test - INFO - [INFO] Starting generation at 1/2
2025-01-06 17:48:36,715 - star_logger_test - ERROR - 
2025-01-06 17:48:37,810 - star_logger_test - INFO - INFO 01-06 17:48:37 model_runner_base.py:120] Writing input of failed execution to /tmp/err_execute_model_input_20250106-174837.pkl...
2025-01-06 17:48:37,816 - star_logger_test - INFO - INFO 01-06 17:48:37 model_runner_base.py:149] Completed writing input of failed execution to /tmp/err_execute_model_input_20250106-174837.pkl.
2025-01-06 17:48:37,819 - star_logger_test - ERROR - Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][rank0]: Traceback (most recent call last):
2025-01-06 17:48:37,819 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/worker/model_runner_base.py", line 116, in _wrapper
2025-01-06 17:48:37,819 - star_logger_test - ERROR - [rank0]:     return func(*args, **kwargs)
2025-01-06 17:48:37,819 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/worker/model_runner.py", line 1747, in execute_model
2025-01-06 17:48:37,819 - star_logger_test - ERROR - [rank0]:     output: SamplerOutput = self.model.sample(
2025-01-06 17:48:37,819 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/llama.py", line 584, in sample
2025-01-06 17:48:37,819 - star_logger_test - ERROR - [rank0]:     next_tokens = self.sampler(logits, sampling_metadata)
2025-01-06 17:48:37,819 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
2025-01-06 17:48:37,819 - star_logger_test - ERROR - [rank0]:     return self._call_impl(*args, **kwargs)
2025-01-06 17:48:37,819 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
2025-01-06 17:48:37,819 - star_logger_test - ERROR - [rank0]:     return forward_call(*args, **kwargs)
2025-01-06 17:48:37,819 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/sampler.py", line 274, in forward
2025-01-06 17:48:37,819 - star_logger_test - ERROR - [rank0]:     logits = _apply_top_k_top_p(logits, sampling_tensors.top_ps,
2025-01-06 17:48:37,819 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/sampler.py", line 392, in _apply_top_k_top_p
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]:     logits_sort, logits_idx = logits.sort(dim=-1, descending=False)
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacity of 44.38 GiB of which 244.62 MiB is free. Process 3163872 has 44.13 GiB memory in use. Of the allocated memory 43.32 GiB is allocated by PyTorch, and 347.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-06 17:48:37,820 - star_logger_test - ERROR - 
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]: The above exception was the direct cause of the following exception:
2025-01-06 17:48:37,820 - star_logger_test - ERROR - 
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]: Traceback (most recent call last):
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]:   File "/home/data/v.moskvoretskii/QAC/star_vllm_generation.py", line 328, in <module>
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]:     main()
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]:   File "/home/data/v.moskvoretskii/QAC/star_vllm_generation.py", line 279, in main
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]:     train_data = perform_generation(
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]:   File "/home/data/v.moskvoretskii/QAC/star_vllm_generation.py", line 203, in perform_generation
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]:     generation_results = generate_for_dataset(
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]:   File "/home/data/v.moskvoretskii/QAC/generation_utils.py", line 184, in generate_for_dataset
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]:     generation_results = model.generate(all_prompts, sampling_params)
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/utils.py", line 1021, in inner
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]:     return fn(*args, **kwargs)
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/llm.py", line 462, in generate
2025-01-06 17:48:37,820 - star_logger_test - ERROR - [rank0]:     outputs = self._run_engine(use_tqdm=use_tqdm)
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/llm.py", line 1242, in _run_engine
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]:     step_outputs = self.llm_engine.step()
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py", line 1390, in step
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]:     outputs = self.model_executor.execute_model(
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/executor/distributed_gpu_executor.py", line 82, in execute_model
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]:     driver_outputs = self._driver_execute_model(execute_model_req)
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/executor/multiproc_gpu_executor.py", line 120, in _driver_execute_model
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]:     return self.driver_worker.execute_model(execute_model_req)
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/worker/worker_base.py", line 343, in execute_model
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]:     output = self.model_runner.execute_model(
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]:     return func(*args, **kwargs)
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/worker/model_runner_base.py", line 152, in _wrapper
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]:     raise type(err)(
2025-01-06 17:48:37,821 - star_logger_test - ERROR - [rank0]: torch.OutOfMemoryError: Error in model execution (input dumped to /tmp/err_execute_model_input_20250106-174837.pkl): CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacity of 44.38 GiB of which 244.62 MiB is free. Process 3163872 has 44.13 GiB memory in use. Of the allocated memory 43.32 GiB is allocated by PyTorch, and 347.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-06 17:48:39,232 - star_logger_test - INFO - INFO 01-06 17:48:39 multiproc_worker_utils.py:127] Killing local vLLM worker processes
2025-01-06 17:48:40,232 - star_logger_test - ERROR - Fatal Python error: _enter_buffered_busy: could not acquire lock for <_io.BufferedWriter name='<stdout>'> at interpreter shutdown, possibly due to daemon threads
2025-01-06 17:48:40,232 - star_logger_test - ERROR - Python runtime state: finalizing (tstate=0x000055a08c71c6f0)
2025-01-06 17:48:40,233 - star_logger_test - ERROR - 
2025-01-06 17:48:40,233 - star_logger_test - ERROR - Current thread 0x00007fb24d8ee1c0 (most recent call first):
2025-01-06 17:48:40,233 - star_logger_test - ERROR -   <no Python frame>
2025-01-06 17:48:40,233 - star_logger_test - ERROR - 
2025-01-06 17:48:40,234 - star_logger_test - ERROR - Extension modules: numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, yaml._yaml, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._helpers_c, yarl._quoting_c, aiohttp._helpers, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, markupsafe._speedups, PIL._imaging, msgspec._core, PIL._imagingft, sentencepiece._sentencepiece, sklearn.__check_build._check_build, psutil._psutil_linux, psutil._psutil_posix, scipy._lib._ccallback_c, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg.cython_blas, scipy.linalg._matfuncs_expm, scipy.linalg._decomp_update, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.linalg._propack._spropack, scipy.sparse.linalg._propack._dpropack, scipy.sparse.linalg._propack._cpropack, scipy.sparse.linalg._propack._zpropack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.spatial.transform._rotation, scipy.optimize._group_columns, scipy.optimize._trlib._trlib, scipy.optimize._lbfgsb, _moduleTNC, scipy.optimize._moduleTNC, scipy.optimize._cobyla, scipy.optimize._slsqp, scipy.optimize._minpack, scipy.optimize._lsq.givens_elimination, scipy.optimize._zeros, scipy.optimize._highs.cython.src._highs_wrapper, scipy.optimize._highs._highs_wrapper, scipy.optimize._highs.cython.src._highs_constants, scipy.optimize._highs._highs_constants, scipy.linalg._interpolative, scipy.optimize._bglu_dense, scipy.optimize._lsap, scipy.optimize._direct, scipy.integrate._odepack, scipy.integrate._quadpack, scipy.integrate._vode, scipy.integrate._dop, scipy.integrate._lsoda, scipy.interpolate._fitpack, scipy.interpolate._dfitpack, scipy.interpolate._bspl, scipy.interpolate._ppoly, scipy.interpolate.interpnd, scipy.interpolate._rbfinterp_pythran, scipy.interpolate._rgi_cython, scipy.special.cython_special, scipy.stats._stats, scipy.stats._biasedurn, scipy.stats._levy_stable.levyst, scipy.stats._stats_pythran, scipy._lib._uarray._uarray, scipy.stats._ansari_swilk_statistics, scipy.stats._sobol, scipy.stats._qmc_cy, scipy.stats._mvn, scipy.stats._rcont.rcont, scipy.stats._unuran.unuran_wrapper, scipy.ndimage._nd_image, _ni_label, scipy.ndimage._ni_label, sklearn.utils._isfinite, sklearn.utils.sparsefuncs_fast, sklearn.utils.murmurhash, sklearn.utils._openmp_helpers, sklearn.metrics.cluster._expected_mutual_info_fast, sklearn.preprocessing._csr_polynomial_expansion, sklearn.preprocessing._target_encoder_fast, sklearn.metrics._dist_metrics, sklearn.metrics._pairwise_distances_reduction._datasets_pair, sklearn.utils._cython_blas, sklearn.metrics._pairwise_distances_reduction._base, sklearn.metrics._pairwise_distances_reduction._middle_term_computer, sklearn.utils._heap, sklearn.utils._sorting, sklearn.metrics._pairwise_distances_reduction._argkmin, sklearn.metrics._pairwise_distances_reduction._argkmin_classmode, sklearn.utils._vector_sentinel, sklearn.metrics._pairwise_distances_reduction._radius_neighbors, sklearn.metrics._pairwise_distances_reduction._radius_neighbors_classmode, sklearn.metrics._pairwise_fast, regex._regex, msgpack._cmsgpack, google._upb._message, setproctitle, uvloop.loop, ray._raylet, sklearn.feature_extraction._hashing_fast, sklearn.utils._random, sklearn.utils._seq_dataset, sklearn.linear_model._cd_fast, _loss, sklearn._loss._loss, sklearn.utils.arrayfuncs, sklearn.svm._liblinear, sklearn.svm._libsvm, sklearn.svm._libsvm_sparse, sklearn.utils._weight_vector, sklearn.linear_model._sgd_fast, sklearn.linear_model._sag_fast, scipy.io.matlab._mio_utils, scipy.io.matlab._streams, scipy.io.matlab._mio5_utils, sklearn.datasets._svmlight_format_fast, zmq.backend.cython._zmq, cuda_utils, __triton_launcher (total: 224)
2025-01-06 17:57:43,292 - star_logger_test - INFO - [INFO] Starting iteration 1/2
2025-01-06 17:57:43,292 - star_logger_test - INFO - Running command: python star_vllm_generation.py --config_path configs/star_config.yaml --generation_model_path luezzka/Llama-3.2-1B-Instruct --ft_dataset_path /home/data/v.moskvoretskii/cache/STaR/test/data/data_0 --iteration 0
2025-01-06 17:57:51,685 - star_logger_test - INFO - [INFO] No few-shot file found for prompt_type='star_generation' at 'few_shots/star_generation.json'. Using none.
2025-01-06 17:57:51,685 - star_logger_test - INFO - [INFO] No few-shot file found for prompt_type='star_rationalization' at 'few_shots/star_rationalization.json'. Using none.
2025-01-06 17:57:51,685 - star_logger_test - INFO - INFO 01-06 17:57:51 config.py:2272] Downcasting torch.float32 to torch.bfloat16.
2025-01-06 17:57:59,613 - star_logger_test - INFO - INFO 01-06 17:57:59 config.py:510] This model supports multiple tasks: {'embed', 'score', 'generate', 'classify', 'reward'}. Defaulting to 'generate'.
2025-01-06 17:57:59,615 - star_logger_test - INFO - INFO 01-06 17:57:59 config.py:1310] Defaulting to use mp for distributed inference
2025-01-06 17:57:59,615 - star_logger_test - INFO - WARNING 01-06 17:57:59 cuda.py:98] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
2025-01-06 17:57:59,616 - star_logger_test - INFO - WARNING 01-06 17:57:59 config.py:642] Async output processing is not supported on the current platform type cuda.
2025-01-06 17:57:59,626 - star_logger_test - INFO - INFO 01-06 17:57:59 llm_engine.py:234] Initializing an LLM engine (v0.6.6.post1) with config: model='luezzka/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='luezzka/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1024, download_dir='/home/data/v.moskvoretskii/cache/', load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=luezzka/Llama-3.2-1B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[],"max_capture_size":0}, use_cached_outputs=False, 
2025-01-06 17:58:00,746 - star_logger_test - INFO - WARNING 01-06 17:58:00 multiproc_worker_utils.py:312] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
2025-01-06 17:58:00,813 - star_logger_test - INFO - INFO 01-06 17:58:00 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
2025-01-06 17:58:02,107 - star_logger_test - INFO - INFO 01-06 17:58:02 selector.py:120] Using Flash Attention backend.
2025-01-06 17:58:02,127 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=218340)[0;0m INFO 01-06 17:58:02 selector.py:120] Using Flash Attention backend.
2025-01-06 17:58:02,127 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=218340)[0;0m INFO 01-06 17:58:02 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
2025-01-06 17:58:02,820 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=218340)[0;0m INFO 01-06 17:58:02 utils.py:918] Found nccl from library libnccl.so.2
2025-01-06 17:58:02,820 - star_logger_test - INFO - INFO 01-06 17:58:02 utils.py:918] Found nccl from library libnccl.so.2
2025-01-06 17:58:02,820 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=218340)[0;0m INFO 01-06 17:58:02 pynccl.py:69] vLLM is using nccl==2.21.5
2025-01-06 17:58:02,820 - star_logger_test - INFO - INFO 01-06 17:58:02 pynccl.py:69] vLLM is using nccl==2.21.5
2025-01-06 17:58:03,094 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=218340)[0;0m INFO 01-06 17:58:03 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
2025-01-06 17:58:03,094 - star_logger_test - INFO - INFO 01-06 17:58:03 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
2025-01-06 17:58:03,106 - star_logger_test - INFO - INFO 01-06 17:58:03 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_7c3eeec5'), local_subscribe_port=58655, remote_subscribe_port=None)
2025-01-06 17:58:03,111 - star_logger_test - INFO - INFO 01-06 17:58:03 model_runner.py:1094] Starting to load model luezzka/Llama-3.2-1B-Instruct...
2025-01-06 17:58:03,112 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=218340)[0;0m INFO 01-06 17:58:03 model_runner.py:1094] Starting to load model luezzka/Llama-3.2-1B-Instruct...
2025-01-06 17:58:03,625 - star_logger_test - INFO - INFO 01-06 17:58:03 weight_utils.py:251] Using model weights format ['*.safetensors']
2025-01-06 17:58:03,646 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=218340)[0;0m INFO 01-06 17:58:03 weight_utils.py:251] Using model weights format ['*.safetensors']
2025-01-06 17:58:03,947 - star_logger_test - INFO - INFO 01-06 17:58:03 weight_utils.py:296] No model.safetensors.index.json found in remote.
2025-01-06 17:58:03,949 - star_logger_test - ERROR - 
2025-01-06 17:58:03,949 - star_logger_test - ERROR - Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-01-06 17:58:04,266 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=218340)[0;0m INFO 01-06 17:58:04 weight_utils.py:296] No model.safetensors.index.json found in remote.
2025-01-06 17:58:04,730 - star_logger_test - ERROR - 
2025-01-06 17:58:04,730 - star_logger_test - ERROR - Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.28it/s]
2025-01-06 17:58:04,730 - star_logger_test - ERROR - 
2025-01-06 17:58:04,731 - star_logger_test - ERROR - Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.28it/s]
2025-01-06 17:58:04,731 - star_logger_test - ERROR - 
2025-01-06 17:58:05,072 - star_logger_test - INFO - INFO 01-06 17:58:05 model_runner.py:1099] Loading model weights took 1.1666 GB
2025-01-06 17:58:16,018 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=218340)[0;0m INFO 01-06 17:58:16 model_runner.py:1099] Loading model weights took 1.1666 GB
2025-01-06 17:58:18,614 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=218340)[0;0m INFO 01-06 17:58:18 worker.py:241] Memory profiling takes 2.59 seconds
2025-01-06 17:58:18,614 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=218340)[0;0m INFO 01-06 17:58:18 worker.py:241] the current vLLM instance can use total_gpu_memory (44.38GiB) x gpu_memory_utilization (0.99) = 43.94GiB
2025-01-06 17:58:18,614 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=218340)[0;0m INFO 01-06 17:58:18 worker.py:241] model weights take 1.17GiB; non_torch_memory takes 0.25GiB; PyTorch activation peak memory takes 0.08GiB; the rest of the memory reserved for KV Cache is 42.44GiB.
2025-01-06 17:58:18,756 - star_logger_test - INFO - INFO 01-06 17:58:18 worker.py:241] Memory profiling takes 2.74 seconds
2025-01-06 17:58:18,757 - star_logger_test - INFO - INFO 01-06 17:58:18 worker.py:241] the current vLLM instance can use total_gpu_memory (44.38GiB) x gpu_memory_utilization (0.99) = 43.94GiB
2025-01-06 17:58:18,757 - star_logger_test - INFO - INFO 01-06 17:58:18 worker.py:241] model weights take 1.17GiB; non_torch_memory takes 0.25GiB; PyTorch activation peak memory takes 1.18GiB; the rest of the memory reserved for KV Cache is 41.34GiB.
2025-01-06 17:58:18,961 - star_logger_test - INFO - INFO 01-06 17:58:18 distributed_gpu_executor.py:57] # GPU blocks: 169332, # CPU blocks: 16384
2025-01-06 17:58:18,961 - star_logger_test - INFO - INFO 01-06 17:58:18 distributed_gpu_executor.py:61] Maximum concurrency for 1024 tokens per request: 2645.81x
2025-01-06 17:58:21,262 - star_logger_test - INFO - INFO 01-06 17:58:21 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 5.24 seconds
2025-01-06 17:58:25,162 - star_logger_test - INFO - [INFO] Starting generation at 1/2
2025-01-06 17:58:25,163 - star_logger_test - ERROR - 
2025-01-06 17:58:26,271 - star_logger_test - INFO - INFO 01-06 17:58:26 model_runner_base.py:120] Writing input of failed execution to /tmp/err_execute_model_input_20250106-175826.pkl...
2025-01-06 17:58:26,279 - star_logger_test - INFO - INFO 01-06 17:58:26 model_runner_base.py:149] Completed writing input of failed execution to /tmp/err_execute_model_input_20250106-175826.pkl.
2025-01-06 17:58:26,282 - star_logger_test - ERROR - Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][rank0]: Traceback (most recent call last):
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/worker/model_runner_base.py", line 116, in _wrapper
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]:     return func(*args, **kwargs)
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/worker/model_runner.py", line 1747, in execute_model
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]:     output: SamplerOutput = self.model.sample(
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/llama.py", line 584, in sample
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]:     next_tokens = self.sampler(logits, sampling_metadata)
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]:     return self._call_impl(*args, **kwargs)
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1747, in _call_impl
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]:     return forward_call(*args, **kwargs)
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/sampler.py", line 274, in forward
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]:     logits = _apply_top_k_top_p(logits, sampling_tensors.top_ps,
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/sampler.py", line 392, in _apply_top_k_top_p
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]:     logits_sort, logits_idx = logits.sort(dim=-1, descending=False)
2025-01-06 17:58:26,282 - star_logger_test - ERROR - [rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacity of 44.38 GiB of which 244.62 MiB is free. Process 3323234 has 44.13 GiB memory in use. Of the allocated memory 43.32 GiB is allocated by PyTorch, and 347.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-06 17:58:26,282 - star_logger_test - ERROR - 
2025-01-06 17:58:26,283 - star_logger_test - ERROR - [rank0]: The above exception was the direct cause of the following exception:
2025-01-06 17:58:26,283 - star_logger_test - ERROR - 
2025-01-06 17:58:26,283 - star_logger_test - ERROR - [rank0]: Traceback (most recent call last):
2025-01-06 17:58:26,283 - star_logger_test - ERROR - [rank0]:   File "/home/data/v.moskvoretskii/QAC/star_vllm_generation.py", line 328, in <module>
2025-01-06 17:58:26,283 - star_logger_test - ERROR - [rank0]:     main()
2025-01-06 17:58:26,283 - star_logger_test - ERROR - [rank0]:   File "/home/data/v.moskvoretskii/QAC/star_vllm_generation.py", line 279, in main
2025-01-06 17:58:26,283 - star_logger_test - ERROR - [rank0]:     train_data = perform_generation(
2025-01-06 17:58:26,283 - star_logger_test - ERROR - [rank0]:   File "/home/data/v.moskvoretskii/QAC/star_vllm_generation.py", line 203, in perform_generation
2025-01-06 17:58:26,283 - star_logger_test - ERROR - [rank0]:     generation_results = generate_for_dataset(
2025-01-06 17:58:26,283 - star_logger_test - ERROR - [rank0]:   File "/home/data/v.moskvoretskii/QAC/generation_utils.py", line 184, in generate_for_dataset
2025-01-06 17:58:26,283 - star_logger_test - ERROR - [rank0]:     generation_results = model.generate(all_prompts, sampling_params)
2025-01-06 17:58:26,283 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/utils.py", line 1021, in inner
2025-01-06 17:58:26,283 - star_logger_test - ERROR - [rank0]:     return fn(*args, **kwargs)
2025-01-06 17:58:26,283 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/llm.py", line 462, in generate
2025-01-06 17:58:26,284 - star_logger_test - ERROR - [rank0]:     outputs = self._run_engine(use_tqdm=use_tqdm)
2025-01-06 17:58:26,284 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/llm.py", line 1242, in _run_engine
2025-01-06 17:58:26,284 - star_logger_test - ERROR - [rank0]:     step_outputs = self.llm_engine.step()
2025-01-06 17:58:26,284 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py", line 1390, in step
2025-01-06 17:58:26,284 - star_logger_test - ERROR - [rank0]:     outputs = self.model_executor.execute_model(
2025-01-06 17:58:26,284 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/executor/distributed_gpu_executor.py", line 82, in execute_model
2025-01-06 17:58:26,284 - star_logger_test - ERROR - [rank0]:     driver_outputs = self._driver_execute_model(execute_model_req)
2025-01-06 17:58:26,284 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/executor/multiproc_gpu_executor.py", line 120, in _driver_execute_model
2025-01-06 17:58:26,284 - star_logger_test - ERROR - [rank0]:     return self.driver_worker.execute_model(execute_model_req)
2025-01-06 17:58:26,284 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/worker/worker_base.py", line 343, in execute_model
2025-01-06 17:58:26,284 - star_logger_test - ERROR - [rank0]:     output = self.model_runner.execute_model(
2025-01-06 17:58:26,284 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
2025-01-06 17:58:26,284 - star_logger_test - ERROR - [rank0]:     return func(*args, **kwargs)
2025-01-06 17:58:26,284 - star_logger_test - ERROR - [rank0]:   File "/usr/local/lib/python3.10/dist-packages/vllm/worker/model_runner_base.py", line 152, in _wrapper
2025-01-06 17:58:26,285 - star_logger_test - ERROR - [rank0]:     raise type(err)(
2025-01-06 17:58:26,285 - star_logger_test - ERROR - [rank0]: torch.OutOfMemoryError: Error in model execution (input dumped to /tmp/err_execute_model_input_20250106-175826.pkl): CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacity of 44.38 GiB of which 244.62 MiB is free. Process 3323234 has 44.13 GiB memory in use. Of the allocated memory 43.32 GiB is allocated by PyTorch, and 347.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-01-06 17:58:27,807 - star_logger_test - ERROR - 
2025-01-06 17:58:27,807 - star_logger_test - ERROR - Processed prompts:   0%|          | 0/500 [00:02<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
2025-01-06 17:58:28,699 - star_logger_test - ERROR - [rank0]:[W106 17:58:28.688513612 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
2025-01-06 17:58:29,662 - star_logger_test - ERROR - /usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
2025-01-06 17:58:29,663 - star_logger_test - ERROR -   warnings.warn('resource_tracker: There appear to be %d '
2025-01-06 17:59:01,577 - star_logger_test - INFO - [INFO] Starting iteration 1/2
2025-01-06 17:59:01,577 - star_logger_test - INFO - Running command: python star_vllm_generation.py --config_path configs/star_config.yaml --generation_model_path luezzka/Llama-3.2-1B-Instruct --ft_dataset_path /home/data/v.moskvoretskii/cache/STaR/test/data/data_0 --iteration 0
2025-01-06 17:59:10,093 - star_logger_test - INFO - [INFO] No few-shot file found for prompt_type='star_generation' at 'few_shots/star_generation.json'. Using none.
2025-01-06 17:59:10,093 - star_logger_test - INFO - [INFO] No few-shot file found for prompt_type='star_rationalization' at 'few_shots/star_rationalization.json'. Using none.
2025-01-06 17:59:10,093 - star_logger_test - INFO - INFO 01-06 17:59:10 config.py:2272] Downcasting torch.float32 to torch.bfloat16.
2025-01-06 17:59:18,319 - star_logger_test - INFO - INFO 01-06 17:59:18 config.py:510] This model supports multiple tasks: {'embed', 'score', 'classify', 'generate', 'reward'}. Defaulting to 'generate'.
2025-01-06 17:59:18,319 - star_logger_test - INFO - INFO 01-06 17:59:18 config.py:1310] Defaulting to use mp for distributed inference
2025-01-06 17:59:18,320 - star_logger_test - INFO - WARNING 01-06 17:59:18 cuda.py:98] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
2025-01-06 17:59:18,320 - star_logger_test - INFO - WARNING 01-06 17:59:18 config.py:642] Async output processing is not supported on the current platform type cuda.
2025-01-06 17:59:18,323 - star_logger_test - INFO - INFO 01-06 17:59:18 llm_engine.py:234] Initializing an LLM engine (v0.6.6.post1) with config: model='luezzka/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='luezzka/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1024, download_dir='/home/data/v.moskvoretskii/cache/', load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=luezzka/Llama-3.2-1B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[],"max_capture_size":0}, use_cached_outputs=False, 
2025-01-06 17:59:19,345 - star_logger_test - INFO - WARNING 01-06 17:59:19 multiproc_worker_utils.py:312] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
2025-01-06 17:59:19,367 - star_logger_test - INFO - INFO 01-06 17:59:19 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
2025-01-06 17:59:20,719 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=219627)[0;0m INFO 01-06 17:59:20 selector.py:120] Using Flash Attention backend.
2025-01-06 17:59:20,719 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=219627)[0;0m INFO 01-06 17:59:20 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
2025-01-06 17:59:20,739 - star_logger_test - INFO - INFO 01-06 17:59:20 selector.py:120] Using Flash Attention backend.
2025-01-06 17:59:22,160 - star_logger_test - INFO - INFO 01-06 17:59:22 utils.py:918] Found nccl from library libnccl.so.2
2025-01-06 17:59:22,161 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=219627)[0;0m INFO 01-06 17:59:22 utils.py:918] Found nccl from library libnccl.so.2
2025-01-06 17:59:22,161 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=219627)[0;0m INFO 01-06 17:59:22 pynccl.py:69] vLLM is using nccl==2.21.5
2025-01-06 17:59:22,161 - star_logger_test - INFO - INFO 01-06 17:59:22 pynccl.py:69] vLLM is using nccl==2.21.5
2025-01-06 17:59:22,452 - star_logger_test - INFO - INFO 01-06 17:59:22 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
2025-01-06 17:59:22,452 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=219627)[0;0m INFO 01-06 17:59:22 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
2025-01-06 17:59:22,465 - star_logger_test - INFO - INFO 01-06 17:59:22 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_649853b4'), local_subscribe_port=43051, remote_subscribe_port=None)
2025-01-06 17:59:22,471 - star_logger_test - INFO - INFO 01-06 17:59:22 model_runner.py:1094] Starting to load model luezzka/Llama-3.2-1B-Instruct...
2025-01-06 17:59:22,472 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=219627)[0;0m INFO 01-06 17:59:22 model_runner.py:1094] Starting to load model luezzka/Llama-3.2-1B-Instruct...
2025-01-06 17:59:22,977 - star_logger_test - INFO - INFO 01-06 17:59:22 weight_utils.py:251] Using model weights format ['*.safetensors']
2025-01-06 17:59:23,004 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=219627)[0;0m INFO 01-06 17:59:23 weight_utils.py:251] Using model weights format ['*.safetensors']
2025-01-06 17:59:23,293 - star_logger_test - INFO - INFO 01-06 17:59:23 weight_utils.py:296] No model.safetensors.index.json found in remote.
2025-01-06 17:59:23,295 - star_logger_test - ERROR - 
2025-01-06 17:59:23,295 - star_logger_test - ERROR - Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-01-06 17:59:23,616 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=219627)[0;0m INFO 01-06 17:59:23 weight_utils.py:296] No model.safetensors.index.json found in remote.
2025-01-06 17:59:24,029 - star_logger_test - ERROR - 
2025-01-06 17:59:24,029 - star_logger_test - ERROR - Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.36it/s]
2025-01-06 17:59:24,029 - star_logger_test - ERROR - 
2025-01-06 17:59:24,029 - star_logger_test - ERROR - Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.36it/s]
2025-01-06 17:59:24,029 - star_logger_test - ERROR - 
2025-01-06 17:59:24,324 - star_logger_test - INFO - INFO 01-06 17:59:24 model_runner.py:1099] Loading model weights took 1.1666 GB
2025-01-06 17:59:26,988 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=219627)[0;0m INFO 01-06 17:59:26 model_runner.py:1099] Loading model weights took 1.1666 GB
2025-01-06 17:59:29,542 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=219627)[0;0m INFO 01-06 17:59:29 worker.py:241] Memory profiling takes 2.55 seconds
2025-01-06 17:59:29,542 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=219627)[0;0m INFO 01-06 17:59:29 worker.py:241] the current vLLM instance can use total_gpu_memory (44.38GiB) x gpu_memory_utilization (0.50) = 22.19GiB
2025-01-06 17:59:29,542 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=219627)[0;0m INFO 01-06 17:59:29 worker.py:241] model weights take 1.17GiB; non_torch_memory takes 0.25GiB; PyTorch activation peak memory takes 0.08GiB; the rest of the memory reserved for KV Cache is 20.69GiB.
2025-01-06 17:59:29,640 - star_logger_test - INFO - INFO 01-06 17:59:29 worker.py:241] Memory profiling takes 2.65 seconds
2025-01-06 17:59:29,641 - star_logger_test - INFO - INFO 01-06 17:59:29 worker.py:241] the current vLLM instance can use total_gpu_memory (44.38GiB) x gpu_memory_utilization (0.50) = 22.19GiB
2025-01-06 17:59:29,641 - star_logger_test - INFO - INFO 01-06 17:59:29 worker.py:241] model weights take 1.17GiB; non_torch_memory takes 0.25GiB; PyTorch activation peak memory takes 1.18GiB; the rest of the memory reserved for KV Cache is 19.59GiB.
2025-01-06 17:59:29,850 - star_logger_test - INFO - INFO 01-06 17:59:29 distributed_gpu_executor.py:57] # GPU blocks: 80251, # CPU blocks: 16384
2025-01-06 17:59:29,850 - star_logger_test - INFO - INFO 01-06 17:59:29 distributed_gpu_executor.py:61] Maximum concurrency for 1024 tokens per request: 1253.92x
2025-01-06 17:59:31,959 - star_logger_test - INFO - INFO 01-06 17:59:31 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 4.97 seconds
2025-01-06 17:59:34,502 - star_logger_test - INFO - [INFO] Starting generation at 1/2
2025-01-06 17:59:34,502 - star_logger_test - ERROR - 
2025-01-06 17:59:37,143 - star_logger_test - ERROR - Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
2025-01-06 17:59:39,907 - star_logger_test - ERROR - Processed prompts:   0%|          | 1/500 [00:02<21:57,  2.64s/it, est. speed input: 41.67 toks/s, output: 10.98 toks/s]
2025-01-06 17:59:40,769 - star_logger_test - ERROR - Processed prompts:   0%|          | 2/500 [00:05<22:31,  2.71s/it, est. speed input: 40.34 toks/s, output: 19.24 toks/s]
2025-01-06 17:59:41,268 - star_logger_test - ERROR - Processed prompts:   1%|          | 3/500 [00:06<15:28,  1.87s/it, est. speed input: 52.82 toks/s, output: 30.96 toks/s]
2025-01-06 17:59:41,762 - star_logger_test - ERROR - Processed prompts:   1%|          | 4/500 [00:06<10:58,  1.33s/it, est. speed input: 65.33 toks/s, output: 43.16 toks/s]
2025-01-06 17:59:42,706 - star_logger_test - ERROR - Processed prompts:   1%|          | 6/500 [00:07<06:12,  1.32it/s, est. speed input: 90.77 toks/s, output: 68.46 toks/s]
2025-01-06 17:59:42,948 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 8/500 [00:08<05:11,  1.58it/s, est. speed input: 108.12 toks/s, output: 88.50 toks/s]
2025-01-06 17:59:43,074 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 9/500 [00:08<04:25,  1.85it/s, est. speed input: 118.53 toks/s, output: 100.88 toks/s]
2025-01-06 17:59:43,214 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 10/500 [00:08<03:33,  2.29it/s, est. speed input: 129.50 toks/s, output: 114.33 toks/s]
2025-01-06 17:59:43,569 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 12/500 [00:08<02:18,  3.53it/s, est. speed input: 152.56 toks/s, output: 142.23 toks/s]
2025-01-06 17:59:43,834 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 13/500 [00:09<02:26,  3.33it/s, est. speed input: 158.71 toks/s, output: 151.65 toks/s]
2025-01-06 17:59:44,020 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 15/500 [00:09<01:53,  4.28it/s, est. speed input: 177.99 toks/s, output: 177.02 toks/s]
2025-01-06 17:59:44,148 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 16/500 [00:09<01:47,  4.49it/s, est. speed input: 186.50 toks/s, output: 188.60 toks/s]
2025-01-06 17:59:44,276 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 17/500 [00:09<01:36,  5.00it/s, est. speed input: 195.43 toks/s, output: 201.13 toks/s]
2025-01-06 17:59:44,477 - star_logger_test - ERROR - Processed prompts:   4%|▎         | 18/500 [00:09<01:27,  5.50it/s, est. speed input: 204.22 toks/s, output: 213.52 toks/s]
2025-01-06 17:59:44,679 - star_logger_test - ERROR - Processed prompts:   4%|▍         | 20/500 [00:09<01:10,  6.78it/s, est. speed input: 222.06 toks/s, output: 239.11 toks/s]
2025-01-06 17:59:44,822 - star_logger_test - ERROR - Processed prompts:   4%|▍         | 22/500 [00:10<01:02,  7.69it/s, est. speed input: 239.28 toks/s, output: 264.24 toks/s]
2025-01-06 17:59:44,960 - star_logger_test - ERROR - Processed prompts:   5%|▍         | 23/500 [00:10<01:03,  7.53it/s, est. speed input: 246.72 toks/s, output: 275.60 toks/s]
2025-01-06 17:59:45,212 - star_logger_test - ERROR - Processed prompts:   5%|▍         | 24/500 [00:10<01:03,  7.46it/s, est. speed input: 254.35 toks/s, output: 286.95 toks/s]
2025-01-06 17:59:45,370 - star_logger_test - ERROR - Processed prompts:   5%|▌         | 25/500 [00:10<01:17,  6.12it/s, est. speed input: 258.54 toks/s, output: 295.24 toks/s]
2025-01-06 17:59:45,518 - star_logger_test - ERROR - Processed prompts:   6%|▌         | 29/500 [00:10<00:42, 11.03it/s, est. speed input: 295.18 toks/s, output: 350.48 toks/s]
2025-01-06 17:59:45,664 - star_logger_test - ERROR - Processed prompts:   7%|▋         | 33/500 [00:11<00:30, 15.12it/s, est. speed input: 331.35 toks/s, output: 405.24 toks/s]
2025-01-06 17:59:45,923 - star_logger_test - ERROR - Processed prompts:   7%|▋         | 37/500 [00:11<00:25, 18.38it/s, est. speed input: 366.36 toks/s, output: 459.45 toks/s]
2025-01-06 17:59:46,066 - star_logger_test - ERROR - Processed prompts:   8%|▊         | 39/500 [00:11<00:32, 14.08it/s, est. speed input: 377.28 toks/s, output: 478.76 toks/s]
2025-01-06 17:59:46,270 - star_logger_test - ERROR - Processed prompts:   8%|▊         | 41/500 [00:11<00:32, 14.07it/s, est. speed input: 391.49 toks/s, output: 502.70 toks/s]
2025-01-06 17:59:46,484 - star_logger_test - ERROR - Processed prompts:   9%|▉         | 45/500 [00:11<00:28, 15.90it/s, est. speed input: 422.27 toks/s, output: 553.06 toks/s]
2025-01-06 17:59:46,618 - star_logger_test - ERROR - Processed prompts:   9%|▉         | 47/500 [00:11<00:33, 13.72it/s, est. speed input: 433.16 toks/s, output: 572.87 toks/s]
2025-01-06 17:59:46,763 - star_logger_test - ERROR - Processed prompts:  10%|█         | 50/500 [00:12<00:28, 15.71it/s, est. speed input: 455.54 toks/s, output: 611.04 toks/s]
2025-01-06 17:59:46,968 - star_logger_test - ERROR - Processed prompts:  10%|█         | 52/500 [00:12<00:29, 15.21it/s, est. speed input: 468.58 toks/s, output: 633.50 toks/s]
2025-01-06 17:59:47,112 - star_logger_test - ERROR - Processed prompts:  11%|█         | 56/500 [00:12<00:26, 16.70it/s, est. speed input: 496.74 toks/s, output: 682.29 toks/s]
2025-01-06 17:59:47,261 - star_logger_test - ERROR - Processed prompts:  12%|█▏        | 58/500 [00:12<00:27, 15.96it/s, est. speed input: 508.49 toks/s, output: 704.21 toks/s]
2025-01-06 17:59:47,467 - star_logger_test - ERROR - Processed prompts:  12%|█▏        | 62/500 [00:12<00:23, 18.95it/s, est. speed input: 538.21 toks/s, output: 755.24 toks/s]
2025-01-06 17:59:47,614 - star_logger_test - ERROR - Processed prompts:  13%|█▎        | 64/500 [00:12<00:27, 15.69it/s, est. speed input: 546.77 toks/s, output: 772.84 toks/s]
2025-01-06 17:59:47,749 - star_logger_test - ERROR - Processed prompts:  13%|█▎        | 66/500 [00:13<00:28, 15.15it/s, est. speed input: 557.51 toks/s, output: 793.86 toks/s]
2025-01-06 17:59:47,894 - star_logger_test - ERROR - Processed prompts:  14%|█▎        | 68/500 [00:13<00:28, 15.05it/s, est. speed input: 568.12 toks/s, output: 815.35 toks/s]
2025-01-06 17:59:48,106 - star_logger_test - ERROR - Processed prompts:  14%|█▍        | 70/500 [00:13<00:29, 14.70it/s, est. speed input: 579.00 toks/s, output: 836.24 toks/s]
2025-01-06 17:59:48,255 - star_logger_test - ERROR - Processed prompts:  14%|█▍        | 72/500 [00:13<00:33, 12.76it/s, est. speed input: 586.04 toks/s, output: 852.81 toks/s]
2025-01-06 17:59:48,387 - star_logger_test - ERROR - Processed prompts:  15%|█▍        | 74/500 [00:13<00:32, 12.94it/s, est. speed input: 595.96 toks/s, output: 873.15 toks/s]
2025-01-06 17:59:48,527 - star_logger_test - ERROR - Processed prompts:  15%|█▌        | 76/500 [00:13<00:31, 13.49it/s, est. speed input: 606.26 toks/s, output: 894.34 toks/s]
2025-01-06 17:59:48,753 - star_logger_test - ERROR - Processed prompts:  16%|█▌        | 79/500 [00:14<00:26, 15.72it/s, est. speed input: 623.62 toks/s, output: 929.66 toks/s]
2025-01-06 17:59:48,901 - star_logger_test - ERROR - Processed prompts:  16%|█▌        | 81/500 [00:14<00:32, 13.02it/s, est. speed input: 629.08 toks/s, output: 944.36 toks/s]
2025-01-06 17:59:49,053 - star_logger_test - ERROR - Processed prompts:  17%|█▋        | 83/500 [00:14<00:31, 13.15it/s, est. speed input: 638.04 toks/s, output: 964.17 toks/s]
2025-01-06 17:59:49,320 - star_logger_test - ERROR - Processed prompts:  18%|█▊        | 89/500 [00:14<00:19, 20.59it/s, est. speed input: 676.67 toks/s, output: 1042.21 toks/s]
2025-01-06 17:59:49,645 - star_logger_test - ERROR - Processed prompts:  18%|█▊        | 92/500 [00:14<00:24, 16.71it/s, est. speed input: 686.81 toks/s, output: 1067.37 toks/s]
2025-01-06 17:59:49,794 - star_logger_test - ERROR - Processed prompts:  19%|█▉        | 94/500 [00:15<00:33, 12.28it/s, est. speed input: 686.39 toks/s, output: 1073.84 toks/s]
2025-01-06 17:59:49,946 - star_logger_test - ERROR - Processed prompts:  19%|█▉        | 96/500 [00:15<00:32, 12.54it/s, est. speed input: 693.86 toks/s, output: 1092.91 toks/s]
2025-01-06 17:59:50,098 - star_logger_test - ERROR - Processed prompts:  20%|█▉        | 99/500 [00:15<00:28, 14.25it/s, est. speed input: 708.44 toks/s, output: 1118.12 toks/s]
2025-01-06 17:59:50,312 - star_logger_test - ERROR - Processed prompts:  20%|██        | 102/500 [00:15<00:25, 15.66it/s, est. speed input: 722.78 toks/s, output: 1151.30 toks/s]
2025-01-06 17:59:50,530 - star_logger_test - ERROR - Processed prompts:  21%|██        | 105/500 [00:15<00:26, 15.09it/s, est. speed input: 733.71 toks/s, output: 1179.63 toks/s]
2025-01-06 17:59:50,678 - star_logger_test - ERROR - Processed prompts:  22%|██▏       | 109/500 [00:16<00:24, 16.18it/s, est. speed input: 751.41 toks/s, output: 1222.04 toks/s]
2025-01-06 17:59:50,809 - star_logger_test - ERROR - Processed prompts:  23%|██▎       | 113/500 [00:16<00:20, 18.79it/s, est. speed input: 771.70 toks/s, output: 1269.35 toks/s]
2025-01-06 17:59:50,953 - star_logger_test - ERROR - Processed prompts:  23%|██▎       | 115/500 [00:16<00:21, 17.98it/s, est. speed input: 778.95 toks/s, output: 1288.50 toks/s]
2025-01-06 17:59:51,163 - star_logger_test - ERROR - Processed prompts:  23%|██▎       | 117/500 [00:16<00:22, 16.89it/s, est. speed input: 785.52 toks/s, output: 1306.61 toks/s]
2025-01-06 17:59:51,335 - star_logger_test - ERROR - Processed prompts:  24%|██▍       | 121/500 [00:16<00:21, 17.64it/s, est. speed input: 802.12 toks/s, output: 1348.42 toks/s]
2025-01-06 17:59:51,482 - star_logger_test - ERROR - Processed prompts:  25%|██▍       | 124/500 [00:16<00:21, 17.59it/s, est. speed input: 813.65 toks/s, output: 1378.56 toks/s]
2025-01-06 17:59:51,685 - star_logger_test - ERROR - Processed prompts:  25%|██▌       | 126/500 [00:16<00:22, 16.53it/s, est. speed input: 819.63 toks/s, output: 1395.90 toks/s]
2025-01-06 17:59:51,901 - star_logger_test - ERROR - Processed prompts:  26%|██▌       | 128/500 [00:17<00:26, 14.24it/s, est. speed input: 822.86 toks/s, output: 1408.57 toks/s]
2025-01-06 17:59:53,258 - star_logger_test - ERROR - Processed prompts:  26%|██▌       | 130/500 [00:17<00:29, 12.53it/s, est. speed input: 825.13 toks/s, output: 1420.23 toks/s]
2025-01-06 17:59:54,754 - star_logger_test - ERROR - Processed prompts:  52%|█████▏    | 258/500 [00:18<00:03, 74.29it/s, est. speed input: 1521.11 toks/s, output: 3059.01 toks/s]
2025-01-06 17:59:55,307 - star_logger_test - ERROR - Processed prompts:  52%|█████▏    | 262/500 [00:20<00:06, 35.38it/s, est. speed input: 1430.52 toks/s, output: 2868.24 toks/s]
2025-01-06 17:59:55,416 - star_logger_test - ERROR - Processed prompts:  53%|█████▎    | 265/500 [00:20<00:08, 28.70it/s, est. speed input: 1408.56 toks/s, output: 2812.93 toks/s]
2025-01-06 17:59:56,438 - star_logger_test - ERROR - Processed prompts:  54%|█████▎    | 268/500 [00:20<00:08, 28.64it/s, est. speed input: 1416.92 toks/s, output: 2815.39 toks/s]
2025-01-06 17:59:56,547 - star_logger_test - ERROR - Processed prompts:  54%|█████▍    | 271/500 [00:21<00:13, 17.28it/s, est. speed input: 1365.97 toks/s, output: 2712.16 toks/s]
2025-01-06 17:59:57,292 - star_logger_test - ERROR - Processed prompts:  55%|█████▍    | 273/500 [00:22<00:13, 17.35it/s, est. speed input: 1369.31 toks/s, output: 2712.76 toks/s]
2025-01-06 17:59:57,397 - star_logger_test - ERROR - Processed prompts:  55%|█████▌    | 275/500 [00:22<00:19, 11.76it/s, est. speed input: 1334.12 toks/s, output: 2643.88 toks/s]
2025-01-06 17:59:57,675 - star_logger_test - ERROR - Processed prompts:  55%|█████▌    | 277/500 [00:22<00:18, 12.28it/s, est. speed input: 1337.73 toks/s, output: 2649.07 toks/s]
2025-01-06 17:59:57,834 - star_logger_test - ERROR - Processed prompts:  56%|█████▌    | 279/500 [00:23<00:19, 11.20it/s, est. speed input: 1331.05 toks/s, output: 2637.79 toks/s]
2025-01-06 17:59:58,054 - star_logger_test - ERROR - Processed prompts:  56%|█████▋    | 282/500 [00:23<00:17, 12.34it/s, est. speed input: 1336.23 toks/s, output: 2637.18 toks/s]
2025-01-06 17:59:58,267 - star_logger_test - ERROR - Processed prompts:  57%|█████▋    | 284/500 [00:23<00:18, 11.60it/s, est. speed input: 1333.10 toks/s, output: 2629.84 toks/s]
2025-01-06 17:59:58,471 - star_logger_test - ERROR - Processed prompts:  58%|█████▊    | 288/500 [00:23<00:15, 13.31it/s, est. speed input: 1339.75 toks/s, output: 2640.02 toks/s]
2025-01-06 17:59:58,584 - star_logger_test - ERROR - Processed prompts:  58%|█████▊    | 291/500 [00:23<00:15, 13.65it/s, est. speed input: 1342.19 toks/s, output: 2639.99 toks/s]
2025-01-06 17:59:58,738 - star_logger_test - ERROR - Processed prompts:  59%|█████▊    | 293/500 [00:24<00:14, 14.32it/s, est. speed input: 1345.02 toks/s, output: 2643.45 toks/s]
2025-01-06 17:59:59,447 - star_logger_test - ERROR - Processed prompts:  59%|█████▉    | 295/500 [00:24<00:14, 13.99it/s, est. speed input: 1345.44 toks/s, output: 2636.34 toks/s]
2025-01-06 17:59:59,695 - star_logger_test - ERROR - Processed prompts:  59%|█████▉    | 297/500 [00:24<00:28,  7.14it/s, est. speed input: 1316.25 toks/s, output: 2571.85 toks/s]
2025-01-06 17:59:59,891 - star_logger_test - ERROR - Processed prompts:  60%|█████▉    | 299/500 [00:25<00:27,  7.37it/s, est. speed input: 1312.03 toks/s, output: 2566.94 toks/s]
2025-01-06 18:00:00,037 - star_logger_test - ERROR - Processed prompts:  61%|██████    | 305/500 [00:25<00:15, 12.23it/s, est. speed input: 1328.08 toks/s, output: 2584.62 toks/s]
2025-01-06 18:00:00,181 - star_logger_test - ERROR - Processed prompts:  62%|██████▏   | 309/500 [00:25<00:12, 14.99it/s, est. speed input: 1337.78 toks/s, output: 2598.36 toks/s]
2025-01-06 18:00:00,383 - star_logger_test - ERROR - Processed prompts:  63%|██████▎   | 313/500 [00:25<00:10, 17.60it/s, est. speed input: 1347.29 toks/s, output: 2615.64 toks/s]
2025-01-06 18:00:00,534 - star_logger_test - ERROR - Processed prompts:  63%|██████▎   | 316/500 [00:25<00:10, 16.80it/s, est. speed input: 1349.84 toks/s, output: 2619.18 toks/s]
2025-01-06 18:00:00,726 - star_logger_test - ERROR - Processed prompts:  64%|██████▍   | 321/500 [00:26<00:08, 20.67it/s, est. speed input: 1363.14 toks/s, output: 2641.42 toks/s]
2025-01-06 18:00:00,962 - star_logger_test - ERROR - Processed prompts:  65%|██████▍   | 324/500 [00:26<00:09, 19.16it/s, est. speed input: 1365.80 toks/s, output: 2640.30 toks/s]
2025-01-06 18:00:01,202 - star_logger_test - ERROR - Processed prompts:  66%|██████▌   | 328/500 [00:26<00:09, 18.40it/s, est. speed input: 1370.29 toks/s, output: 2646.93 toks/s]
2025-01-06 18:00:01,327 - star_logger_test - ERROR - Processed prompts:  66%|██████▌   | 331/500 [00:26<00:10, 16.42it/s, est. speed input: 1370.47 toks/s, output: 2648.13 toks/s]
2025-01-06 18:00:01,473 - star_logger_test - ERROR - Processed prompts:  67%|██████▋   | 334/500 [00:26<00:09, 17.93it/s, est. speed input: 1376.50 toks/s, output: 2661.40 toks/s]
2025-01-06 18:00:01,600 - star_logger_test - ERROR - Processed prompts:  67%|██████▋   | 337/500 [00:26<00:08, 18.58it/s, est. speed input: 1381.32 toks/s, output: 2674.50 toks/s]
2025-01-06 18:00:01,725 - star_logger_test - ERROR - Processed prompts:  68%|██████▊   | 340/500 [00:27<00:08, 19.76it/s, est. speed input: 1386.85 toks/s, output: 2685.38 toks/s]
2025-01-06 18:00:01,846 - star_logger_test - ERROR - Processed prompts:  69%|██████▉   | 346/500 [00:27<00:05, 26.84it/s, est. speed input: 1404.87 toks/s, output: 2725.87 toks/s]
2025-01-06 18:00:01,966 - star_logger_test - ERROR - Processed prompts:  70%|███████   | 351/500 [00:27<00:04, 30.54it/s, est. speed input: 1419.09 toks/s, output: 2753.58 toks/s]
2025-01-06 18:00:02,084 - star_logger_test - ERROR - Processed prompts:  71%|███████   | 355/500 [00:27<00:04, 31.30it/s, est. speed input: 1429.02 toks/s, output: 2775.43 toks/s]
2025-01-06 18:00:02,201 - star_logger_test - ERROR - Processed prompts:  73%|███████▎  | 363/500 [00:27<00:03, 41.22it/s, est. speed input: 1454.76 toks/s, output: 2816.24 toks/s]
2025-01-06 18:00:02,309 - star_logger_test - ERROR - Processed prompts:  74%|███████▍  | 370/500 [00:27<00:02, 46.37it/s, est. speed input: 1476.40 toks/s, output: 2859.12 toks/s]
2025-01-06 18:00:02,527 - star_logger_test - ERROR - Processed prompts:  76%|███████▌  | 380/500 [00:27<00:02, 58.81it/s, est. speed input: 1510.31 toks/s, output: 2922.73 toks/s]
2025-01-06 18:00:02,729 - star_logger_test - ERROR - Processed prompts:  77%|███████▋  | 387/500 [00:28<00:02, 47.20it/s, est. speed input: 1525.81 toks/s, output: 2952.03 toks/s]
2025-01-06 18:00:02,858 - star_logger_test - ERROR - Processed prompts:  79%|███████▊  | 393/500 [00:28<00:02, 40.76it/s, est. speed input: 1538.43 toks/s, output: 2976.92 toks/s]
2025-01-06 18:00:02,987 - star_logger_test - ERROR - Processed prompts:  80%|███████▉  | 399/500 [00:28<00:02, 42.18it/s, est. speed input: 1554.77 toks/s, output: 3012.76 toks/s]
2025-01-06 18:00:03,140 - star_logger_test - ERROR - Processed prompts:  81%|████████  | 405/500 [00:28<00:02, 43.39it/s, est. speed input: 1571.43 toks/s, output: 3046.77 toks/s]
2025-01-06 18:00:03,264 - star_logger_test - ERROR - Processed prompts:  82%|████████▏ | 410/500 [00:28<00:02, 40.05it/s, est. speed input: 1582.43 toks/s, output: 3072.11 toks/s]
2025-01-06 18:00:03,414 - star_logger_test - ERROR - Processed prompts:  83%|████████▎ | 416/500 [00:28<00:01, 42.28it/s, est. speed input: 1598.79 toks/s, output: 3109.85 toks/s]
2025-01-06 18:00:03,583 - star_logger_test - ERROR - Processed prompts:  84%|████████▍ | 421/500 [00:28<00:02, 39.48it/s, est. speed input: 1609.41 toks/s, output: 3133.90 toks/s]
2025-01-06 18:00:03,713 - star_logger_test - ERROR - Processed prompts:  85%|████████▌ | 426/500 [00:29<00:02, 36.13it/s, est. speed input: 1619.39 toks/s, output: 3157.66 toks/s]
2025-01-06 18:00:03,814 - star_logger_test - ERROR - Processed prompts:  86%|████████▌ | 431/500 [00:29<00:01, 36.73it/s, est. speed input: 1630.99 toks/s, output: 3186.32 toks/s]
2025-01-06 18:00:03,916 - star_logger_test - ERROR - Processed prompts:  88%|████████▊ | 438/500 [00:29<00:01, 44.30it/s, est. speed input: 1651.96 toks/s, output: 3233.09 toks/s]
2025-01-06 18:00:04,029 - star_logger_test - ERROR - Processed prompts:  89%|████████▊ | 443/500 [00:29<00:01, 45.43it/s, est. speed input: 1664.94 toks/s, output: 3263.92 toks/s]
2025-01-06 18:00:04,180 - star_logger_test - ERROR - Processed prompts:  90%|████████▉ | 448/500 [00:29<00:01, 45.06it/s, est. speed input: 1677.45 toks/s, output: 3292.88 toks/s]
2025-01-06 18:00:04,273 - star_logger_test - ERROR - Processed prompts:  91%|█████████ | 454/500 [00:29<00:01, 43.23it/s, est. speed input: 1691.30 toks/s, output: 3327.21 toks/s]
2025-01-06 18:00:04,273 - star_logger_test - ERROR - Processed prompts: 100%|██████████| 500/500 [00:29<00:00, 16.80it/s, est. speed input: 1856.95 toks/s, output: 3712.35 toks/s]
2025-01-06 18:00:04,833 - star_logger_test - INFO - [INFO] Starting rationalization at 1/2
2025-01-06 18:00:04,833 - star_logger_test - ERROR - 
2025-01-06 18:00:10,021 - star_logger_test - ERROR - Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
2025-01-06 18:00:10,976 - star_logger_test - ERROR - Processed prompts:   0%|          | 1/500 [00:05<43:08,  5.19s/it, est. speed input: 28.53 toks/s, output: 13.69 toks/s]
2025-01-06 18:00:11,239 - star_logger_test - ERROR - Processed prompts:   0%|          | 2/500 [00:06<22:23,  2.70s/it, est. speed input: 47.70 toks/s, output: 25.72 toks/s]
2025-01-06 18:00:11,435 - star_logger_test - ERROR - Processed prompts:   1%|          | 3/500 [00:06<13:08,  1.59s/it, est. speed input: 68.69 toks/s, output: 38.87 toks/s]
2025-01-06 18:00:11,876 - star_logger_test - ERROR - Processed prompts:   1%|          | 6/500 [00:06<04:46,  1.73it/s, est. speed input: 133.16 toks/s, output: 79.53 toks/s]
2025-01-06 18:00:12,017 - star_logger_test - ERROR - Processed prompts:   1%|▏         | 7/500 [00:07<04:29,  1.83it/s, est. speed input: 145.68 toks/s, output: 88.89 toks/s]
2025-01-06 18:00:12,350 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 8/500 [00:07<03:37,  2.26it/s, est. speed input: 163.43 toks/s, output: 101.48 toks/s]
2025-01-06 18:00:12,722 - star_logger_test - ERROR - Processed prompts:   2%|▏         | 12/500 [00:07<01:52,  4.35it/s, est. speed input: 234.01 toks/s, output: 152.59 toks/s]
2025-01-06 18:00:12,944 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 14/500 [00:07<01:45,  4.62it/s, est. speed input: 260.38 toks/s, output: 173.54 toks/s]
2025-01-06 18:00:13,263 - star_logger_test - ERROR - Processed prompts:   3%|▎         | 16/500 [00:08<01:29,  5.40it/s, est. speed input: 288.66 toks/s, output: 197.41 toks/s]
2025-01-06 18:00:13,531 - star_logger_test - ERROR - Processed prompts:   4%|▎         | 18/500 [00:08<01:25,  5.63it/s, est. speed input: 312.11 toks/s, output: 218.28 toks/s]
2025-01-06 18:00:13,741 - star_logger_test - ERROR - Processed prompts:   4%|▍         | 19/500 [00:08<01:33,  5.17it/s, est. speed input: 319.16 toks/s, output: 226.03 toks/s]
2025-01-06 18:00:14,055 - star_logger_test - ERROR - Processed prompts:   4%|▍         | 21/500 [00:08<01:18,  6.10it/s, est. speed input: 344.09 toks/s, output: 249.45 toks/s]
2025-01-06 18:00:14,188 - star_logger_test - ERROR - Processed prompts:   5%|▍         | 23/500 [00:09<01:17,  6.19it/s, est. speed input: 364.03 toks/s, output: 269.47 toks/s]
2025-01-06 18:00:14,382 - star_logger_test - ERROR - Processed prompts:   5%|▍         | 24/500 [00:09<01:14,  6.40it/s, est. speed input: 374.17 toks/s, output: 280.20 toks/s]
2025-01-06 18:00:14,652 - star_logger_test - ERROR - Processed prompts:   5%|▌         | 26/500 [00:09<01:04,  7.37it/s, est. speed input: 397.65 toks/s, output: 303.29 toks/s]
2025-01-06 18:00:14,798 - star_logger_test - ERROR - Processed prompts:   6%|▌         | 28/500 [00:09<01:03,  7.39it/s, est. speed input: 415.64 toks/s, output: 323.77 toks/s]
2025-01-06 18:00:14,993 - star_logger_test - ERROR - Processed prompts:   6%|▌         | 30/500 [00:09<00:54,  8.67it/s, est. speed input: 438.66 toks/s, output: 348.04 toks/s]
2025-01-06 18:00:15,128 - star_logger_test - ERROR - Processed prompts:   6%|▌         | 31/500 [00:10<01:01,  7.68it/s, est. speed input: 444.51 toks/s, output: 355.93 toks/s]
2025-01-06 18:00:15,277 - star_logger_test - ERROR - Processed prompts:   7%|▋         | 33/500 [00:10<00:50,  9.24it/s, est. speed input: 467.55 toks/s, output: 380.22 toks/s]
2025-01-06 18:00:15,792 - star_logger_test - ERROR - Processed prompts:   7%|▋         | 36/500 [00:10<00:38, 12.01it/s, est. speed input: 502.13 toks/s, output: 418.25 toks/s]
2025-01-06 18:00:15,999 - star_logger_test - ERROR - Processed prompts:   8%|▊         | 38/500 [00:10<01:01,  7.48it/s, est. speed input: 504.74 toks/s, output: 427.26 toks/s]
2025-01-06 18:00:16,213 - star_logger_test - ERROR - Processed prompts:   8%|▊         | 40/500 [00:11<00:57,  8.01it/s, est. speed input: 522.51 toks/s, output: 448.53 toks/s]
2025-01-06 18:00:16,419 - star_logger_test - ERROR - Processed prompts:   8%|▊         | 42/500 [00:11<00:54,  8.36it/s, est. speed input: 538.33 toks/s, output: 469.08 toks/s]
2025-01-06 18:00:16,689 - star_logger_test - ERROR - Processed prompts:   9%|▉         | 45/500 [00:11<00:45, 10.01it/s, est. speed input: 565.96 toks/s, output: 503.99 toks/s]
2025-01-06 18:00:16,882 - star_logger_test - ERROR - Processed prompts:   9%|▉         | 47/500 [00:11<00:49,  9.15it/s, est. speed input: 577.98 toks/s, output: 521.63 toks/s]
2025-01-06 18:00:17,032 - star_logger_test - ERROR - Processed prompts:  10%|▉         | 49/500 [00:12<00:47,  9.45it/s, est. speed input: 592.35 toks/s, output: 542.47 toks/s]
2025-01-06 18:00:17,295 - star_logger_test - ERROR - Processed prompts:  10%|█         | 51/500 [00:12<00:43, 10.31it/s, est. speed input: 608.38 toks/s, output: 564.93 toks/s]
2025-01-06 18:00:17,568 - star_logger_test - ERROR - Processed prompts:  11%|█         | 53/500 [00:12<00:47,  9.35it/s, est. speed input: 618.88 toks/s, output: 581.89 toks/s]
2025-01-06 18:00:17,716 - star_logger_test - ERROR - Processed prompts:  11%|█▏        | 57/500 [00:12<00:39, 11.17it/s, est. speed input: 652.40 toks/s, output: 627.03 toks/s]
2025-01-06 18:00:17,851 - star_logger_test - ERROR - Processed prompts:  12%|█▏        | 59/500 [00:12<00:37, 11.67it/s, est. speed input: 667.21 toks/s, output: 648.96 toks/s]
2025-01-06 18:00:18,009 - star_logger_test - ERROR - Processed prompts:  12%|█▏        | 61/500 [00:13<00:35, 12.34it/s, est. speed input: 682.93 toks/s, output: 671.25 toks/s]
2025-01-06 18:00:18,230 - star_logger_test - ERROR - Processed prompts:  13%|█▎        | 63/500 [00:13<00:35, 12.43it/s, est. speed input: 696.99 toks/s, output: 692.28 toks/s]
2025-01-06 18:00:18,443 - star_logger_test - ERROR - Processed prompts:  14%|█▍        | 69/500 [00:13<00:24, 17.51it/s, est. speed input: 751.30 toks/s, output: 767.42 toks/s]
2025-01-06 18:00:18,597 - star_logger_test - ERROR - Processed prompts:  14%|█▍        | 72/500 [00:13<00:26, 16.43it/s, est. speed input: 771.85 toks/s, output: 798.81 toks/s]
2025-01-06 18:00:18,819 - star_logger_test - ERROR - Processed prompts:  15%|█▌        | 77/500 [00:13<00:20, 20.41it/s, est. speed input: 815.63 toks/s, output: 862.12 toks/s]
2025-01-06 18:00:18,974 - star_logger_test - ERROR - Processed prompts:  16%|█▌        | 80/500 [00:13<00:23, 18.07it/s, est. speed input: 833.78 toks/s, output: 891.76 toks/s]
2025-01-06 18:00:19,246 - star_logger_test - ERROR - Processed prompts:  17%|█▋        | 85/500 [00:14<00:19, 21.67it/s, est. speed input: 875.78 toks/s, output: 954.21 toks/s]
2025-01-06 18:00:19,392 - star_logger_test - ERROR - Processed prompts:  18%|█▊        | 88/500 [00:14<00:23, 17.55it/s, est. speed input: 889.81 toks/s, output: 970.02 toks/s]
2025-01-06 18:00:19,542 - star_logger_test - ERROR - Processed prompts:  18%|█▊        | 90/500 [00:14<00:24, 16.66it/s, est. speed input: 901.07 toks/s, output: 989.19 toks/s]
2025-01-06 18:00:19,704 - star_logger_test - ERROR - Processed prompts:  19%|█▊        | 93/500 [00:14<00:23, 17.50it/s, est. speed input: 922.19 toks/s, output: 1022.40 toks/s]
2025-01-06 18:00:19,856 - star_logger_test - ERROR - Processed prompts:  19%|█▉        | 97/500 [00:14<00:20, 19.52it/s, est. speed input: 951.78 toks/s, output: 1068.86 toks/s]
2025-01-06 18:00:19,989 - star_logger_test - ERROR - Processed prompts:  20%|██        | 101/500 [00:15<00:18, 21.37it/s, est. speed input: 980.22 toks/s, output: 1107.03 toks/s]
2025-01-06 18:00:20,140 - star_logger_test - ERROR - Processed prompts:  21%|██        | 104/500 [00:15<00:18, 21.65it/s, est. speed input: 1000.55 toks/s, output: 1140.49 toks/s]
2025-01-06 18:00:20,479 - star_logger_test - ERROR - Processed prompts:  21%|██▏       | 107/500 [00:15<00:18, 21.16it/s, est. speed input: 1018.68 toks/s, output: 1172.47 toks/s]
2025-01-06 18:00:20,869 - star_logger_test - ERROR - Processed prompts:  22%|██▏       | 110/500 [00:15<00:25, 15.19it/s, est. speed input: 1024.37 toks/s, output: 1190.04 toks/s]
2025-01-06 18:00:21,019 - star_logger_test - ERROR - Processed prompts:  22%|██▏       | 112/500 [00:16<00:36, 10.74it/s, est. speed input: 1017.62 toks/s, output: 1189.93 toks/s]
2025-01-06 18:00:21,239 - star_logger_test - ERROR - Processed prompts:  23%|██▎       | 115/500 [00:16<00:30, 12.55it/s, est. speed input: 1035.73 toks/s, output: 1222.07 toks/s]
2025-01-06 18:00:21,515 - star_logger_test - ERROR - Processed prompts:  24%|██▎       | 118/500 [00:16<00:29, 12.87it/s, est. speed input: 1048.43 toks/s, output: 1248.73 toks/s]
2025-01-06 18:00:21,665 - star_logger_test - ERROR - Processed prompts:  24%|██▍       | 122/500 [00:16<00:28, 13.43it/s, est. speed input: 1066.97 toks/s, output: 1285.36 toks/s]
2025-01-06 18:00:21,934 - star_logger_test - ERROR - Processed prompts:  25%|██▍       | 124/500 [00:16<00:28, 13.40it/s, est. speed input: 1074.48 toks/s, output: 1302.68 toks/s]
2025-01-06 18:00:22,082 - star_logger_test - ERROR - Processed prompts:  25%|██▌       | 126/500 [00:17<00:33, 11.31it/s, est. speed input: 1074.40 toks/s, output: 1310.88 toks/s]
2025-01-06 18:00:22,293 - star_logger_test - ERROR - Processed prompts:  26%|██▌       | 128/500 [00:17<00:31, 11.80it/s, est. speed input: 1082.27 toks/s, output: 1328.50 toks/s]
2025-01-06 18:00:22,507 - star_logger_test - ERROR - Processed prompts:  26%|██▌       | 131/500 [00:17<00:29, 12.54it/s, est. speed input: 1093.99 toks/s, output: 1355.51 toks/s]
2025-01-06 18:00:24,084 - star_logger_test - ERROR - Processed prompts:  27%|██▋       | 134/500 [00:17<00:28, 12.98it/s, est. speed input: 1105.93 toks/s, output: 1382.10 toks/s]
2025-01-06 18:00:24,444 - star_logger_test - ERROR - Processed prompts:  52%|█████▏    | 259/500 [00:19<00:03, 63.58it/s, est. speed input: 1973.45 toks/s, output: 2924.12 toks/s]
2025-01-06 18:00:25,673 - star_logger_test - ERROR - Processed prompts:  53%|█████▎    | 263/500 [00:19<00:04, 53.14it/s, est. speed input: 1967.36 toks/s, output: 2897.80 toks/s]
2025-01-06 18:00:26,126 - star_logger_test - ERROR - Processed prompts:  53%|█████▎    | 266/500 [00:20<00:08, 28.14it/s, est. speed input: 1872.32 toks/s, output: 2743.55 toks/s]
2025-01-06 18:00:26,245 - star_logger_test - ERROR - Processed prompts:  54%|█████▎    | 268/500 [00:21<00:09, 23.25it/s, est. speed input: 1846.36 toks/s, output: 2704.08 toks/s]
2025-01-06 18:00:26,360 - star_logger_test - ERROR - Processed prompts:  54%|█████▍    | 270/500 [00:21<00:10, 22.79it/s, est. speed input: 1849.69 toks/s, output: 2707.94 toks/s]
2025-01-06 18:00:26,524 - star_logger_test - ERROR - Processed prompts:  54%|█████▍    | 272/500 [00:21<00:10, 22.31it/s, est. speed input: 1853.43 toks/s, output: 2712.90 toks/s]
2025-01-06 18:00:26,683 - star_logger_test - ERROR - Processed prompts:  55%|█████▍    | 274/500 [00:21<00:10, 20.73it/s, est. speed input: 1853.02 toks/s, output: 2709.34 toks/s]
2025-01-06 18:00:27,104 - star_logger_test - ERROR - Processed prompts:  55%|█████▌    | 276/500 [00:21<00:11, 19.28it/s, est. speed input: 1853.08 toks/s, output: 2706.46 toks/s]
2025-01-06 18:00:27,941 - star_logger_test - ERROR - Processed prompts:  56%|█████▌    | 278/500 [00:22<00:16, 13.46it/s, est. speed input: 1831.18 toks/s, output: 2671.79 toks/s]
2025-01-06 18:00:28,110 - star_logger_test - ERROR - Processed prompts:  56%|█████▌    | 280/500 [00:23<00:29,  7.57it/s, est. speed input: 1777.81 toks/s, output: 2589.83 toks/s]
2025-01-06 18:00:28,332 - star_logger_test - ERROR - Processed prompts:  56%|█████▌    | 281/500 [00:23<00:29,  7.35it/s, est. speed input: 1771.33 toks/s, output: 2577.17 toks/s]
2025-01-06 18:00:28,590 - star_logger_test - ERROR - Processed prompts:  57%|█████▋    | 285/500 [00:23<00:22,  9.48it/s, est. speed input: 1779.50 toks/s, output: 2591.78 toks/s]
2025-01-06 18:00:28,760 - star_logger_test - ERROR - Processed prompts:  58%|█████▊    | 288/500 [00:23<00:21, 10.01it/s, est. speed input: 1778.57 toks/s, output: 2586.08 toks/s]
2025-01-06 18:00:28,874 - star_logger_test - ERROR - Processed prompts:  58%|█████▊    | 291/500 [00:23<00:18, 11.47it/s, est. speed input: 1784.64 toks/s, output: 2587.64 toks/s]
2025-01-06 18:00:28,975 - star_logger_test - ERROR - Processed prompts:  59%|█████▉    | 294/500 [00:24<00:14, 13.75it/s, est. speed input: 1794.58 toks/s, output: 2596.10 toks/s]
2025-01-06 18:00:29,079 - star_logger_test - ERROR - Processed prompts:  59%|█████▉    | 296/500 [00:24<00:13, 14.74it/s, est. speed input: 1799.39 toks/s, output: 2600.95 toks/s]
2025-01-06 18:00:29,363 - star_logger_test - ERROR - Processed prompts:  60%|█████▉    | 298/500 [00:24<00:12, 15.61it/s, est. speed input: 1803.84 toks/s, output: 2607.37 toks/s]
2025-01-06 18:00:29,467 - star_logger_test - ERROR - Processed prompts:  60%|██████    | 300/500 [00:24<00:16, 11.93it/s, est. speed input: 1794.94 toks/s, output: 2589.26 toks/s]
2025-01-06 18:00:29,713 - star_logger_test - ERROR - Processed prompts:  60%|██████    | 302/500 [00:24<00:14, 13.25it/s, est. speed input: 1799.15 toks/s, output: 2595.45 toks/s]
2025-01-06 18:00:30,001 - star_logger_test - ERROR - Processed prompts:  61%|██████    | 306/500 [00:24<00:13, 14.43it/s, est. speed input: 1805.15 toks/s, output: 2605.86 toks/s]
2025-01-06 18:00:30,154 - star_logger_test - ERROR - Processed prompts:  62%|██████▏   | 310/500 [00:25<00:13, 14.22it/s, est. speed input: 1808.13 toks/s, output: 2603.30 toks/s]
2025-01-06 18:00:30,354 - star_logger_test - ERROR - Processed prompts:  62%|██████▏   | 312/500 [00:25<00:13, 13.95it/s, est. speed input: 1809.13 toks/s, output: 2598.34 toks/s]
2025-01-06 18:00:30,557 - star_logger_test - ERROR - Processed prompts:  63%|██████▎   | 314/500 [00:25<00:14, 12.77it/s, est. speed input: 1806.43 toks/s, output: 2593.45 toks/s]
2025-01-06 18:00:30,713 - star_logger_test - ERROR - Processed prompts:  64%|██████▎   | 318/500 [00:25<00:12, 14.85it/s, est. speed input: 1815.10 toks/s, output: 2599.67 toks/s]
2025-01-06 18:00:30,867 - star_logger_test - ERROR - Processed prompts:  64%|██████▍   | 320/500 [00:25<00:12, 14.35it/s, est. speed input: 1815.67 toks/s, output: 2599.29 toks/s]
2025-01-06 18:00:31,058 - star_logger_test - ERROR - Processed prompts:  64%|██████▍   | 322/500 [00:26<00:12, 13.99it/s, est. speed input: 1816.15 toks/s, output: 2602.24 toks/s]
2025-01-06 18:00:31,201 - star_logger_test - ERROR - Processed prompts:  65%|██████▌   | 326/500 [00:26<00:10, 16.18it/s, est. speed input: 1825.22 toks/s, output: 2609.63 toks/s]
2025-01-06 18:00:31,306 - star_logger_test - ERROR - Processed prompts:  66%|██████▌   | 329/500 [00:26<00:09, 17.42it/s, est. speed input: 1832.15 toks/s, output: 2620.90 toks/s]
2025-01-06 18:00:31,444 - star_logger_test - ERROR - Processed prompts:  67%|██████▋   | 333/500 [00:26<00:07, 21.73it/s, est. speed input: 1847.24 toks/s, output: 2645.43 toks/s]
2025-01-06 18:00:31,678 - star_logger_test - ERROR - Processed prompts:  67%|██████▋   | 336/500 [00:26<00:07, 21.71it/s, est. speed input: 1854.09 toks/s, output: 2651.32 toks/s]
2025-01-06 18:00:31,896 - star_logger_test - ERROR - Processed prompts:  68%|██████▊   | 339/500 [00:26<00:08, 18.11it/s, est. speed input: 1854.00 toks/s, output: 2650.39 toks/s]
2025-01-06 18:00:32,017 - star_logger_test - ERROR - Processed prompts:  68%|██████▊   | 342/500 [00:27<00:09, 16.59it/s, est. speed input: 1855.82 toks/s, output: 2655.96 toks/s]
2025-01-06 18:00:32,175 - star_logger_test - ERROR - Processed prompts:  69%|██████▉   | 347/500 [00:27<00:06, 21.97it/s, est. speed input: 1874.48 toks/s, output: 2683.53 toks/s]
2025-01-06 18:00:32,334 - star_logger_test - ERROR - Processed prompts:  70%|███████   | 350/500 [00:27<00:07, 21.10it/s, est. speed input: 1879.54 toks/s, output: 2686.83 toks/s]
2025-01-06 18:00:32,452 - star_logger_test - ERROR - Processed prompts:  71%|███████   | 353/500 [00:27<00:07, 20.46it/s, est. speed input: 1884.49 toks/s, output: 2696.44 toks/s]
2025-01-06 18:00:32,604 - star_logger_test - ERROR - Processed prompts:  72%|███████▏  | 359/500 [00:27<00:05, 27.69it/s, est. speed input: 1908.35 toks/s, output: 2730.86 toks/s]
2025-01-06 18:00:32,715 - star_logger_test - ERROR - Processed prompts:  73%|███████▎  | 363/500 [00:27<00:05, 27.26it/s, est. speed input: 1919.25 toks/s, output: 2749.89 toks/s]
2025-01-06 18:00:33,288 - star_logger_test - ERROR - Processed prompts:  73%|███████▎  | 366/500 [00:27<00:04, 27.19it/s, est. speed input: 1927.26 toks/s, output: 2761.22 toks/s]
2025-01-06 18:00:33,396 - star_logger_test - ERROR - Processed prompts:  74%|███████▍  | 369/500 [00:28<00:09, 13.15it/s, est. speed input: 1903.78 toks/s, output: 2730.22 toks/s]
2025-01-06 18:00:33,498 - star_logger_test - ERROR - Processed prompts:  75%|███████▍  | 373/500 [00:28<00:07, 16.67it/s, est. speed input: 1917.01 toks/s, output: 2753.43 toks/s]
2025-01-06 18:00:33,607 - star_logger_test - ERROR - Processed prompts:  75%|███████▌  | 377/500 [00:28<00:06, 20.39it/s, est. speed input: 1930.69 toks/s, output: 2775.01 toks/s]
2025-01-06 18:00:33,767 - star_logger_test - ERROR - Processed prompts:  77%|███████▋  | 385/500 [00:28<00:03, 31.11it/s, est. speed input: 1964.42 toks/s, output: 2825.51 toks/s]
2025-01-06 18:00:33,874 - star_logger_test - ERROR - Processed prompts:  78%|███████▊  | 391/500 [00:28<00:03, 32.96it/s, est. speed input: 1984.41 toks/s, output: 2859.06 toks/s]
2025-01-06 18:00:33,991 - star_logger_test - ERROR - Processed prompts:  79%|███████▉  | 397/500 [00:29<00:02, 38.11it/s, est. speed input: 2008.12 toks/s, output: 2893.45 toks/s]
2025-01-06 18:00:34,106 - star_logger_test - ERROR - Processed prompts:  81%|████████  | 403/500 [00:29<00:02, 41.45it/s, est. speed input: 2030.25 toks/s, output: 2927.99 toks/s]
2025-01-06 18:00:34,240 - star_logger_test - ERROR - Processed prompts:  82%|████████▏ | 411/500 [00:29<00:01, 48.88it/s, est. speed input: 2062.33 toks/s, output: 2980.53 toks/s]
2025-01-06 18:00:34,341 - star_logger_test - ERROR - Processed prompts:  83%|████████▎ | 417/500 [00:29<00:01, 47.69it/s, est. speed input: 2082.97 toks/s, output: 3017.95 toks/s]
2025-01-06 18:00:34,458 - star_logger_test - ERROR - Processed prompts:  85%|████████▌ | 425/500 [00:29<00:01, 55.53it/s, est. speed input: 2115.10 toks/s, output: 3072.33 toks/s]
2025-01-06 18:00:34,583 - star_logger_test - ERROR - Processed prompts:  86%|████████▌ | 431/500 [00:29<00:01, 54.27it/s, est. speed input: 2136.54 toks/s, output: 3106.93 toks/s]
2025-01-06 18:00:34,699 - star_logger_test - ERROR - Processed prompts:  87%|████████▋ | 437/500 [00:29<00:01, 52.27it/s, est. speed input: 2156.90 toks/s, output: 3143.03 toks/s]
2025-01-06 18:00:34,901 - star_logger_test - ERROR - Processed prompts:  89%|████████▊ | 443/500 [00:29<00:01, 52.09it/s, est. speed input: 2177.94 toks/s, output: 3180.19 toks/s]
2025-01-06 18:00:35,004 - star_logger_test - ERROR - Processed prompts:  90%|████████▉ | 449/500 [00:30<00:01, 42.74it/s, est. speed input: 2193.12 toks/s, output: 3209.10 toks/s]
2025-01-06 18:00:35,067 - star_logger_test - ERROR - Processed prompts:  91%|█████████ | 455/500 [00:30<00:00, 46.40it/s, est. speed input: 2214.59 toks/s, output: 3248.46 toks/s]
2025-01-06 18:00:35,067 - star_logger_test - ERROR - Processed prompts: 100%|██████████| 500/500 [00:30<00:00, 16.54it/s, est. speed input: 2428.96 toks/s, output: 3622.56 toks/s]
2025-01-06 18:00:35,447 - star_logger_test - INFO - DatasetDict({
2025-01-06 18:00:35,447 - star_logger_test - ERROR - 
2025-01-06 18:00:35,447 - star_logger_test - INFO -     train: Dataset({
2025-01-06 18:00:35,447 - star_logger_test - INFO -         features: ['question_id', 'question_text', 'reference', 'rationale', 'messages'],
2025-01-06 18:00:35,447 - star_logger_test - INFO -         num_rows: 15
2025-01-06 18:00:35,447 - star_logger_test - INFO -     })
2025-01-06 18:00:35,447 - star_logger_test - INFO - })
2025-01-06 18:00:35,451 - star_logger_test - ERROR - Saving the dataset (0/1 shards):   0%|          | 0/15 [00:00<?, ? examples/s]
2025-01-06 18:00:35,451 - star_logger_test - ERROR - Saving the dataset (1/1 shards): 100%|██████████| 15/15 [00:00<00:00, 4045.95 examples/s]
2025-01-06 18:00:35,451 - star_logger_test - ERROR - Saving the dataset (1/1 shards): 100%|██████████| 15/15 [00:00<00:00, 3867.38 examples/s]
2025-01-06 18:00:35,488 - star_logger_test - INFO - INFO 01-06 18:00:35 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
2025-01-06 18:00:35,490 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=219627)[0;0m INFO 01-06 18:00:35 multiproc_worker_utils.py:247] Worker exiting
2025-01-06 18:00:37,444 - star_logger_test - ERROR - [rank0]:[W106 18:00:37.432910066 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
2025-01-06 18:00:38,354 - star_logger_test - ERROR - /usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
2025-01-06 18:00:38,354 - star_logger_test - ERROR -   warnings.warn('resource_tracker: There appear to be %d '
2025-01-06 18:00:39,258 - star_logger_test - INFO - Running command: accelerate launch --config_file configs/accelerate_config.yaml fine_tune.py --config_path configs/temp_STaR_ft_config.yaml
2025-01-06 18:00:48,922 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
2025-01-06 18:00:48,922 - star_logger_test - ERROR -   warnings.warn(
2025-01-06 18:00:48,966 - star_logger_test - INFO - [INFO] Loading Model at luezzka/Llama-3.2-1B-Instruct
2025-01-06 18:00:49,195 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
2025-01-06 18:00:49,195 - star_logger_test - ERROR -   warnings.warn(
2025-01-06 18:00:50,891 - star_logger_test - INFO - [INFO] Loading Model at luezzka/Llama-3.2-1B-Instruct
2025-01-06 18:01:00,359 - star_logger_test - ERROR - The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
2025-01-06 18:01:00,739 - star_logger_test - ERROR - The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
2025-01-06 18:01:07,756 - star_logger_test - INFO - [INFO] Loading Dataset from at /home/data/v.moskvoretskii/cache/STaR/test/data/data_0
2025-01-06 18:01:07,993 - star_logger_test - ERROR - /home/data/v.moskvoretskii/QAC/fine_tune.py:251: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-01-06 18:01:07,994 - star_logger_test - ERROR -   trainer = Trainer(
2025-01-06 18:01:11,491 - star_logger_test - INFO - [INFO] Loading Dataset from at /home/data/v.moskvoretskii/cache/STaR/test/data/data_0
2025-01-06 18:01:11,675 - star_logger_test - ERROR - /home/data/v.moskvoretskii/QAC/fine_tune.py:251: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-01-06 18:01:11,676 - star_logger_test - ERROR -   trainer = Trainer(
2025-01-06 18:01:15,845 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:1585: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight.
2025-01-06 18:01:15,845 - star_logger_test - ERROR -   warnings.warn(
2025-01-06 18:01:15,845 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:1585: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
2025-01-06 18:01:15,846 - star_logger_test - ERROR -   warnings.warn(
2025-01-06 18:01:15,846 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:1591: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
2025-01-06 18:01:15,846 - star_logger_test - ERROR -   warnings.warn(
2025-01-06 18:01:15,872 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py:657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)
2025-01-06 18:01:15,872 - star_logger_test - ERROR -   batch["labels"] = torch.tensor(batch["labels"], dtype=torch.int64)
2025-01-06 18:01:17,287 - star_logger_test - ERROR - wandb: Currently logged in as: vityavitalich. Use `wandb login --relogin` to force relogin
2025-01-06 18:01:18,440 - star_logger_test - ERROR - wandb: wandb version 0.19.1 is available!  To upgrade, please run:
2025-01-06 18:01:18,440 - star_logger_test - ERROR - wandb:  $ pip install wandb --upgrade
2025-01-06 18:01:18,441 - star_logger_test - ERROR - wandb: Tracking run with wandb version 0.16.2
2025-01-06 18:01:18,441 - star_logger_test - ERROR - wandb: Run data is saved locally in /home/data/v.moskvoretskii/QAC/wandb/run-20250106_180117-2ah9ejhp
2025-01-06 18:01:18,441 - star_logger_test - ERROR - wandb: Run `wandb offline` to turn off syncing.
2025-01-06 18:01:18,447 - star_logger_test - ERROR - wandb: Syncing run test_0
2025-01-06 18:01:18,448 - star_logger_test - ERROR - wandb: ⭐️ View project at https://wandb.ai/vityavitalich/STaR
2025-01-06 18:01:18,448 - star_logger_test - ERROR - wandb: 🚀 View run at https://wandb.ai/vityavitalich/STaR/runs/2ah9ejhp
2025-01-06 18:01:18,477 - star_logger_test - ERROR - 
2025-01-06 18:01:18,484 - star_logger_test - ERROR -   0%|          | 0/4 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py:657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)
2025-01-06 18:01:18,484 - star_logger_test - ERROR -   batch["labels"] = torch.tensor(batch["labels"], dtype=torch.int64)
2025-01-06 18:01:19,881 - star_logger_test - ERROR - 
2025-01-06 18:01:20,225 - star_logger_test - ERROR -  25%|██▌       | 1/4 [00:01<00:04,  1.40s/it]
2025-01-06 18:01:20,585 - star_logger_test - ERROR -  50%|█████     | 2/4 [00:01<00:01,  1.28it/s]
2025-01-06 18:01:20,950 - star_logger_test - ERROR -  75%|███████▌  | 3/4 [00:02<00:00,  1.70it/s]
2025-01-06 18:01:21,044 - star_logger_test - ERROR - 100%|██████████| 4/4 [00:02<00:00,  2.00it/s]
2025-01-06 18:01:21,045 - star_logger_test - INFO - {'train_runtime': 5.1889, 'train_samples_per_second': 2.891, 'train_steps_per_second': 0.771, 'train_loss': 3.430392265319824, 'epoch': 1.0}
2025-01-06 18:01:21,045 - star_logger_test - ERROR -                                              
2025-01-06 18:01:21,045 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
2025-01-06 18:01:21,045 - star_logger_test - ERROR -   warnings.warn(
2025-01-06 18:01:21,045 - star_logger_test - ERROR - 
2025-01-06 18:01:21,046 - star_logger_test - ERROR - 100%|██████████| 4/4 [00:02<00:00,  2.00it/s]
2025-01-06 18:01:21,046 - star_logger_test - ERROR - 100%|██████████| 4/4 [00:02<00:00,  1.56it/s]
2025-01-06 18:01:21,046 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
2025-01-06 18:01:21,046 - star_logger_test - ERROR -   warnings.warn(
2025-01-06 18:03:04,529 - star_logger_test - ERROR - wandb: - 0.042 MB of 0.058 MB uploaded
2025-01-06 18:03:04,620 - star_logger_test - ERROR - wandb: \ 0.060 MB of 0.060 MB uploaded
2025-01-06 18:03:04,789 - star_logger_test - ERROR - wandb: | 0.060 MB of 0.060 MB uploaded
2025-01-06 18:03:04,790 - star_logger_test - ERROR - wandb: 
2025-01-06 18:03:04,790 - star_logger_test - ERROR - wandb: Run history:
2025-01-06 18:03:04,790 - star_logger_test - ERROR - wandb:       train/epoch ▁
2025-01-06 18:03:04,790 - star_logger_test - ERROR - wandb: train/global_step ▁
2025-01-06 18:03:04,790 - star_logger_test - ERROR - wandb: 
2025-01-06 18:03:04,790 - star_logger_test - ERROR - wandb: Run summary:
2025-01-06 18:03:04,790 - star_logger_test - ERROR - wandb:               total_flos 4589357105152.0
2025-01-06 18:03:04,790 - star_logger_test - ERROR - wandb:              train/epoch 1.0
2025-01-06 18:03:04,791 - star_logger_test - ERROR - wandb:        train/global_step 4
2025-01-06 18:03:04,791 - star_logger_test - ERROR - wandb:               train_loss 3.43039
2025-01-06 18:03:04,791 - star_logger_test - ERROR - wandb:            train_runtime 5.1889
2025-01-06 18:03:04,791 - star_logger_test - ERROR - wandb: train_samples_per_second 2.891
2025-01-06 18:03:04,791 - star_logger_test - ERROR - wandb:   train_steps_per_second 0.771
2025-01-06 18:03:04,791 - star_logger_test - ERROR - wandb: 
2025-01-06 18:03:04,791 - star_logger_test - ERROR - wandb: 🚀 View run test_0 at: https://wandb.ai/vityavitalich/STaR/runs/2ah9ejhp
2025-01-06 18:03:04,792 - star_logger_test - ERROR - wandb: ️⚡ View job at https://wandb.ai/vityavitalich/STaR/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjUzMDIxNTAzOQ==/version_details/v3
2025-01-06 18:03:04,792 - star_logger_test - ERROR - wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
2025-01-06 18:03:04,792 - star_logger_test - ERROR - wandb: Find logs at: ./wandb/run-20250106_180117-2ah9ejhp/logs
2025-01-06 18:03:09,059 - star_logger_test - INFO - [INFO] Starting iteration 2/2
2025-01-06 18:03:09,059 - star_logger_test - INFO - Running command: python star_vllm_generation.py --config_path configs/star_config.yaml --generation_model_path /home/data/v.moskvoretskii/cache/STaR/test_0 --ft_dataset_path /home/data/v.moskvoretskii/cache/STaR/test/data/data_1 --iteration 1
2025-01-06 18:03:15,586 - star_logger_test - INFO - [INFO] No few-shot file found for prompt_type='star_generation' at 'few_shots/star_generation.json'. Using none.
2025-01-06 18:03:15,586 - star_logger_test - INFO - [INFO] No few-shot file found for prompt_type='star_rationalization' at 'few_shots/star_rationalization.json'. Using none.
2025-01-06 18:03:15,586 - star_logger_test - INFO - INFO 01-06 18:03:15 config.py:2272] Downcasting torch.float32 to torch.bfloat16.
2025-01-06 18:03:23,082 - star_logger_test - INFO - INFO 01-06 18:03:23 config.py:510] This model supports multiple tasks: {'score', 'reward', 'embed', 'generate', 'classify'}. Defaulting to 'generate'.
2025-01-06 18:03:23,083 - star_logger_test - INFO - INFO 01-06 18:03:23 config.py:1310] Defaulting to use mp for distributed inference
2025-01-06 18:03:23,083 - star_logger_test - INFO - WARNING 01-06 18:03:23 cuda.py:98] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
2025-01-06 18:03:23,083 - star_logger_test - INFO - WARNING 01-06 18:03:23 config.py:642] Async output processing is not supported on the current platform type cuda.
2025-01-06 18:03:23,087 - star_logger_test - INFO - INFO 01-06 18:03:23 llm_engine.py:234] Initializing an LLM engine (v0.6.6.post1) with config: model='/home/data/v.moskvoretskii/cache/STaR/test_0', speculative_config=None, tokenizer='/home/data/v.moskvoretskii/cache/STaR/test_0', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1024, download_dir='/home/data/v.moskvoretskii/cache/', load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/data/v.moskvoretskii/cache/STaR/test_0, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=False, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"candidate_compile_sizes":[],"compile_sizes":[],"capture_sizes":[],"max_capture_size":0}, use_cached_outputs=False, 
2025-01-06 18:03:23,851 - star_logger_test - INFO - WARNING 01-06 18:03:23 multiproc_worker_utils.py:312] Reducing Torch parallelism from 48 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
2025-01-06 18:03:23,916 - star_logger_test - INFO - INFO 01-06 18:03:23 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager
2025-01-06 18:03:25,249 - star_logger_test - INFO - INFO 01-06 18:03:25 selector.py:120] Using Flash Attention backend.
2025-01-06 18:03:25,260 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=222436)[0;0m INFO 01-06 18:03:25 selector.py:120] Using Flash Attention backend.
2025-01-06 18:03:25,260 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=222436)[0;0m INFO 01-06 18:03:25 multiproc_worker_utils.py:222] Worker ready; awaiting tasks
2025-01-06 18:03:25,995 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=222436)[0;0m INFO 01-06 18:03:25 utils.py:918] Found nccl from library libnccl.so.2
2025-01-06 18:03:25,995 - star_logger_test - INFO - INFO 01-06 18:03:25 utils.py:918] Found nccl from library libnccl.so.2
2025-01-06 18:03:25,995 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=222436)[0;0m INFO 01-06 18:03:25 pynccl.py:69] vLLM is using nccl==2.21.5
2025-01-06 18:03:25,995 - star_logger_test - INFO - INFO 01-06 18:03:25 pynccl.py:69] vLLM is using nccl==2.21.5
2025-01-06 18:03:26,321 - star_logger_test - INFO - INFO 01-06 18:03:26 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
2025-01-06 18:03:26,321 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=222436)[0;0m INFO 01-06 18:03:26 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
2025-01-06 18:03:26,335 - star_logger_test - INFO - INFO 01-06 18:03:26 shm_broadcast.py:255] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_aba75a04'), local_subscribe_port=35257, remote_subscribe_port=None)
2025-01-06 18:03:26,341 - star_logger_test - INFO - INFO 01-06 18:03:26 model_runner.py:1094] Starting to load model /home/data/v.moskvoretskii/cache/STaR/test_0...
2025-01-06 18:03:26,343 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=222436)[0;0m INFO 01-06 18:03:26 model_runner.py:1094] Starting to load model /home/data/v.moskvoretskii/cache/STaR/test_0...
2025-01-06 18:03:26,552 - star_logger_test - ERROR - 
2025-01-06 18:03:26,552 - star_logger_test - ERROR - Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
2025-01-06 18:04:03,972 - star_logger_test - ERROR - 
2025-01-06 18:04:03,973 - star_logger_test - ERROR - Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:37<00:37, 37.42s/it]
2025-01-06 18:04:04,101 - star_logger_test - ERROR - 
2025-01-06 18:04:04,101 - star_logger_test - ERROR - Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:37<00:00, 15.48s/it]
2025-01-06 18:04:04,101 - star_logger_test - ERROR - 
2025-01-06 18:04:04,101 - star_logger_test - ERROR - Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:37<00:00, 18.77s/it]
2025-01-06 18:04:04,101 - star_logger_test - ERROR - 
2025-01-06 18:04:04,348 - star_logger_test - INFO - INFO 01-06 18:04:04 model_runner.py:1099] Loading model weights took 1.1668 GB
2025-01-06 18:04:04,423 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=222436)[0;0m INFO 01-06 18:04:04 model_runner.py:1099] Loading model weights took 1.1668 GB
2025-01-06 18:04:06,978 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=222436)[0;0m INFO 01-06 18:04:06 worker.py:241] Memory profiling takes 2.55 seconds
2025-01-06 18:04:06,978 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=222436)[0;0m INFO 01-06 18:04:06 worker.py:241] the current vLLM instance can use total_gpu_memory (44.38GiB) x gpu_memory_utilization (0.50) = 22.19GiB
2025-01-06 18:04:06,978 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=222436)[0;0m INFO 01-06 18:04:06 worker.py:241] model weights take 1.17GiB; non_torch_memory takes 0.25GiB; PyTorch activation peak memory takes 0.08GiB; the rest of the memory reserved for KV Cache is 20.69GiB.
2025-01-06 18:04:07,040 - star_logger_test - INFO - INFO 01-06 18:04:07 worker.py:241] Memory profiling takes 2.62 seconds
2025-01-06 18:04:07,041 - star_logger_test - INFO - INFO 01-06 18:04:07 worker.py:241] the current vLLM instance can use total_gpu_memory (44.38GiB) x gpu_memory_utilization (0.50) = 22.19GiB
2025-01-06 18:04:07,041 - star_logger_test - INFO - INFO 01-06 18:04:07 worker.py:241] model weights take 1.17GiB; non_torch_memory takes 0.25GiB; PyTorch activation peak memory takes 1.18GiB; the rest of the memory reserved for KV Cache is 19.59GiB.
2025-01-06 18:04:07,245 - star_logger_test - INFO - INFO 01-06 18:04:07 distributed_gpu_executor.py:57] # GPU blocks: 80251, # CPU blocks: 16384
2025-01-06 18:04:07,246 - star_logger_test - INFO - INFO 01-06 18:04:07 distributed_gpu_executor.py:61] Maximum concurrency for 1024 tokens per request: 1253.92x
2025-01-06 18:04:09,482 - star_logger_test - INFO - INFO 01-06 18:04:09 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 5.06 seconds
2025-01-06 18:04:11,770 - star_logger_test - INFO - [INFO] Starting generation at 2/2
2025-01-06 18:04:11,770 - star_logger_test - ERROR - 
2025-01-06 18:04:12,915 - star_logger_test - ERROR - Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
2025-01-06 18:04:13,065 - star_logger_test - ERROR - Processed prompts:   0%|          | 1/500 [00:01<09:31,  1.14s/it, est. speed input: 94.37 toks/s, output: 4.37 toks/s]
2025-01-06 18:04:13,364 - star_logger_test - ERROR - Processed prompts:   6%|▌         | 30/500 [00:01<00:15, 31.24it/s, est. speed input: 2554.61 toks/s, output: 116.68 toks/s]
2025-01-06 18:04:13,679 - star_logger_test - ERROR - Processed prompts:  22%|██▏       | 109/500 [00:01<00:03, 103.45it/s, est. speed input: 7571.20 toks/s, output: 392.93 toks/s]
2025-01-06 18:04:13,863 - star_logger_test - ERROR - Processed prompts:  39%|███▉      | 196/500 [00:01<00:01, 158.39it/s, est. speed input: 11351.75 toks/s, output: 647.70 toks/s]
2025-01-06 18:04:14,003 - star_logger_test - ERROR - Processed prompts:  48%|████▊     | 238/500 [00:02<00:01, 172.89it/s, est. speed input: 12568.31 toks/s, output: 751.53 toks/s]
2025-01-06 18:04:14,119 - star_logger_test - ERROR - Processed prompts:  53%|█████▎    | 267/500 [00:02<00:01, 179.46it/s, est. speed input: 13222.32 toks/s, output: 790.71 toks/s]
2025-01-06 18:04:14,676 - star_logger_test - ERROR - Processed prompts:  86%|████████▋ | 432/500 [00:02<00:00, 403.24it/s, est. speed input: 20329.75 toks/s, output: 1227.14 toks/s]
2025-01-06 18:04:14,676 - star_logger_test - ERROR - Processed prompts: 100%|██████████| 500/500 [00:02<00:00, 247.82it/s, est. speed input: 19025.72 toks/s, output: 1188.02 toks/s]
2025-01-06 18:04:14,677 - star_logger_test - ERROR - Processed prompts: 100%|██████████| 500/500 [00:02<00:00, 172.07it/s, est. speed input: 19025.72 toks/s, output: 1188.02 toks/s]
2025-01-06 18:04:15,454 - star_logger_test - INFO - [INFO] Starting rationalization at 2/2
2025-01-06 18:04:15,454 - star_logger_test - ERROR - 
2025-01-06 18:04:16,697 - star_logger_test - ERROR - Processed prompts:   0%|          | 0/500 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
2025-01-06 18:04:16,918 - star_logger_test - ERROR - Processed prompts:   0%|          | 1/500 [00:01<10:19,  1.24s/it, est. speed input: 113.49 toks/s, output: 4.02 toks/s]
2025-01-06 18:04:17,253 - star_logger_test - ERROR - Processed prompts:   8%|▊         | 40/500 [00:01<00:12, 36.38it/s, est. speed input: 3999.43 toks/s, output: 137.30 toks/s]
2025-01-06 18:04:17,623 - star_logger_test - ERROR - Processed prompts:  21%|██▏       | 107/500 [00:01<00:04, 86.28it/s, est. speed input: 8731.71 toks/s, output: 335.78 toks/s]
2025-01-06 18:04:17,839 - star_logger_test - ERROR - Processed prompts:  37%|███▋      | 184/500 [00:02<00:02, 125.89it/s, est. speed input: 12450.47 toks/s, output: 527.56 toks/s]
2025-01-06 18:04:17,981 - star_logger_test - ERROR - Processed prompts:  45%|████▍     | 223/500 [00:02<00:02, 137.47it/s, est. speed input: 13712.81 toks/s, output: 610.90 toks/s]
2025-01-06 18:04:18,120 - star_logger_test - ERROR - Processed prompts:  48%|████▊     | 241/500 [00:02<00:01, 135.73it/s, est. speed input: 13993.14 toks/s, output: 633.24 toks/s]
2025-01-06 18:04:18,236 - star_logger_test - ERROR - Processed prompts:  62%|██████▏   | 308/500 [00:02<00:00, 201.17it/s, est. speed input: 16948.59 toks/s, output: 785.10 toks/s]
2025-01-06 18:04:18,283 - star_logger_test - ERROR - Processed prompts:  90%|█████████ | 452/500 [00:02<00:00, 392.64it/s, est. speed input: 23839.29 toks/s, output: 1113.33 toks/s]
2025-01-06 18:04:18,283 - star_logger_test - ERROR - Processed prompts: 100%|██████████| 500/500 [00:02<00:00, 176.76it/s, est. speed input: 25961.36 toks/s, output: 1246.52 toks/s]
2025-01-06 18:04:18,766 - star_logger_test - INFO - DatasetDict({
2025-01-06 18:04:18,766 - star_logger_test - ERROR - 
2025-01-06 18:04:18,766 - star_logger_test - INFO -     train: Dataset({
2025-01-06 18:04:18,766 - star_logger_test - INFO -         features: ['question_id', 'question_text', 'reference', 'rationale', 'messages'],
2025-01-06 18:04:18,767 - star_logger_test - INFO -         num_rows: 140
2025-01-06 18:04:18,767 - star_logger_test - INFO -     })
2025-01-06 18:04:18,767 - star_logger_test - INFO - })
2025-01-06 18:04:18,770 - star_logger_test - ERROR - Saving the dataset (0/1 shards):   0%|          | 0/140 [00:00<?, ? examples/s]
2025-01-06 18:04:18,770 - star_logger_test - ERROR - Saving the dataset (1/1 shards): 100%|██████████| 140/140 [00:00<00:00, 34596.27 examples/s]
2025-01-06 18:04:18,770 - star_logger_test - ERROR - Saving the dataset (1/1 shards): 100%|██████████| 140/140 [00:00<00:00, 33307.01 examples/s]
2025-01-06 18:04:18,815 - star_logger_test - INFO - INFO 01-06 18:04:18 multiproc_worker_utils.py:140] Terminating local vLLM worker processes
2025-01-06 18:04:18,816 - star_logger_test - INFO - [1;36m(VllmWorkerProcess pid=222436)[0;0m INFO 01-06 18:04:18 multiproc_worker_utils.py:247] Worker exiting
2025-01-06 18:04:20,471 - star_logger_test - ERROR - [rank0]:[W106 18:04:20.459817909 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
2025-01-06 18:04:21,481 - star_logger_test - ERROR - /usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
2025-01-06 18:04:21,482 - star_logger_test - ERROR -   warnings.warn('resource_tracker: There appear to be %d '
2025-01-06 18:04:22,305 - star_logger_test - INFO - Running command: accelerate launch --config_file configs/accelerate_config.yaml fine_tune.py --config_path configs/temp_STaR_ft_config.yaml
2025-01-06 18:04:31,578 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
2025-01-06 18:04:31,578 - star_logger_test - ERROR -   warnings.warn(
2025-01-06 18:04:32,239 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
2025-01-06 18:04:32,239 - star_logger_test - ERROR -   warnings.warn(
2025-01-06 18:04:32,281 - star_logger_test - INFO - [INFO] Loading Model at luezzka/Llama-3.2-1B-Instruct
2025-01-06 18:04:32,877 - star_logger_test - INFO - [INFO] Loading Model at luezzka/Llama-3.2-1B-Instruct
2025-01-06 18:04:41,856 - star_logger_test - ERROR - The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
2025-01-06 18:04:49,240 - star_logger_test - INFO - [INFO] Loading Dataset from at /home/data/v.moskvoretskii/cache/STaR/test/data/data_1
2025-01-06 18:04:49,454 - star_logger_test - ERROR - /home/data/v.moskvoretskii/QAC/fine_tune.py:251: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-01-06 18:04:49,454 - star_logger_test - ERROR -   trainer = Trainer(
2025-01-06 18:04:49,847 - star_logger_test - ERROR - The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
2025-01-06 18:04:59,312 - star_logger_test - INFO - [INFO] Loading Dataset from at /home/data/v.moskvoretskii/cache/STaR/test/data/data_1
2025-01-06 18:04:59,502 - star_logger_test - ERROR - /home/data/v.moskvoretskii/QAC/fine_tune.py:251: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
2025-01-06 18:04:59,503 - star_logger_test - ERROR -   trainer = Trainer(
2025-01-06 18:05:02,423 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:1585: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight.
2025-01-06 18:05:02,423 - star_logger_test - ERROR -   warnings.warn(
2025-01-06 18:05:02,424 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:1585: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
2025-01-06 18:05:02,424 - star_logger_test - ERROR -   warnings.warn(
2025-01-06 18:05:02,424 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:1591: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
2025-01-06 18:05:02,424 - star_logger_test - ERROR -   warnings.warn(
2025-01-06 18:05:02,572 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py:657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)
2025-01-06 18:05:02,572 - star_logger_test - ERROR -   batch["labels"] = torch.tensor(batch["labels"], dtype=torch.int64)
2025-01-06 18:05:03,866 - star_logger_test - ERROR - wandb: Currently logged in as: vityavitalich. Use `wandb login --relogin` to force relogin
2025-01-06 18:05:05,661 - star_logger_test - ERROR - wandb: wandb version 0.19.1 is available!  To upgrade, please run:
2025-01-06 18:05:05,661 - star_logger_test - ERROR - wandb:  $ pip install wandb --upgrade
2025-01-06 18:05:05,661 - star_logger_test - ERROR - wandb: Tracking run with wandb version 0.16.2
2025-01-06 18:05:05,661 - star_logger_test - ERROR - wandb: Run data is saved locally in /home/data/v.moskvoretskii/QAC/wandb/run-20250106_180503-vcr70ro8
2025-01-06 18:05:05,661 - star_logger_test - ERROR - wandb: Run `wandb offline` to turn off syncing.
2025-01-06 18:05:05,668 - star_logger_test - ERROR - wandb: Syncing run test_1
2025-01-06 18:05:05,668 - star_logger_test - ERROR - wandb: ⭐️ View project at https://wandb.ai/vityavitalich/STaR
2025-01-06 18:05:05,668 - star_logger_test - ERROR - wandb: 🚀 View run at https://wandb.ai/vityavitalich/STaR/runs/vcr70ro8
2025-01-06 18:05:05,699 - star_logger_test - ERROR - 
2025-01-06 18:05:05,707 - star_logger_test - ERROR -   0%|          | 0/35 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py:657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)
2025-01-06 18:05:05,707 - star_logger_test - ERROR -   batch["labels"] = torch.tensor(batch["labels"], dtype=torch.int64)
2025-01-06 18:05:07,174 - star_logger_test - ERROR - 
2025-01-06 18:05:07,512 - star_logger_test - ERROR -   3%|▎         | 1/35 [00:01<00:50,  1.47s/it]
2025-01-06 18:05:07,870 - star_logger_test - ERROR -   6%|▌         | 2/35 [00:01<00:26,  1.24it/s]
2025-01-06 18:05:08,232 - star_logger_test - ERROR -   9%|▊         | 3/35 [00:02<00:19,  1.66it/s]
2025-01-06 18:05:08,590 - star_logger_test - ERROR -  11%|█▏        | 4/35 [00:02<00:15,  1.97it/s]
2025-01-06 18:05:08,948 - star_logger_test - ERROR -  14%|█▍        | 5/35 [00:02<00:13,  2.21it/s]
2025-01-06 18:05:09,306 - star_logger_test - ERROR -  17%|█▋        | 6/35 [00:03<00:12,  2.38it/s]
2025-01-06 18:05:09,665 - star_logger_test - ERROR -  20%|██        | 7/35 [00:03<00:11,  2.50it/s]
2025-01-06 18:05:10,024 - star_logger_test - ERROR -  23%|██▎       | 8/35 [00:03<00:10,  2.58it/s]
2025-01-06 18:05:10,382 - star_logger_test - ERROR -  26%|██▌       | 9/35 [00:04<00:09,  2.64it/s]
2025-01-06 18:05:10,481 - star_logger_test - ERROR -  29%|██▊       | 10/35 [00:04<00:09,  2.69it/s]
2025-01-06 18:05:10,481 - star_logger_test - INFO - {'loss': 2.6677, 'grad_norm': 135.69268798828125, 'learning_rate': 8.618670190525352e-05, 'epoch': 0.29}
2025-01-06 18:05:10,481 - star_logger_test - ERROR -                                                
2025-01-06 18:05:10,481 - star_logger_test - ERROR - 
2025-01-06 18:05:10,744 - star_logger_test - ERROR -  29%|██▊       | 10/35 [00:04<00:09,  2.69it/s]
2025-01-06 18:05:11,105 - star_logger_test - ERROR -  31%|███▏      | 11/35 [00:05<00:08,  2.71it/s]
2025-01-06 18:05:11,466 - star_logger_test - ERROR -  34%|███▍      | 12/35 [00:05<00:08,  2.73it/s]
2025-01-06 18:05:11,823 - star_logger_test - ERROR -  37%|███▋      | 13/35 [00:05<00:08,  2.74it/s]
2025-01-06 18:05:12,192 - star_logger_test - ERROR -  40%|████      | 14/35 [00:06<00:07,  2.76it/s]
2025-01-06 18:05:12,551 - star_logger_test - ERROR -  43%|████▎     | 15/35 [00:06<00:07,  2.74it/s]
2025-01-06 18:05:12,912 - star_logger_test - ERROR -  46%|████▌     | 16/35 [00:06<00:06,  2.76it/s]
2025-01-06 18:05:13,271 - star_logger_test - ERROR -  49%|████▊     | 17/35 [00:07<00:06,  2.76it/s]
2025-01-06 18:05:13,632 - star_logger_test - ERROR -  51%|█████▏    | 18/35 [00:07<00:06,  2.77it/s]
2025-01-06 18:05:13,989 - star_logger_test - ERROR -  54%|█████▍    | 19/35 [00:07<00:05,  2.77it/s]
2025-01-06 18:05:14,086 - star_logger_test - ERROR -  57%|█████▋    | 20/35 [00:08<00:05,  2.78it/s]
2025-01-06 18:05:14,087 - star_logger_test - INFO - {'loss': 2.4244, 'grad_norm': 51.24120330810547, 'learning_rate': 4.288425808633575e-05, 'epoch': 0.57}
2025-01-06 18:05:14,087 - star_logger_test - ERROR -                                                
2025-01-06 18:05:14,087 - star_logger_test - ERROR - 
2025-01-06 18:05:14,347 - star_logger_test - ERROR -  57%|█████▋    | 20/35 [00:08<00:05,  2.78it/s]
2025-01-06 18:05:14,713 - star_logger_test - ERROR -  60%|██████    | 21/35 [00:08<00:05,  2.78it/s]
2025-01-06 18:05:15,073 - star_logger_test - ERROR -  63%|██████▎   | 22/35 [00:09<00:04,  2.77it/s]
2025-01-06 18:05:15,429 - star_logger_test - ERROR -  66%|██████▌   | 23/35 [00:09<00:04,  2.77it/s]
2025-01-06 18:05:15,789 - star_logger_test - ERROR -  69%|██████▊   | 24/35 [00:09<00:03,  2.78it/s]
2025-01-06 18:05:16,147 - star_logger_test - ERROR -  71%|███████▏  | 25/35 [00:10<00:03,  2.78it/s]
2025-01-06 18:05:16,518 - star_logger_test - ERROR -  74%|███████▍  | 26/35 [00:10<00:03,  2.78it/s]
2025-01-06 18:05:16,871 - star_logger_test - ERROR -  77%|███████▋  | 27/35 [00:10<00:02,  2.76it/s]
2025-01-06 18:05:17,226 - star_logger_test - ERROR -  80%|████████  | 28/35 [00:11<00:02,  2.78it/s]
2025-01-06 18:05:17,586 - star_logger_test - ERROR -  83%|████████▎ | 29/35 [00:11<00:02,  2.79it/s]
2025-01-06 18:05:17,686 - star_logger_test - ERROR -  86%|████████▌ | 30/35 [00:11<00:01,  2.79it/s]
2025-01-06 18:05:17,686 - star_logger_test - INFO - {'loss': 2.6535, 'grad_norm': 45.78642654418945, 'learning_rate': 5.558227567253832e-06, 'epoch': 0.86}
2025-01-06 18:05:17,686 - star_logger_test - ERROR -                                                
2025-01-06 18:05:17,686 - star_logger_test - ERROR - 
2025-01-06 18:05:17,948 - star_logger_test - ERROR -  86%|████████▌ | 30/35 [00:11<00:01,  2.79it/s]
2025-01-06 18:05:18,311 - star_logger_test - ERROR -  89%|████████▊ | 31/35 [00:12<00:01,  2.78it/s]
2025-01-06 18:05:18,668 - star_logger_test - ERROR -  91%|█████████▏| 32/35 [00:12<00:01,  2.77it/s]
2025-01-06 18:05:19,027 - star_logger_test - ERROR -  94%|█████████▍| 33/35 [00:12<00:00,  2.78it/s]
2025-01-06 18:05:19,383 - star_logger_test - ERROR -  97%|█████████▋| 34/35 [00:13<00:00,  2.78it/s]
2025-01-06 18:05:19,482 - star_logger_test - ERROR - 100%|██████████| 35/35 [00:13<00:00,  2.79it/s]
2025-01-06 18:05:19,482 - star_logger_test - INFO - {'train_runtime': 17.0496, 'train_samples_per_second': 8.211, 'train_steps_per_second': 2.053, 'train_loss': 2.565822056361607, 'epoch': 1.0}
2025-01-06 18:05:19,483 - star_logger_test - ERROR -                                                
2025-01-06 18:05:19,483 - star_logger_test - ERROR - 
2025-01-06 18:05:19,483 - star_logger_test - ERROR - 100%|██████████| 35/35 [00:13<00:00,  2.79it/s]/usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
2025-01-06 18:05:19,483 - star_logger_test - ERROR -   warnings.warn(
2025-01-06 18:05:19,483 - star_logger_test - ERROR - 
2025-01-06 18:05:19,483 - star_logger_test - ERROR - 100%|██████████| 35/35 [00:13<00:00,  2.54it/s]
2025-01-06 18:05:19,484 - star_logger_test - ERROR - /usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:690: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
2025-01-06 18:05:19,484 - star_logger_test - ERROR -   warnings.warn(
2025-01-06 18:06:53,971 - star_logger_test - ERROR - wandb: - 0.011 MB of 0.011 MB uploaded
2025-01-06 18:06:54,972 - star_logger_test - ERROR - wandb: \ 0.011 MB of 0.011 MB uploaded
2025-01-06 18:06:55,972 - star_logger_test - ERROR - wandb: | 0.011 MB of 0.011 MB uploaded
2025-01-06 18:06:56,973 - star_logger_test - ERROR - wandb: / 0.011 MB of 0.011 MB uploaded
2025-01-06 18:06:57,975 - star_logger_test - ERROR - wandb: - 0.042 MB of 0.060 MB uploaded (0.006 MB deduped)
2025-01-06 18:06:58,028 - star_logger_test - ERROR - wandb: \ 0.061 MB of 0.061 MB uploaded (0.006 MB deduped)
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb: | 0.061 MB of 0.061 MB uploaded (0.006 MB deduped)
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb: 
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb: Run history:
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb:         train/epoch ▁▄▇█
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb:   train/global_step ▁▄▇█
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb:     train/grad_norm █▁▁
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb: train/learning_rate █▄▁
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb:          train/loss █▁█
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb: 
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb: Run summary:
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb:               total_flos 40574353670144.0
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb:              train/epoch 1.0
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb:        train/global_step 35
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb:          train/grad_norm 45.78643
2025-01-06 18:06:58,195 - star_logger_test - ERROR - wandb:      train/learning_rate 1e-05
2025-01-06 18:06:58,196 - star_logger_test - ERROR - wandb:               train/loss 2.6535
2025-01-06 18:06:58,196 - star_logger_test - ERROR - wandb:               train_loss 2.56582
2025-01-06 18:06:58,196 - star_logger_test - ERROR - wandb:            train_runtime 17.0496
2025-01-06 18:06:58,196 - star_logger_test - ERROR - wandb: train_samples_per_second 8.211
2025-01-06 18:06:58,196 - star_logger_test - ERROR - wandb:   train_steps_per_second 2.053
2025-01-06 18:06:58,196 - star_logger_test - ERROR - wandb: 
2025-01-06 18:06:58,196 - star_logger_test - ERROR - wandb: 🚀 View run test_1 at: https://wandb.ai/vityavitalich/STaR/runs/vcr70ro8
2025-01-06 18:06:58,196 - star_logger_test - ERROR - wandb: ️⚡ View job at https://wandb.ai/vityavitalich/STaR/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjUzMDIxNTAzOQ==/version_details/v4
2025-01-06 18:06:58,196 - star_logger_test - ERROR - wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
2025-01-06 18:06:58,196 - star_logger_test - ERROR - wandb: Find logs at: ./wandb/run-20250106_180503-vcr70ro8/logs
2025-01-06 18:07:02,302 - star_logger_test - INFO - [INFO] STaR algorithm completed.
